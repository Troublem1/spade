1
00:00:00.066 --> 00:00:03.966
音楽

2
00:00:03.966 --> 00:00:08.900
前のビデオでは、回帰問題の指標について説
明しました。

3
00:00:08.900 --> 00:00:11.310
ここでは、分類の指標を確認します。

4
00:00:12.932 --> 00:00:17.310
我々は、最初の精度について話をする,
対数損失, と

5
00:00:17.310 --> 00:00:23.200
次に、受信機の操作曲線の下の領域に取得し
、コーエンのカッパ。

6
00:00:23.200 --> 00:00:25.390
そして、具体的に二次加重カッパ。

7
00:00:26.420 --> 00:00:28.110
まずは表記を直すことから始めましょう。

8
00:00:29.350 --> 00:00:34.600
N は、データセット内のオブジェクトの数
、L、クラスの数です。

9
00:00:35.720 --> 00:00:41.458
以前のように、y
は予測のために、ターゲットと y
の帽子のために立つでしょう。

10
00:00:41.458 --> 00:00:46.430
角かっこで囲まれた式が表示されている場合
は、インジケーター関数です。

11
00:00:46.430 --> 00:00:51.510
式が true
の場合はフィールド1、false
の場合は0を返します。

12
00:00:51.510 --> 00:00:56.426
ビデオを通して、我々は2つの用語のハード
ラベルを使用しますか

13
00:00:56.426 --> 00:01:00.985
ハード予測、およびソフトラベルやソフトの
予測。

14
00:01:00.985 --> 00:01:04.970
通常、モデルはいくつかの種類のスコアを出
力します。

15
00:01:04.970 --> 00:01:09.470
たとえば、各クラスに属するオブジェクトの
確率。

16
00:01:10.730 --> 00:01:14.950
スコアは L
サイズのベクトルとして書くことができ、

17
00:01:14.950 --> 00:01:18.840
私は、ソフトの予測には、このベクトルを参
照します。

18
00:01:18.840 --> 00:01:22.630
今の分類では、通常のラベルを予測するため
に求められている

19
00:01:22.630 --> 00:01:24.700
オブジェクトは、ハード予測を行います。

20
00:01:26.110 --> 00:01:30.656
それを行うには、我々は通常、ソフトの予測
で最大値を見つけると

21
00:01:30.656 --> 00:01:35.445
この最大スコアに対応するクラスを予測ラベ
ルとして設定します。

22
00:01:35.445 --> 00:01:38.613
従って堅いラベルは柔らかいラベルの機能、

23
00:01:38.613 --> 00:01:42.485
通常、マルチクラスタスクの場合は arg
max ですが、

24
00:01:42.485 --> 00:01:47.860
バイナリ分類それは閾値関数として考えるこ
とができます。

25
00:01:49.170 --> 00:01:52.310
だから、出力ラベル1のソフトスコア

26
00:01:52.310 --> 00:01:56.740
クラス1はしきい値よりも高く、それ以外の
場合はクラス0を出力します。

27
00:01:57.820 --> 00:02:00.500
精度スコアで旅を始めましょう。

28
00:02:01.510 --> 00:02:04.920
精度は、分類子の品質の最も簡単な尺度です
。

29
00:02:06.150 --> 00:02:08.380
0から1までの値です。

30
00:02:08.380 --> 00:02:10.014
より高い、より良い。

31
00:02:10.014 --> 00:02:15.679
そして、それは正しく分類されたオブジェク
トの割合に等しくなります。

32
00:02:15.679 --> 00:02:18.908
精度を計算するには、ハード予測が必要です
。

33
00:02:18.908 --> 00:02:22.975
各オブジェクトに特定のテーブルを割り当て
る必要があります。

34
00:02:22.975 --> 00:02:28.319
今、正確さの場合に予測するために最適な定
数は何ですか?

35
00:02:28.319 --> 00:02:31.339
実際には、試行する定数の数が少ないです。

36
00:02:31.339 --> 00:02:35.660
クラスラベルは、すべてのオブジェクトに一
度に割り当てることができます。

37
00:02:35.660 --> 00:02:39.440
では、どのクラスを割り当てるべきでしょう
か。

38
00:02:39.440 --> 00:02:40.970
明らかに、最も頻繁に1つ。

39
00:02:42.060 --> 00:02:45.330
その後、正しく推測されたオブジェクトの数
が最も高くなります。

40
00:02:46.830 --> 00:02:49.000
しかし、まさにその理由のために、

41
00:02:49.000 --> 00:02:53.360
精度スコアの値の解釈には注意点があります
。

42
00:02:54.840 --> 00:02:57.330
この例を見てください。

43
00:02:57.330 --> 00:03:02.048
私達は私達の列車セットに10匹の猫および
90匹の犬があることを言う。

44
00:03:02.048 --> 00:03:06.081
我々は常にすべてのオブジェクトの犬を予測
した場合、

45
00:03:06.081 --> 00:03:10.020
その後、精度はすでに0.9 になります。

46
00:03:10.020 --> 00:03:15.429
そして、あなたは、あなたの分類子が10の
うち9回正しいことを誰かに伝える想像して
ください。

47
00:03:16.460 --> 00:03:19.523
人はおそらくあなたが素敵なモデルを持って
いると思うだろう。

48
00:03:19.523 --> 00:03:25.598
しかし実際は、あなたのモデルはどんな入力
があるか犬のクラスをちょうど予測する。

49
00:03:25.598 --> 00:03:31.374
ので、問題は、ベースラインの精度は非常に
高いことができることです

50
00:03:31.374 --> 00:03:38.004
データセットも 99%
で、結果を解釈するのが難しくなります。

51
00:03:38.004 --> 00:03:40.865
精度スコアは非常にきれいで直感的ですが、

52
00:03:40.865 --> 00:03:43.050
それは非常に最適化するのは難しいことが判
明した。

53
00:03:44.230 --> 00:03:49.867
精度は、分類子が予測にどの程度自信を持っ
ているかも気にしません。

54
00:03:49.867 --> 00:03:52.080
そして、どのようなソフトの予測です。

55
00:03:53.090 --> 00:03:56.000
それは、ソフト予測の arg max
についてだけ気にします。

56
00:03:57.330 --> 00:04:01.768
したがって、人々は時々、最初にある別の指
標を使用することを好む

57
00:04:01.768 --> 00:04:03.005
簡単に最適化できます。

58
00:04:03.005 --> 00:04:08.180
そして第二に、これらのメトリックは、ソフ
トの予測ではなく、ハードなもので動作しま
す。

59
00:04:09.340 --> 00:04:11.960
そのような指標の1つは対数損失です。

60
00:04:11.960 --> 00:04:17.775
それは2つの後部確率を出力する分類子を作
ることを試みる

61
00:04:17.775 --> 00:04:22.385
特定のクラスの特定の種類のオブジェクト。

62
00:04:22.385 --> 00:04:26.265
ログの損失は、通常、バイナリのために少し
異なる理由であり、

63
00:04:26.265 --> 00:04:27.395
マルチクラスのタスク。

64
00:04:28.500 --> 00:04:35.102
バイナリの場合、y ハットは01の範囲か
らの数値であると仮定し、

65
00:04:35.102 --> 00:04:41.112
そして、それはクラス1に属するオブジェク
トの確率です。

66
00:04:41.112 --> 00:04:47.400
したがって、1マイナス y ハットは、こ
のオブジェクトがクラス0になる確率です。

67
00:04:47.400 --> 00:04:51.460
multiclass
タスクの場合、LogLoss
はこのフォームに書き込まれます。

68
00:04:52.630 --> 00:05:00.183
ここで y ハット i は L サイズの
ベクトルで、その和は正確に1です。

69
00:05:00.183 --> 00:05:05.210
要素は、各クラスに属する確率です。

70
00:05:06.400 --> 00:05:10.138
この数式を L が2になるように書き、

71
00:05:10.138 --> 00:05:13.887
あなたはそれが上から正確にバイナリの損失
であることがわかります。

72
00:05:13.887 --> 00:05:19.404
そして最後に、それは実際に避けるために、
言及する必要があります

73
00:05:19.404 --> 00:05:23.796
予測は0から1ではないようにクリッピング
されますが、

74
00:05:23.796 --> 00:05:30.053
いくつかの小さな正の数から1マイナスいく
つかの小さな正の数から。

75
00:05:30.053 --> 00:05:33.230
さて、今少し分析してみましょう。

76
00:05:33.230 --> 00:05:39.080
オブジェクトのターゲットが0であると仮定
し、ここでプロットに、

77
00:05:39.080 --> 00:05:43.213
予測を0から1に変更すると、エラーがどの
ように変化するかがわかります。

78
00:05:43.213 --> 00:05:48.640
比較のために、我々は別の色で絶対的なエラ
ーをプロットします。

79
00:05:48.640 --> 00:05:53.269
Logloss
は、通常、完全に間違った答えを処罰

80
00:05:53.269 --> 00:05:58.676
1つが厳しいミスに小さなミスの多くを作る
ことを好む。

81
00:05:58.676 --> 00:06:03.190
今、対数の損失のための最もよい定数は何で
あるか。

82
00:06:03.190 --> 00:06:07.560
それはあなたがそれぞれの周波数に予測を設
定する必要があることが判明

83
00:06:07.560 --> 00:06:08.977
データセット内のクラス。

84
00:06:08.977 --> 00:06:12.789
私たちの場合では、周波数の

85
00:06:12.789 --> 00:06:19.200
猫クラスは0.1
で、クラスドッグで0.9 です。

86
00:06:19.200 --> 00:06:22.250
その後、最適な定数は、これら2つの値のベ
クトルです。

87
00:06:23.420 --> 00:06:26.070
どのように私は、よくどのように私はそうで
す知っていますか?

88
00:06:27.160 --> 00:06:31.790
それを証明するために我々は一定のアルファ
に関して導関数を取るべきだ

89
00:06:31.790 --> 00:06:35.240
0に設定し、この式からアルファを見つけま
す。

90
00:06:36.360 --> 00:06:41.480
さて、我々は正確さとログの損失を議論した
、今の移動してみましょう。

91
00:06:42.570 --> 00:06:44.580
例を見てみましょう。

92
00:06:44.580 --> 00:06:47.880
地上の真理値を色で示し、

93
00:06:47.880 --> 00:06:50.490
点の位置は、分類子スコアを示します。

94
00:06:51.490 --> 00:06:55.670
バイナリタスクの精度スコアを計算すること
を思い出してください,

95
00:06:55.670 --> 00:06:59.529
我々は通常、我々のモデルからソフトの予測
を取るとしきい値を適用します。

96
00:07:00.530 --> 00:07:05.631
我々は、スコアが0.5 よりも高い場合は
、予測が緑色であることがわかります

97
00:07:05.631 --> 00:07:07.059
赤が低ければ

98
00:07:07.059 --> 00:07:14.486
この例では、精度は6または7で、1つの赤
色のオブジェクトをよりしています。

99
00:07:14.486 --> 00:07:18.115
しかし、見て、しきい値は0.7
だった場合、

100
00:07:18.115 --> 00:07:22.934
その後、すべてのオブジェクトが正しく分類
されます。

101
00:07:22.934 --> 00:07:27.620
だから、これは私たちの次のメトリック、曲
線の下の領域のためのモチベーションのよう
なものです。

102
00:07:29.120 --> 00:07:31.710
我々はそれのためのしきい値を修正すべきで
はないが、

103
00:07:32.820 --> 00:07:37.127
このメートルの種類はすべての可能な物を試
み、それらのスコアを集計する。

104
00:07:38.190 --> 00:07:43.139
したがって、このメトリックは実際に予測の
絶対値を気にしません。

105
00:07:43.139 --> 00:07:46.602
しかし、それはオブジェクトの順序にのみ依
存します。

106
00:07:46.602 --> 00:07:53.767
実際には、いくつかの方法 AUC、または
曲線の下にこの領域は、説明することができ
ますがあります。

107
00:07:53.767 --> 00:07:57.630
最初の1つは、領域を計算する必要がある曲
線の下で説明します。

108
00:07:57.630 --> 00:08:01.520
そして、2番目の確率として AUC
を説明

109
00:08:01.520 --> 00:08:04.530
オブジェクトのペアを正確に我々のモデルで
注文する。

110
00:08:04.530 --> 00:08:08.897
我々は、現時点では両方の説明が表示されま
す。

111
00:08:08.897 --> 00:08:11.031
だから最初の1つから始めましょう。

112
00:08:11.031 --> 00:08:15.211
そこで、曲線の下の領域を計算する必要があ
ります。

113
00:08:15.211 --> 00:08:17.151
どんなカーブ?

114
00:08:17.151 --> 00:08:19.471
今すぐに構築してみましょう。

115
00:08:19.471 --> 00:08:25.201
もう一度、我々は6つのオブジェクトを持っ
ていると言うと、その真のラベルは、色で表
示されます。

116
00:08:25.201 --> 00:08:29.951
そして、ドットの位置は、分類子の予測を示
しています。

117
00:08:29.951 --> 00:08:36.801
そして今のところ我々は、赤のクラスに属し
ているシノニムとして肯定的な単語を使用し
ます。

118
00:08:36.801 --> 00:08:40.021
だから肯定的な側面は左側にあります。

119
00:08:40.021 --> 00:08:46.744
我々は今何をするか、我々は左から右に移動
します、別のオブジェクトからジャンプしま
す。

120
00:08:46.744 --> 00:08:51.320
そして、それぞれの我々はどのように多くの
赤と計算されます

121
00:08:51.320 --> 00:08:57.961
緑の点が左に、このオブジェクトには、我々
に立っている。

122
00:08:57.961 --> 00:09:02.421
赤い点には、真陽性の名前があります。

123
00:09:02.421 --> 00:09:06.851
そして、緑のものについては、偽陽性の名前
があります。

124
00:09:06.851 --> 00:09:12.072
だから我々は一種の計算のようになりますど
のように多くの真陽性と

125
00:09:12.072 --> 00:09:18.015
我々が立っているオブジェクトの左側に表示
される偽陽性。

126
00:09:18.015 --> 00:09:22.855
実際には非常に単純な、我々は左下隅から開
始し、

127
00:09:22.855 --> 00:09:25.331
赤い点を見るたびに上がる。

128
00:09:25.331 --> 00:09:28.331
そして、右に我々は緑のいずれかを参照して
ください。

129
00:09:28.331 --> 00:09:30.101
えっと。

130
00:09:30.101 --> 00:09:32.441
だから我々は最初の左端のポイントに立って
いる。

131
00:09:32.441 --> 00:09:35.020
そして、それは赤、または肯定的です。

132
00:09:35.020 --> 00:09:38.873
だから我々は、真陽性の数を増やすと上に移
動します。

133
00:09:38.873 --> 00:09:41.641
次に、我々は緑のポイントにジャンプします
。

134
00:09:41.641 --> 00:09:45.906
それは偽陽性であり、従って私達は右に行く
。

135
00:09:45.906 --> 00:09:49.691
それから2つの赤いポイントのための2回。

136
00:09:49.691 --> 00:09:53.561
最後のグリーンポイントのために最後に2回
右。

137
00:09:53.561 --> 00:09:55.925
我々は、右上隅に終了しました。

138
00:09:55.925 --> 00:09:59.930
そしてそれは常にそのように動作します。

139
00:09:59.930 --> 00:10:01.680
私たちは左下から開始し、

140
00:10:01.680 --> 00:10:06.600
私たちが右のほとんどのポイントにジャンプ
するときに右上隅に終了します。

141
00:10:06.600 --> 00:10:12.290
ところで、先ほど作成したカーブはレシーバ
動作曲線と呼ばれます。

142
00:10:12.290 --> 00:10:12.860
ROC 曲線。

143
00:10:14.180 --> 00:10:17.290
そして今、私たちはこの曲線の下の領域を計
算する準備が整いました。

144
00:10:18.460 --> 00:10:25.550
面積は7であり、我々は正方形の合計複数の
領域でそれを正規化する必要があります。

145
00:10:25.550 --> 00:10:30.102
だから AUC は7/9、涼しいです。

146
00:10:30.102 --> 00:10:34.929
今、どのような AUC が分離することが
できるデータセットのためになります

147
00:10:34.929 --> 00:10:39.150
私たちの最初の例のようなしきい値を持つ?

148
00:10:39.150 --> 00:10:43.778
実際に auc は1、最大値 auc
になります。

149
00:10:43.778 --> 00:10:46.526
だから、動作します。

150
00:10:46.526 --> 00:10:49.270
これは、しきい値を指定する必要はありませ
ん

151
00:10:49.270 --> 00:10:51.610
絶対値に依存しません。

152
00:10:51.610 --> 00:10:56.328
カーブの作成時に絶対値を使用したことがな
いことを思い出してください。

153
00:10:56.328 --> 00:10:59.680
今実際には、このような曲線を構築する場合

154
00:10:59.680 --> 00:11:05.397
巨大なデータを実際の分類子に設定すると、
そのような画像を観察します。

155
00:11:05.397 --> 00:11:10.510
ここに異なった分類器のためのカーブは異な
った色と示される。

156
00:11:10.510 --> 00:11:15.368
曲線は、通常、どのように示す破線の上にあ
る

157
00:11:15.368 --> 00:11:20.240
もし我々がランダムに予測した曲線のように
なります。

158
00:11:20.240 --> 00:11:24.500
だから、私たちのベースラインを示していま
す。

159
00:11:24.500 --> 00:11:29.818
破線の下の領域は0.5
であることに注意してください。

160
00:11:29.818 --> 00:11:35.420
すべての権利は、我々はその下に曲線と計算
領域を構築することができます見てきました
。

161
00:11:35.420 --> 00:11:40.832
AUC
のための別の合計別の説明があります。

162
00:11:40.832 --> 00:11:43.324
オブジェクトのすべてのペアを考慮し、

163
00:11:43.324 --> 00:11:48.595
そのような1つのオブジェクトは、赤のクラ
スから、もう一つは緑からです。

164
00:11:48.595 --> 00:11:51.527
AUC は、確率のためのスコア

165
00:11:51.527 --> 00:11:56.491
緑の1つは、赤のスコアよりも高くなります
。

166
00:11:56.491 --> 00:12:01.556
すなわち、AUC は、正しく順序付けられ
たペアの一部分である。

167
00:12:01.556 --> 00:12:06.750
この例では、2つの誤った順序のペアがあり
、

168
00:12:06.750 --> 00:12:08.520
合計で9組。

169
00:12:08.520 --> 00:12:15.214
そして、そこに7正しく順序のペアがあり、
したがって AUC は7/9 です。

170
00:12:15.214 --> 00:12:20.758
正確に我々が前に得たように、曲線の下にコ
ンピューティング領域。

171
00:12:20.758 --> 00:12:24.770
ここでは AUC
の計算方法について説明しました。

172
00:12:24.770 --> 00:12:28.780
今度はそれのための最もよい一定した予言が
であるもの考えることを許可しなさい。

173
00:12:28.780 --> 00:12:32.580
実際には、AUC
は予測の正確な値に依存しません。

174
00:12:32.580 --> 00:12:36.382
すべての定数は、同じスコアにつながるので
、

175
00:12:36.382 --> 00:12:40.490
このスコアは約0.5、ベースラインになり
ます。

176
00:12:40.490 --> 00:12:44.957
これは実際に人々が AUC
について愛するものです。

177
00:12:44.957 --> 00:12:48.110
ベースラインが何であるかは明らかです。

178
00:12:48.110 --> 00:12:53.240
もちろん、AUC の欠陥がある、すべての
メトリックはいくつかを持っています。

179
00:12:53.240 --> 00:12:59.180
しかし、まだ AUC は、私は通常、誰も
私のために別の1つを設定するときに使用す
るメトリックです。

180
00:12:59.180 --> 00:13:05.914
最後に話し合う指標を教えよう

181
00:13:05.914 --> 00:13:10.331
コーエンのカッパとそれはデリバティブです
。

182
00:13:10.331 --> 00:13:15.128
我々は常に最も頻繁にクラスのラベルを予測
する場合は、リコール

183
00:13:15.128 --> 00:13:20.350
我々はすでにかなり高精度のスコアを得るこ
とができ、それは誤解を招くことができます
。

184
00:13:20.350 --> 00:13:24.960
実際に我々の例では、すべてのモデルが収ま
るように、

185
00:13:24.960 --> 00:13:29.800
0.9 と1の間のどこかにスコアを持つこ
とになります。

186
00:13:29.800 --> 00:13:36.682
そこで、1の精度のための新しいメトリック
を導入することができます,
それは私たちを与えるだろう 1,

187
00:13:36.682 --> 00:13:40.950
また、ベースラインの精度については、0を
出力します。

188
00:13:40.950 --> 00:13:45.290
そしてもちろん、ベースラインのために異な
ることになるだろう

189
00:13:45.290 --> 00:13:49.543
すべてのデータは、必ずしも0.9
または何でも。

190
00:13:49.543 --> 00:13:53.560
また、非常にどのような2乗されている
MSE と似ています。

191
00:13:53.560 --> 00:13:58.480
非公式に言ってそれを正規化の一種です。

192
00:13:58.480 --> 00:14:01.690
だから我々はここで同じことを行う。

193
00:14:01.690 --> 00:14:05.660
そして、これは実際にはすでにほとんどコー
エン氏のカッパです。

194
00:14:05.660 --> 00:14:09.572
コーエンのカッパでは、ベースラインとして
別の値を取る。

195
00:14:09.572 --> 00:14:14.428
我々は、データセットのためのより高い予測
を取り、それらをシャッフル、

196
00:14:14.428 --> 00:14:16.291
ランダムに permute のように。

197
00:14:16.291 --> 00:14:21.050
次に、これらのシャッフル予測の精度を計算
します。

198
00:14:21.050 --> 00:14:24.778
そして、それは私たちのベースラインになり
ます。

199
00:14:24.778 --> 00:14:29.845
正確に言えば、精度を何度も計算して
permute

200
00:14:29.845 --> 00:14:34.750
、ベースラインとして、それらの計算精度の
平均を取る。

201
00:14:34.750 --> 00:14:39.210
実際には、もちろん、我々は任意の順列を行
う必要はありません。

202
00:14:39.210 --> 00:14:43.411
この基準スコアは、解析的に計算することが
できます。

203
00:14:43.411 --> 00:14:48.522
我々は、まず、我々の予測の経験的な周波数
を乗算する必要があります

204
00:14:48.522 --> 00:14:52.196
各クラスにそれらのラベルを付与し、それら
を合計します。

205
00:14:52.196 --> 00:14:56.859
たとえば、20個の cat
ラベルを割り当て、

206
00:14:56.859 --> 00:15:02.505
80犬のラベルをランダムにし、ベースライ
ンの精度

207
00:15:02.505 --> 00:15:08.411
0.2 * 0.1 + 0.8 *
0.9 = 0.74 になります。

208
00:15:08.411 --> 00:15:12.185
より多くの例を実際に見つけることができま
す。

209
00:15:12.185 --> 00:15:18.584
ここで私は、ベースラインとしてエリミネー
ターについての考え方の良い方法を説明した
い。

210
00:15:18.584 --> 00:15:23.356
我々はまた、エラーが1のマイナスの精度に
等しいことを思い出すことができます。

211
00:15:23.356 --> 00:15:31.206
数式を1マイナスモデルのエラー/ベースラ
インエラーとして書き換えることができます
。

212
00:15:31.206 --> 00:15:33.018
それでもコーエンのカッパになりますが、

213
00:15:33.018 --> 00:15:36.520
しかし、今、それは加重コーエン氏のカッパ
を導出することが容易になります。

214
00:15:36.520 --> 00:15:41.274
加重カッパを説明するために、我々は最初の
ステップを脇に行う必要があり、

215
00:15:41.274 --> 00:15:43.396
加重誤差を導入します。

216
00:15:43.396 --> 00:15:46.740
猫と犬とトラを分類する

217
00:15:46.740 --> 00:15:52.704
我々は猫の代わりに犬を予測する場合、我々
は、またはより少なく大丈夫です。

218
00:15:52.704 --> 00:15:57.760
しかし、それは本当に虎なら猫や犬を予測す
ることは望ましくありません。

219
00:15:57.760 --> 00:16:01.736
だから我々は、重み行列を形成するつもりだ

220
00:16:01.736 --> 00:16:06.150
各セルには、我々が行うかもしれないミスの
重みが含まれています。

221
00:16:07.170 --> 00:16:11.610
我々のケースでは、我々は猫を予測する場合
、我々は、エラーの重みを10倍の大きさに
設定

222
00:16:11.610 --> 00:16:14.430
犬が、地上の真実のラベルはタイガーです。

223
00:16:15.830 --> 00:16:18.340
したがって、エラーウェイトマトリックスで
は、

224
00:16:18.340 --> 00:16:22.260
我々は、分類子が作成するエラーについての
好みを表現することができます。

225
00:16:23.390 --> 00:16:25.080
今、体重を計算すると

226
00:16:25.080 --> 00:16:29.500
エラーは、分類子の予測のための別の行列、
混乱行列が必要です。

227
00:16:31.010 --> 00:16:35.270
この行列は、我々の分類子が予測をどのよう
に分配するかを示します

228
00:16:35.270 --> 00:16:36.720
オブジェクト。

229
00:16:36.720 --> 00:16:41.880
たとえば、最初の列は、10のうち4匹の猫
が認識されたことを示します

230
00:16:41.880 --> 00:16:47.980
正確には、2つの犬と4タイガースとして分
類された。

231
00:16:47.980 --> 00:16:51.350
したがって、加重エラースコアを取得するに
は、

232
00:16:51.350 --> 00:16:56.520
この2つの行列を乗算して結果を合計する必
要があります。

233
00:16:57.850 --> 00:17:01.940
この式には適切な正規化が必要です

234
00:17:01.940 --> 00:17:06.850
量が0から1の間であることを確認するため
に、それは重要ではありません

235
00:17:06.850 --> 00:17:10.450
私たちの目的は、正規化定数は、とにかくキ
ャンセルされます。

236
00:17:12.120 --> 00:17:15.868
そして最後に、加重カッパは1として計算さ
れます-

237
00:17:15.868 --> 00:17:19.730
加重エラー/加重ベースラインエラーです。

238
00:17:21.010 --> 00:17:26.070
多くの場合、重み行列は非常に単純な方法で
定義されます。

239
00:17:26.070 --> 00:17:29.470
たとえば、順序付けられたラベルの分類の問
題について。

240
00:17:30.700 --> 00:17:35.200
各オブジェクトに1から3までの値を割り当
てる必要があるとします。

241
00:17:35.200 --> 00:17:39.200
これは、例えば、どのように重度の病気の評
価することができます。

242
00:17:39.200 --> 00:17:44.950
そして、それは回帰ではないので、どこかに
なるように値を出力することはできません

243
00:17:44.950 --> 00:17:49.690
評価と地上の真理値の間にもラベルのように
見える、

244
00:17:49.690 --> 00:17:51.730
予測する数値としてではありません。

245
00:17:52.940 --> 00:17:57.240
そのような問題は通常、分類の問題として扱
われますが、

246
00:17:57.240 --> 00:18:02.150
ウェイトマトリックスは、ラベルの順序を考
慮して導入されます。

247
00:18:03.270 --> 00:18:08.720
たとえば、重みを線形にすることができます
,
我々は1つの代わりに2を予測する場合,
我々は1つを支払う.

248
00:18:09.820 --> 00:18:13.971
1つではなく3つを予測する場合は、2つの
支払いを行います。

249
00:18:13.971 --> 00:18:19.506
または重みが2次であることができます,
我々は1つの代わりに二つを予測する場合,

250
00:18:19.506 --> 00:18:25.150
我々はまだ1つを支払うが、我々は1つの代
わりに3を予測する場合、我々は今の支払い
。

251
00:18:26.190 --> 00:18:30.510
使用されるウェイトマトリックスに応じて、

252
00:18:30.510 --> 00:18:34.460
線形重み付きカッパまたは二次加重カッパの
いずれかを取得します。

253
00:18:35.590 --> 00:18:40.281
二次加重カッパは、Kaggle
のいくつかの大会で使用されています。

254
00:18:40.281 --> 00:18:44.761
通常、しかりつける合意係数として説明され
、

255
00:18:44.761 --> 00:18:49.649
モデルの予言が地面真実の評定とどの位一致
するか。

256
00:18:49.649 --> 00:18:53.024
これは、医学のアプリケーションのための非
常に直感的です。

257
00:18:53.024 --> 00:18:56.410
どのくらいのモデルは、プロの医師に同意し
ます。

258
00:18:57.410 --> 00:19:01.590
最後に、このビデオでは、分類マトリックス
について説明しました。

259
00:19:02.620 --> 00:19:07.580
精度は、それが分類のための不可欠な指標で
す。

260
00:19:07.580 --> 00:19:12.485
しかし、同じ値を常に予測する単純なモデル
では、

261
00:19:12.485 --> 00:19:16.991
非常に高い精度で、このメトリックを解釈す
るのが難しくなります。

262
00:19:16.991 --> 00:19:21.473
スコアはまた、我々はソフトに変換すること
を選択したしきい値に依存

263
00:19:21.473 --> 00:19:23.554
ハードラベルへの予測。

264
00:19:23.554 --> 00:19:25.600
Logloss は別の指標であり、

265
00:19:25.600 --> 00:19:31.493
精度とは対照的に、それはソフトの予測では
なく、ハードラベルに依存します。

266
00:19:31.493 --> 00:19:36.408
そして、それはモデルが属しているオブジェ
クトの確率を予測するために強制的に

267
00:19:36.408 --> 00:19:37.500
各クラスに。

268
00:19:37.500 --> 00:19:43.158
AUC, レシーバ動作曲線下の領域,
絶対値に依存しない

269
00:19:43.158 --> 00:19:48.430
分類子によって予測されますが、オブジェク
トの順序を考慮するだけです。

270
00:19:49.750 --> 00:19:54.530
また、すべてのしきい値を暗黙的に試行して
、ソフト予測を収束

271
00:19:54.530 --> 00:20:00.210
これにより、しきい値のスコアの依存性が取
り除かれます。

272
00:20:01.960 --> 00:20:08.262
最後に、コーエンのカッパは、精度スコアの
ベースラインをゼロに修正します。

273
00:20:08.262 --> 00:20:11.777
精神では、非常にどのように r-2
乗に似ている

274
00:20:11.777 --> 00:20:15.390
ベータスケール MSE
の値を簡単に説明する。

275
00:20:17.480 --> 00:20:24.910
精度ではなく、加重精度を使用する場合、我
々は、カッパを加重取得します。

276
00:20:24.910 --> 00:20:29.746
二次重みを持つ重み付きカッパは、二次加重
カッパと呼ばれ、

277
00:20:29.746 --> 00:20:31.366
一般的に Kaggle で使用されます。

278
00:20:31.366 --> 00:20:41.366
音楽


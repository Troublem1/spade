1
00:00:00.000 --> 00:00:04.717
音これまでのところ、さまざまな指標につい
て説明しました

2
00:00:04.717 --> 00:00:09.003
彼らの定義、およびそれらのための直感。

3
00:00:09.003 --> 00:00:15.030
最適化の損失と目標指標の違いについて検討
しました。

4
00:00:15.030 --> 00:00:19.920
このビデオでは、どのように効率的に使用す
るメトリックを最適化することができますが
表示されます

5
00:00:19.920 --> 00:00:20.889
回帰の問題。

6
00:00:21.915 --> 00:00:25.680
我々は、我々は常にアール停止を使用するこ
とができます議論した。

7
00:00:25.680 --> 00:00:28.280
だから私はこれまでのメトリックのために言
及されません。

8
00:00:28.280 --> 00:00:29.200
しかし、心に留めておいてください。

9
00:00:29.200 --> 00:00:32.940
平均二乗誤差から始めましょう。

10
00:00:32.940 --> 00:00:35.760
これは、回帰タスクに最もよく使用されるメ
トリックです。

11
00:00:35.760 --> 00:00:38.499
だから我々はそれが動作するように簡単であ
ることを期待する必要があります。

12
00:00:39.530 --> 00:00:45.740
実際には、ほとんどすべてのモデリングソフ
トウェアは、損失関数として MSE
を実装します。

13
00:00:45.740 --> 00:00:51.450
あなたがそれを最適化するために行う必要が
あるので、あなたのお気に入りのライブラリ
でこれをオンにすることです。

14
00:00:52.540 --> 00:00:57.030
そして、ここにいくつかのライブラリの平均
二乗エラーの最適化をサポートしています。

15
00:00:57.030 --> 00:00:59.930
XGBoost も LightGBM
も、簡単にやります。

16
00:01:01.222 --> 00:01:06.120
スカラーからの
RandomForestRegresor
は、また、MSE
に基づいて分割することができます,

17
00:01:06.120 --> 00:01:09.830
したがって、個別に最適化。

18
00:01:09.830 --> 00:01:13.770
siclicar
では多くの線形モデルが実装されており、

19
00:01:13.770 --> 00:01:17.040
それらのほとんどは、MSE
を最適化するように設計されています。

20
00:01:17.040 --> 00:01:23.020
たとえば、通常、正方形、リーチ回帰、回帰
などがあります。

21
00:01:24.800 --> 00:01:28.040
SGRegressor のクラスと
Sklearn もあります。

22
00:01:29.180 --> 00:01:31.320
また、線形モデルを実装しますが、

23
00:01:31.320 --> 00:01:34.640
Sklearn
の他の線形モデルに別様に。

24
00:01:34.640 --> 00:01:39.440
それは、それを訓練するためにまともな
[聞こえない] 勾配を使用して、したがっ
て、非常に汎用性。

25
00:01:39.440 --> 00:01:43.238
まあ、もちろん MSE
が組み込まれていた。

26
00:01:43.238 --> 00:01:49.007
線形モデルのオンライン学習のためのライブ
ラリ,

27
00:01:49.007 --> 00:01:53.054
また、失われた関数として MSC
を受け入れます。

28
00:01:53.054 --> 00:01:59.250
しかし、PyTorch、Keras、フロ
ーのようなすべてのニューラルネットパッケ
ージは、MSE
の損失が実装されています。

29
00:01:59.250 --> 00:02:02.480
あなただけの GitHub
またはどこでも、例を見つける必要がある

30
00:02:02.480 --> 00:02:06.500
MSE の損失がその特定の図書館で持って
いる名前を見なさい。

31
00:02:07.640 --> 00:02:11.010
たとえば、L 2
の損失と呼ばれることもありますが、

32
00:02:11.010 --> 00:02:13.600
マットルークの距離に L
として使用しています。

33
00:02:14.770 --> 00:02:17.790
しかし、基本的には、このレッスンで検討す
るすべての指標については、

34
00:02:17.790 --> 00:02:21.100
あなたは、彼らが使用されて以来、plai
ntal 炎を見つけることができる

35
00:02:21.100 --> 00:02:23.900
別のコミュニティで独立して発見。

36
00:02:25.100 --> 00:02:27.598
さて、どういう意味の絶対的なエラーについ
て。

37
00:02:27.598 --> 00:02:33.083
メイも人気があるので、それを最適化するモ
デルを見つけることは簡単です。

38
00:02:33.083 --> 00:02:39.122
残念ながら、余分なブーストは、メイを最適
化することはできません

39
00:02:39.122 --> 00:02:44.588
メイは、LightGBM ができる間、第
2の導関数としてゼロを持っています。

40
00:02:44.588 --> 00:02:48.977
したがって、このメトリックにグラデーショ
ンブーストデシジョンツリーを使用すること
もできます。

41
00:02:48.977 --> 00:02:55.302
メイ基準は、Sklearn から Ran
domForestRegressor
のために実装されました。

42
00:02:55.302 --> 00:03:00.258
しかし、実行時間は非常に MSE のコル
テに比べて高いことに注意してください。

43
00:03:00.258 --> 00:03:04.911
残念ながら、SKLearn
からの線形モデルを含む

44
00:03:04.911 --> 00:03:08.873
SG リグレッサは、負のメイを最適化する
ことはできません。

45
00:03:08.873 --> 00:03:15.510
しかし、そこにロスフーバーロスと呼ばれる
、それはいくつかのモデルで実装されていま
す。

46
00:03:15.510 --> 00:03:20.770
基本的に、それは非常にメイに似ている、特
にエラーが大きい場合。

47
00:03:22.050 --> 00:03:24.468
次のスライドで説明します。

48
00:03:24.468 --> 00:03:27.420
「聞き取れない」では、メイロスが実施され
、

49
00:03:27.420 --> 00:03:32.200
しかし、別の名前の下には、と呼ばれるの変
位の損失。

50
00:03:32.200 --> 00:03:35.780
実際には、メイだけでは、特殊な場合は、変
位の損失です。

51
00:03:36.920 --> 00:03:41.583
ただし、私は詳細には、ここに行くことはあ
りませんが、ちょうどメイはリコール

52
00:03:41.583 --> 00:03:46.695
どういうわけか中央値とメジアンに接続され
ている特定の変位。

53
00:03:47.860 --> 00:03:49.940
ニューラルネットワークは?

54
00:03:49.940 --> 00:03:53.920
我々は、メイが微分されていない議論したと
きにのみ予測

55
00:03:53.920 --> 00:03:55.930
はターゲットに等しくなります。

56
00:03:55.930 --> 00:03:58.960
そして、それはまれなケースのです。

57
00:03:58.960 --> 00:04:04.152
だからこそ、我々はメイを最適化するために
配置する任意の鉄道模型を使用することがあ
ります。

58
00:04:05.430 --> 00:04:10.420
メイが神経ライブラリーに実装されているの
を見つけられないかもしれない

59
00:04:10.420 --> 00:04:13.100
しかし、それを実装することは非常に簡単で
す。

60
00:04:13.100 --> 00:04:16.200
実際には、すべてのモデルが必要です

61
00:04:16.200 --> 00:04:19.030
は、予測に対する損失関数の勾配です。

62
00:04:19.030 --> 00:04:23.104
この場合、これは単なる set
関数です。

63
00:04:23.104 --> 00:04:27.661
メイのために遭遇するかもしれない別の名前
は、L1 は、フィットと

64
00:04:27.661 --> 00:04:32.216
1つの損失、そして時には人々は、特別なケ
ースを参照してください

65
00:04:32.216 --> 00:04:35.736
五分位階級別回帰としての中間回帰。

66
00:04:35.736 --> 00:04:40.521
多くの、多くの方法メイスムーズにするため
の多くの。

67
00:04:40.521 --> 00:04:45.218
あなたが実際にアップロードしている独自の
円滑な機能を構成することができますように
ループ

68
00:04:45.218 --> 00:04:46.770
メイエラー。

69
00:04:46.770 --> 00:04:49.590
最も有名なものは、フーバーの損失です。

70
00:04:49.590 --> 00:04:53.430
それは基本的に MSE
とメイの間のミックスです。

71
00:04:54.640 --> 00:05:02.100
MSE は、エラーが小さいときに計算され
るので、安全にゼロエラーに近づくことがで
きます。

72
00:05:02.100 --> 00:05:06.580
とメイは、堅牢性を与えられた大きなエラー
に対して計算されます。

73
00:05:07.670 --> 00:05:12.110
そこで、ここでは、平均二乗誤差を最適化で
きるライブラリについて説明し、

74
00:05:12.110 --> 00:05:13.640
絶対誤差を意味します。

75
00:05:13.640 --> 00:05:17.358
さて、一般的な相対メトリックを聞かないよ
うにしましょう。

76
00:05:17.358 --> 00:05:22.270
MSPE と MAPE

77
00:05:22.270 --> 00:05:26.900
それは箱からそれらを最適化することができ
ますモデルを見つけることがはるかに困難で
す。

78
00:05:26.900 --> 00:05:31.880
もちろん、我々は常に、どちらか、もちろん
我々は常に使用することができます

79
00:05:31.880 --> 00:05:35.120
整数ブーストまたはニューラルネットのカス
タム損失を実装します。

80
00:05:35.120 --> 00:05:38.310
本当にそこまでしやすいです。

81
00:05:38.310 --> 00:05:41.280
または、異なるメトリックを最適化し、早期
停止を行うことができます。

82
00:05:42.490 --> 00:05:45.760
しかし、私が言及したいいくつかの具体的な
アプローチがあります。

83
00:05:46.760 --> 00:05:52.169
このアプローチは、MSP が MSE の
加重バージョンであるという事実に基づいて
おり、

84
00:05:52.169 --> 00:05:54.663
マップはメイの加重バージョンです。

85
00:05:54.663 --> 00:06:00.697
右側には、MSP
とマップのセン式があります。

86
00:06:00.697 --> 00:06:05.378
召喚分母は、単に重みを確実に

87
00:06:05.378 --> 00:06:09.340
は1まで加算されますが、必須ではありませ
ん。

88
00:06:10.950 --> 00:06:16.180
直感的に、サンプルの重みは、オブジェクト
がどのように重要であるかを示しています

89
00:06:16.180 --> 00:06:17.950
私たちはモデルを訓練しながら。

90
00:06:19.300 --> 00:06:22.650
ターゲットが小さいほど、オブジェクトの重
要性が高くなります。

91
00:06:24.510 --> 00:06:27.230
どうやってこの知識を使うの?

92
00:06:28.270 --> 00:06:30.810
実際、多くのライブラリはサンプルウェイト
を受け入れます。

93
00:06:31.860 --> 00:06:33.460
MSP を最適化するとします。

94
00:06:34.790 --> 00:06:38.760
そのため、サンプルウェイトを前のスライド
のものに設定できる場合は、

95
00:06:39.880 --> 00:06:41.580
我々はそれで MSE
の法律を使用することができます。

96
00:06:43.020 --> 00:06:48.300
そして、モデルは、実際に所望の MSPE
損失を最適化します。

97
00:06:48.300 --> 00:06:53.060
XGBoost、LightGBM、ほとん
どのニューラルネットのようなほとんどの重
要なライブラリが

98
00:06:53.060 --> 00:06:57.390
パッケージは、すべてのライブラリがそれを
実装するのではなく、サンプル重み付けをサ
ポートします。

99
00:06:58.700 --> 00:07:03.500
しかし、ライブラリは、MSE を最適化す
ることができますたびに動作する別の方法が
あります

100
00:07:03.500 --> 00:07:04.040
またはメイ。

101
00:07:04.040 --> 00:07:05.449
他には何も必要ありません。

102
00:07:06.860 --> 00:07:11.205
我々が行う必要があるのは、それをサンプリ
ングすることによって、新しいトレーニング
セットを作成することです

103
00:07:11.205 --> 00:07:15.548
私たちが持っているとモデルに合わせて、元
のセットは、例えば、

104
00:07:15.548 --> 00:07:18.864
MSPE を最適化したいなら私は
secretarian だ

105
00:07:20.617 --> 00:07:22.874
の確率を設定することが重要です。

106
00:07:22.874 --> 00:07:25.990
計算した重みにサンプリングする各オブジェ
クト。

107
00:07:27.160 --> 00:07:29.260
新しいデータセットのサイズは、あなた次第
です。

108
00:07:29.260 --> 00:07:35.020
たとえば、元の列車セットにあったオブジェ
クトの2倍の数をサンプリングすることがで
きます。

109
00:07:36.418 --> 00:07:39.920
また、テストセットでは何もする必要がない
ことに注意してください。

110
00:07:39.920 --> 00:07:41.740
そのままにしておきます。

111
00:07:42.900 --> 00:07:46.430
私も何度かセットして再サンプル列車にする
ことをお勧めします。

112
00:07:46.430 --> 00:07:48.480
モデルをフィッティングするたびに。

113
00:07:48.480 --> 00:07:52.790
我々ははるかに良いとスコアを取得します場
合、その後、平均モデルの予測、

114
00:07:52.790 --> 00:07:53.490
より安定した。

115
00:07:54.710 --> 00:07:57.890
結果は、我々は MSPE
を最適化することができます別の方法、

116
00:07:59.250 --> 00:08:03.720
このアプローチは Kagle の
Rossmund
競争の間に広く利用された。

117
00:08:03.720 --> 00:08:06.610
これは、エラーが小さい場合は、証明するこ
とができます

118
00:08:06.610 --> 00:08:10.252
我々は、対数スケールで予測を最適化するこ
とができます。

119
00:08:10.252 --> 00:08:13.100
ここで、それは我々が実際に次のスライド上
で何をするかに似ています。

120
00:08:14.450 --> 00:08:15.970
我々は詳細に行くことはありませんが、

121
00:08:15.970 --> 00:08:19.740
あなたは読書資料で説明へのリンクを見つけ
ることができます。

122
00:08:20.860 --> 00:08:25.720
そして最後に、最後の回帰指標について説明
します。

123
00:08:25.720 --> 00:08:27.850
ルート、平均、正方形、対数エラー。

124
00:08:29.160 --> 00:08:34.200
これは、MSE の損失との接続のために、
最適化することは非常に簡単になります。

125
00:08:35.290 --> 00:08:40.230
まず、ターゲット変数に適用して変換する必
要があります。

126
00:08:40.230 --> 00:08:43.310
この場合、ターゲットの対数プラス1。

127
00:08:44.480 --> 00:08:47.460
変換されたターゲットを現在の z
変数で表してみましょう。

128
00:08:49.080 --> 00:08:54.750
そして、我々はターゲットを変換するために
MSE の損失とモデルを適合させる必要が
あります。

129
00:08:54.750 --> 00:08:59.360
テスト対象の予測を取得するには、まず予測
、z ハット、

130
00:08:59.360 --> 00:09:04.790
モデルを呼び出すことによって、対数スケー
ルになります。そのような予測か何か。

131
00:09:06.160 --> 00:09:12.210
次に、対数スケールから元のものへの逆変換
を行います。

132
00:09:12.210 --> 00:09:17.700
expatiating z
の帽子と1を引くことで、

133
00:09:17.700 --> 00:09:22.340
これは、テストセットの予測 y
ハットを取得する方法です。

134
00:09:22.340 --> 00:09:27.610
このビデオでは、回帰マトリックスとツール
を使用して最適化を実行します。

135
00:09:27.610 --> 00:09:32.490
MSE とメイは非常に一般的であり、多く
のパッケージで実装されています。

136
00:09:32.490 --> 00:09:37.930
RMSPE と MAPE を最適化するに
は、データセットをリサンプリングするか、

137
00:09:37.930 --> 00:09:40.662
適切なサンプルウェイトを設定する。

138
00:09:40.662 --> 00:09:47.345
RMSLE は、ログ領域で MSE
を最適化することによって最適化されます。

139
00:09:47.345 --> 00:09:50.884
次のビデオでは、我々の最適化技術が表示さ
れます

140
00:09:50.884 --> 00:09:52.454
分類マトリックス。

141
00:09:52.454 --> 00:10:02.454
音楽


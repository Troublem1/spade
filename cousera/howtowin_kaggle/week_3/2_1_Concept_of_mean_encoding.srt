1
00:00:00.030 --> 00:00:03.898
音楽

2
00:00:03.898 --> 00:00:05.740
ねえ皆さん。

3
00:00:05.740 --> 00:00:10.880
このセクションでは、非常に強力なテクニッ
ク、つまりエンコーディングについて説明し
ます。

4
00:00:10.880 --> 00:00:13.210
それは実際に名前の数を持っています。

5
00:00:13.210 --> 00:00:17.120
いくつかの呼び出しは、尤度符号化、いくつ
かのターゲットエンコーディングが、

6
00:00:17.120 --> 00:00:20.780
このコースでは、プレーンな平均エンコーデ
ィングに固執します。

7
00:00:20.780 --> 00:00:23.850
この手法の一般的なアイデアは、追加するこ
とです

8
00:00:23.850 --> 00:00:28.180
いくつかの機能に基づいて新しい変数は、我
々が始めた場所を取得します。

9
00:00:28.180 --> 00:00:32.510
最も単純なケースでは、カテゴリ変数の各レ
ベルをエンコードします。

10
00:00:32.510 --> 00:00:36.020
対応するターゲットの平均。

11
00:00:36.020 --> 00:00:38.710
次の例を見てみましょう。

12
00:00:38.710 --> 00:00:43.029
ここでは、我々が持っているいくつかのバイ
ナリ分類タスクを持っている

13
00:00:43.029 --> 00:00:45.650
カテゴリ変数、いくつかの都市。

14
00:00:45.650 --> 00:00:49.180
そしてもちろん、我々はそれを数値的に符号
化したい。

15
00:00:49.180 --> 00:00:53.810
最も明白な方法と人々は通常使用するラベル
のエンコードです。

16
00:00:55.120 --> 00:00:56.750
2列目にある

17
00:00:58.050 --> 00:01:00.446
平均エンコーディングは異なる方法で行われ
、

18
00:01:00.446 --> 00:01:04.920
を介して対応する平均目標を持つすべての都
市をエンコードします。

19
00:01:04.920 --> 00:01:11.660
たとえば、モスクワでは、3つの0s
と2つの1s を持つ5つの行があります。

20
00:01:11.660 --> 00:01:17.550
だから我々は5または0.4
で割った2でそれをエンコードします。

21
00:01:17.550 --> 00:01:23.560
同様に、我々は都市の残りの部分に対処する
、かなり簡単です。

22
00:01:23.560 --> 00:01:27.380
私がここで述べたことは非常に高いレベルの
考えである。

23
00:01:27.380 --> 00:01:33.280
実際の競争で克服するべきである落とし穴の
巨大な数がある。

24
00:01:33.280 --> 00:01:36.880
私たちは詳細については、今のところ、ちょ
うどそれを念頭に保管した。

25
00:01:38.390 --> 00:01:40.130
最初に説明させてくれ

26
00:01:40.130 --> 00:01:42.130
どうして働くの?

27
00:01:42.130 --> 00:01:48.900
想像すると、我々のデータセットははるかに
大きく、さまざまな都市の数が含まれていま
す。

28
00:01:48.900 --> 00:01:52.334
まあ、比較してみましょう、もちろん、非常
に抽象、

29
00:01:52.334 --> 00:01:54.390
ラベルエンコーディングによる平均符号化。

30
00:01:55.860 --> 00:02:00.320
クラス0とクラス1の将来のヒストグラムを
プロットします。

31
00:02:00.320 --> 00:02:03.720
ラベル符号化の場合には、我々は常に合計を
取得し、

32
00:02:03.720 --> 00:02:07.970
論理的な順序がないので、ランダムな画像が
、

33
00:02:07.970 --> 00:02:14.350
平均ターゲットを使用してフィーチャをエン
コードすると、クラスはより分離しやすくな
ります。

34
00:02:14.350 --> 00:02:16.010
プロットはソートのように見えます。

35
00:02:17.350 --> 00:02:22.520
これは、平均符号化のこのソート品質が非常
に有用であることが判明した。

36
00:02:22.520 --> 00:02:25.410
覚えて、何が最も人気があると

37
00:02:25.410 --> 00:02:27.654
効果的な方法は、機械学習の問題を解決する
には?

38
00:02:27.654 --> 00:02:33.404
木を使ってグレーディングしている、[聞こ
えない] OIGBM。

39
00:02:33.404 --> 00:02:37.854
いくつかの欠点の一つは、高基数を処理する
ことができないことです。

40
00:02:37.854 --> 00:02:39.609
カテゴリ変数。

41
00:02:40.970 --> 00:02:46.400
木は、平均符号化で、我々はそれを補うこと
ができる、深さを制限している

42
00:02:47.950 --> 00:02:51.990
私たちは短い木でより良い損失に達すること
ができる。

43
00:02:51.990 --> 00:02:54.690
クロス検証の損失は、このように見えるかも
しれません。

44
00:02:55.780 --> 00:03:01.710
一般的に、より複雑で非線形なフィーチャタ
ーゲット依存性は、

45
00:03:01.710 --> 00:03:07.150
より効果的なのは、[ok]
を意味エンコードです。

46
00:03:07.150 --> 00:03:12.030
さらに、このセクションでは、平均エンコー
ディングを構築する方法について説明します
。

47
00:03:12.030 --> 00:03:14.320
実際には多くの方法があります。

48
00:03:14.320 --> 00:03:19.070
また、分類テストは例としてのみ使用するこ
とに注意してください。

49
00:03:19.070 --> 00:03:22.110
他のテストでも数学を使うことができます。

50
00:03:22.110 --> 00:03:24.160
主な考え方は同じままです。

51
00:03:25.520 --> 00:03:31.680
アイデアのシンプルさにもかかわらず、あな
たは非常に検証に注意する必要があります。

52
00:03:31.680 --> 00:03:34.120
申し分のないことになってる

53
00:03:34.120 --> 00:03:36.570
それはおそらく最も重要な部分です。

54
00:03:36.570 --> 00:03:41.600
正しい linkless 検証を理解する
ことも、賭けの基礎となります。

55
00:03:42.600 --> 00:03:46.090
最後ではなく、少なくとも、拡張機能です。

56
00:03:46.090 --> 00:03:50.860
ターゲット変数から新しいフィーチャを導出
するには、無数の可能性があります。

57
00:03:50.860 --> 00:03:54.860
時には、彼らはあなたのモデルの大幅な改善
を生成します。

58
00:03:56.350 --> 00:03:59.410
データセットのいくつかの特性から始めまし
ょう

59
00:03:59.410 --> 00:04:02.170
メインエンコーディングの有用性を示します
。

60
00:04:03.310 --> 00:04:07.010
レベルの多いカテゴリ変数の存在

61
00:04:07.010 --> 00:04:10.600
は、すでに良い指標ですが、我々は少し深く
行く必要があります。

62
00:04:11.820 --> 00:04:16.170
スプリングリーフの競争からこれらの学習ロ
グのそれぞれを見てみましょう。

63
00:04:17.300 --> 00:04:22.337
私は、7、9、11の深さの異なる3つのモ
デルを走った。

64
00:04:22.337 --> 00:04:25.150
列車の丸太は上のプロットにある。

65
00:04:25.150 --> 00:04:27.070
検証ログは、下の1つにあります。

66
00:04:28.160 --> 00:04:32.840
あなたが見ることができるように、木々の深
さを増加させると、私たちのトレーニングケ
アは

67
00:04:32.840 --> 00:04:37.300
より良い、より良い、ほぼ完璧な、それは正
常な部分です。

68
00:04:38.420 --> 00:04:42.260
しかし、我々は実際にフィードをしないと、
それは奇妙です。

69
00:04:42.260 --> 00:04:47.260
私たちの検証スコアも増加し、それは兆候だ

70
00:04:47.260 --> 00:04:53.260
木はいくつかの変数から情報を抽出するため
に分割の膨大な数が必要です。

71
00:04:53.260 --> 00:04:55.160
そして、我々は、致命的なダンプをチェック
することができます。

72
00:04:56.680 --> 00:05:01.770
それは、いくつかの機能は、スプリットポイ
ントの途方もない量を持っていることが判明

73
00:05:01.770 --> 00:05:06.680
1200や1600のように、それは多くの
です。

74
00:05:06.680 --> 00:05:11.170
私たちのモデルは、すべてのこれらのカテゴ
リを異なる治療しようとする

75
00:05:11.170 --> 00:05:14.847
彼らはまた、ターゲットを予測するために非
常に重要です。

76
00:05:14.847 --> 00:05:18.735
我々は、平均符号化を介して私たちのモデル
を助けることができる。

77
00:05:20.115 --> 00:05:22.955
エンコードを計算するには、いくつかの方法
があります。

78
00:05:22.955 --> 00:05:26.315
最初の1つは、我々はこれまで議論してきた
ものです。

79
00:05:26.315 --> 00:05:28.825
単にターゲット変数の平均を取る。

80
00:05:30.035 --> 00:05:34.805
もう1つの一般的なオプションは、この値の
初期対数を取ることです

81
00:05:34.805 --> 00:05:36.335
それは証拠の重みと呼ばれる

82
00:05:37.470 --> 00:05:40.400
またはすべてのものの数を計算することがで
きます。

83
00:05:41.530 --> 00:05:46.150
または0の数との数の違い。

84
00:05:46.150 --> 00:05:48.190
これらのすべては、変数のオプションです。

85
00:05:49.360 --> 00:05:51.960
さて、実際に機能を構築してみましょう。

86
00:05:51.960 --> 00:05:54.060
私達は振りかけたデータセットでそれをする

87
00:05:55.750 --> 00:05:59.750
我々はすでに列車のデータを分離したと仮定
し、

88
00:05:59.750 --> 00:06:04.553
検証、X_tr、および X val
データフレーム。

89
00:06:04.553 --> 00:06:10.045
これらのスニペットは、平均エンコーディン
グを構築する方法を示しています

90
00:06:10.045 --> 00:06:16.708
任意の列と新しいデータフレームにマップ,
新しいとヴァル新しいトレイン.

91
00:06:16.708 --> 00:06:22.199
私たちは、単にその列によってグループ化し
、マップとしてターゲットを使用します。

92
00:06:22.199 --> 00:06:26.627
結果として得られたコマンドは
[聞き取れない]。

93
00:06:26.627 --> 00:06:33.420
次に、マップ演算子によってツリーおよび検
証データセットにマップされます。

94
00:06:33.420 --> 00:06:36.523
すべての呼び出しに対してこのプロセスを繰
り返した後、

95
00:06:36.523 --> 00:06:39.280
この新しいデータには、それぞれのモデルを
収めることができます。

96
00:06:40.710 --> 00:06:43.803
しかし、何かが間違いなく正しくない、

97
00:06:43.803 --> 00:06:49.191
いくつかの努力のトレーニング AOC
の後にほぼ1、検証中に、

98
00:06:49.191 --> 00:06:54.250
スコアは実質的にノイズである0.55
の周りのレートを設定します。

99
00:06:55.820 --> 00:06:58.395
それはひどいオーバーフィット回避の明確な
兆候だ。

100
00:06:59.570 --> 00:07:02.190
しばらくして何があったか説明するわ

101
00:07:02.190 --> 00:07:07.430
今、私は、少なくとも我々が正しく検証した
ことを指摘したい。

102
00:07:07.430 --> 00:07:09.060
私たちは列車を分離し、

103
00:07:09.060 --> 00:07:14.570
検証を行い、すべての列車データを使用して
平均符号化を推定した。

104
00:07:14.570 --> 00:07:19.550
例えば、我々は前に平均符号化を推定した

105
00:07:19.550 --> 00:07:24.060
列車の検証を分割し、我々はそのようなオー
バーフィット回避に気づくことはありません
。

106
00:07:25.510 --> 00:07:27.670
さて、オーバーフィット回避の理由を把握し
ましょう。

107
00:07:29.100 --> 00:07:34.260
それらが分類されるとき、例のような結果を
得ることはかなり共通である、

108
00:07:34.260 --> 00:07:37.708
目標0をトレーニングとターゲット1で検証
します。

109
00:07:37.708 --> 00:07:45.190
平均エンコーディングは、このようなカテゴ
リに最適な機能に変わります。

110
00:07:45.190 --> 00:07:49.460
だからこそ、我々はすぐに電車の中で非常に
良いスコアを取得し、

111
00:07:49.460 --> 00:07:51.310
検証に失敗することはほとんどありません。

112
00:07:52.640 --> 00:07:58.050
これまでのところ、我々は、平均符号化の概
念を把握し、いくつかの些細なを歩いた

113
00:07:58.050 --> 00:08:04.270
例では、明らかに実際にこのような意味のエ
ンコーディングを使用することはできません
。

114
00:08:04.270 --> 00:08:09.530
まずオーバーフィット回避に対処する必要が
ある正則化のいくつかの種類が必要です。

115
00:08:10.720 --> 00:08:18.289
そして、私は別のことを教えてくれます

116
00:08:20.116 --> 00:08:26.119
次のビデオのメソッド。

117
00:08:26.119 --> 00:08:29.699
音楽


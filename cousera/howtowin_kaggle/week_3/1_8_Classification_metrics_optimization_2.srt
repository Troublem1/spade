1
00:00:03.120 --> 00:00:05.920
だから、以前のビデオでは、

2
00:00:05.920 --> 00:00:08.230
Logloss
と正確性について説明しました。

3
00:00:08.230 --> 00:00:10.880
このビデオでは、曲線の下の領域について説
明します,

4
00:00:10.880 --> 00:00:13.000
AUC、および (二次加重) カッパ。

5
00:00:13.000 --> 00:00:15.917
AUC から始めましょう。

6
00:00:15.917 --> 00:00:21.619
AUC の損失関数はほぼどこでもゼロのグ
ラデーションを持っていますが、

7
00:00:21.619 --> 00:00:23.740
正確には、精度の損失として、

8
00:00:23.740 --> 00:00:29.180
勾配法を用いて AUC
を最適化するアルゴリズムが存在し,

9
00:00:29.180 --> 00:00:32.150
いくつかのモデルは、このアルゴリズムを実
装します。

10
00:00:32.150 --> 00:00:35.445
だから、適切なパラメータを設定することに
よってそれを使用することができます。

11
00:00:35.445 --> 00:00:38.280
私はあなたにこの方法についてのアイデアを
与えることなく

12
00:00:38.280 --> 00:00:42.895
多くの詳細は、それを実装する複数の方法が
あるとして。

13
00:00:42.895 --> 00:00:48.745
最初に、分類タスクは通常、オブジェクトの
レベルで解決されることを思い出してくださ
い。

14
00:00:48.745 --> 00:00:52.275
我々は、赤のオブジェクトに0を割り当てた
い

15
00:00:52.275 --> 00:00:54.400
緑のものに1。

16
00:00:54.400 --> 00:00:57.655
しかし、我々は独立して、各オブジェクトの
ために行う

17
00:00:57.655 --> 00:01:00.130
だから我々の損失は間隙

18
00:01:00.130 --> 00:01:03.325
我々は、個々のオブジェクトのためにそれを
計算する

19
00:01:03.325 --> 00:01:09.795
合計損失を得るために、すべてのオブジェク
トの損失を合計または平均します。

20
00:01:09.795 --> 00:01:13.330
今、AUC
が確率であることを思い出してください

21
00:01:13.330 --> 00:01:17.500
正しい方法で注文するオブジェクトのペアの
。

22
00:01:17.500 --> 00:01:19.145
だから理想的には、我々が欲しい

23
00:01:19.145 --> 00:01:25.315
緑のオブジェクトの予測 Y ^
は、赤いものよりも大きくなります。

24
00:01:25.315 --> 00:01:28.655
したがって、単一のオブジェクトを操作する
のではなく、

25
00:01:28.655 --> 00:01:31.288
我々は、オブジェクトのペアで動作する必要
があります。

26
00:01:31.288 --> 00:01:34.235
そして、代わりに間隙の損失を使用して、

27
00:01:34.235 --> 00:01:36.760
我々は一対の損失を使用する必要があります
。

28
00:01:36.760 --> 00:01:40.400
一対の損失は予測とラベルを取る

29
00:01:40.400 --> 00:01:44.175
オブジェクトのペアとその損失を計算します
。

30
00:01:44.175 --> 00:01:49.030
理想的には、順序が正しい場合、損失はゼロ
になります。

31
00:01:49.030 --> 00:01:54.205
順序が正しくない場合は0より大きくなりま
す。

32
00:01:54.205 --> 00:01:57.140
しかし、実際には、異なる損失関数を使用す
ることができます。

33
00:01:57.140 --> 00:01:59.605
例えば、我々は logloss
を使用することができます。

34
00:01:59.605 --> 00:02:04.825
この一対の損失のターゲットは常に1である
と考えるかもしれない

35
00:02:04.825 --> 00:02:08.310
赤マイナスグリーンは1つにする必要があり
ます。

36
00:02:08.310 --> 00:02:12.905
だからこそ、logloss
の目的の2つの代わりに1つの用語です。

37
00:02:12.905 --> 00:02:17.280
式の確率関数が必要です

38
00:02:17.280 --> 00:02:21.660
予測の違いがまだ 0, 1
の範囲にあることを確認してください。

39
00:02:21.660 --> 00:02:25.500
そして、私はシンプルのためだけにここでそ
れを使用してください。

40
00:02:25.500 --> 00:02:31.745
まあ、基本的に、XGBoost、Ligh
tGBM は、私たちが実装した議論した一
対の損失を持っています。

41
00:02:31.745 --> 00:02:35.605
これは、任意のニューラルネットライブラリ
で実装することは簡単ですが、

42
00:02:35.605 --> 00:02:40.655
そして確かに、あなたは GitHub
上で実装を見つけることができます。

43
00:02:40.655 --> 00:02:42.230
私は実際には、と言う必要があります

44
00:02:42.230 --> 00:02:49.845
ほとんどの人はまだ後処理なしで最適化の損
失として logloss
を使用しています。

45
00:02:49.845 --> 00:02:53.610
私は個人的に loglosst で学んだ
XGBoost を与えるために観察

46
00:02:53.610 --> 00:02:59.650
一対の損失で学んだものに匹敵する AUC
のスコア。大丈夫です。

47
00:02:59.650 --> 00:03:04.655
さて、話し合うために最後のトピックに移り
ましょう。

48
00:03:04.655 --> 00:03:08.720
それは二次加重カッパメトリックです。2つ
の方法があります。

49
00:03:08.720 --> 00:03:11.180
1つは非常に、非常に簡単に一般的です

50
00:03:11.180 --> 00:03:14.320
2番目は、一般的ではありませんし、実装す
る必要があります

51
00:03:14.320 --> 00:03:19.330
XGBoost またはニューラルネットの
いずれかのカスタム損失関数。

52
00:03:19.330 --> 00:03:22.110
しかし、我々はすでに XGBoost
のためにそれを実装した

53
00:03:22.110 --> 00:03:26.825
従って読書材料の実施を見つけることができ
る。

54
00:03:26.825 --> 00:03:29.185
しかし、簡単なものから始めましょう。

55
00:03:29.185 --> 00:03:31.435
我々は解決しているリコール

56
00:03:31.435 --> 00:03:36.610
順序付けられた分類問題および私達のラベル
は私達の整数の評価、見つけることができる

57
00:03:36.610 --> 00:03:38.645
1から5まで言う。

58
00:03:38.645 --> 00:03:42.160
タスクは、我々が出力できないように分類さ
れ、

59
00:03:42.160 --> 00:03:44.915
たとえば、回答として4.5。

60
00:03:44.915 --> 00:03:49.255
しかし、とにかく、我々は回帰問題として、
それを治療することができますし、何とか、

61
00:03:49.255 --> 00:03:53.715
予測を後処理し、それらを整数評価に変換し
ます。

62
00:03:53.715 --> 00:04:00.315
そして、実際に二次重みは何とか MSE
の損失と回帰に似てカッパを確認します。

63
00:04:00.315 --> 00:04:05.640
我々の予測は、ラベル間の値を取ることを許
可する場合は、

64
00:04:05.640 --> 00:04:08.855
それは予測を緩めている。

65
00:04:08.855 --> 00:04:12.580
しかし、実際には、それは MSE
に異なっている。

66
00:04:12.580 --> 00:04:16.500
だから、もしリラックスして、カッパになる

67
00:04:16.500 --> 00:04:22.540
1つのマイナス MSE
は本当に予測に依存するもので割った。

68
00:04:22.540 --> 00:04:25.935
そして、それはみんなの論理のように見える
、まあ、

69
00:04:25.935 --> 00:04:28.110
分母に MSE がありますが、

70
00:04:28.110 --> 00:04:29.200
我々はそれを最適化することができます

71
00:04:29.200 --> 00:04:32.340
そして分母は気にしないようにしましょう。

72
00:04:32.340 --> 00:04:34.980
まあ、もちろんそれを行うには正しい方法で
はないが、

73
00:04:34.980 --> 00:04:37.580
しかし、それは実際に有用であることが判明
した。

74
00:04:37.580 --> 00:04:42.090
しかし、とにかく、MSE は、私たちに整
数の代りに平らな値を与えます。

75
00:04:42.090 --> 00:04:46.320
だから今、私たちは何とか整数に変換する必
要があります。

76
00:04:46.320 --> 00:04:52.215
そして、簡単な方法は、すべての予測を丸め
て行うことです。

77
00:04:52.215 --> 00:04:57.505
しかし、我々はしきい値を適用するとして丸
めについて考えることができます。

78
00:04:57.505 --> 00:05:06.700
値が3.5 より大きく、4.5
未満の場合と同様に、出力3。

79
00:05:06.700 --> 00:05:08.635
しかし、その後、我々は自分自身に質問をす
ることができます

80
00:05:08.635 --> 00:05:12.870
なぜ我々は正確にそれらのしきい値を使用す
るのですか?それらを調整してみましょう。

81
00:05:12.870 --> 00:05:15.230
そしてまた、それは単に単純な、

82
00:05:15.230 --> 00:05:18.295
グリッドサーチで簡単に行うことができます
。

83
00:05:18.295 --> 00:05:23.060
要約すると、我々は MSE
の損失に合わせて必要があります

84
00:05:23.060 --> 00:05:28.810
し、適切なしきい値を見つけます。

85
00:05:28.810 --> 00:05:31.355
最後に、紙がある

86
00:05:31.355 --> 00:05:34.920
回帰して分類問題を緩和する方法を提案し、

87
00:05:34.920 --> 00:05:40.530
しかし、それは私たちが持っていた分母の一
部に対処するために、このハードを扱ってい
ます。

88
00:05:40.530 --> 00:05:42.908
私はここで詳細に入ることはありませんが、

89
00:05:42.908 --> 00:05:46.215
でもはっきり書かれていてわかりやすい紙、

90
00:05:46.215 --> 00:05:48.950
だから私は本当にそれを読むことをお勧めし
ます。

91
00:05:48.950 --> 00:05:52.895
さらに、読書材料の損失の実施を見つけるこ
とができる、

92
00:05:52.895 --> 00:05:55.690
そして、あなたが紙を読みたくないなら、そ
れをちょうど使います。

93
00:05:55.690 --> 00:05:59.125
最後に、このレッスンを終了しました。

94
00:05:59.125 --> 00:06:05.580
評価または目標指標は、すべての提出物の採
点方法であることを説明しました。

95
00:06:05.580 --> 00:06:10.128
目標指標と最適化損失の違いについて説明し
ました。

96
00:06:10.128 --> 00:06:13.440
最適化の損失は私達のモデルが最適化するも
のである、

97
00:06:13.440 --> 00:06:19.290
そして、それは常に我々が最適化したい目標
指標と同じではありません。

98
00:06:19.290 --> 00:06:25.020
場合によっては、ターゲットメトリックとは
完全に異なる最適化を行うようにモデルを設
定できます。

99
00:06:25.020 --> 00:06:28.145
しかし、後で、我々は通常、予測を後処理し
ようとする

100
00:06:28.145 --> 00:06:32.035
ターゲット・メトリックを適切に適合させる
。

101
00:06:32.035 --> 00:06:34.080
我々は直感の背後に議論した

102
00:06:34.080 --> 00:06:37.020
回帰および分類タスクのさまざまなメトリッ
ク

103
00:06:37.020 --> 00:06:41.310
さまざまな指標を効率的に最適化する方法を
見ました。

104
00:06:41.310 --> 00:06:43.995
私はあなたがこのレッスンを楽しんでほしい
、

105
00:06:43.995 --> 00:06:46.240
そして、後でお会いします。


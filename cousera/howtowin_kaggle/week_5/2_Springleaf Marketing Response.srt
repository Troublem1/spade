1
00:00:00.000 --> 00:00:03.802
音楽

2
00:00:03.802 --> 00:00:08.527
こんにちは、コースを通して、我々は役に立
つとしてスプリングリーフの競争を使用する

3
00:00:08.527 --> 00:00:13.840
EDA の例では、最も近い近傍に基づいた
符号化と機能を意味します。

4
00:00:13.840 --> 00:00:20.090
当時、我々はと一緒にこの大会で3位を取っ
た。

5
00:00:20.090 --> 00:00:24.710
そして今、このビデオでは、私たちのソリュ
ーションの最後の部分について説明します

6
00:00:24.710 --> 00:00:28.470
これは、スタッキングとアンサンブルの使用
方法です。

7
00:00:28.470 --> 00:00:33.349
この写真では、我々はレベルで生産最終的な
スタッキングスキームを見ることができます

8
00:00:33.349 --> 00:00:38.070
最初のレベルで0の機能は、基本的なモデル
による予測。

9
00:00:38.070 --> 00:00:40.110
レベル1プラスの組み合わせで。

10
00:00:40.110 --> 00:00:44.270
したがって、これらの予測といくつかの正確
に選択した機能

11
00:00:44.270 --> 00:00:47.880
機能のこの新しいセットの2番目のレベルの
モデルに。

12
00:00:47.880 --> 00:00:52.290
そして最後に、3番目のレベルでは、その線
形の組み合わせ。

13
00:00:52.290 --> 00:00:52.910
このビデオでは、

14
00:00:52.910 --> 00:00:58.301
それは、この非自明な ensembled
スキームにビルドとして我々は、各レベルを
通過します。

15
00:00:59.430 --> 00:01:03.590
しかし、まず、すぐに問題について自分自身
を思い出させる。

16
00:01:03.590 --> 00:01:07.428
これは、曲線メトリックの下の領域を持つバ
イナリ分類タスクでした。

17
00:01:07.428 --> 00:01:15.270
我々は、トレーニングデータと約2000匿
名の機能で145000サンプルを持ってい
た。

18
00:01:15.270 --> 00:01:19.740
これらは、EDA をしながら私たちによっ
て導き出された有用な洞察でした。

19
00:01:19.740 --> 00:01:26.080
そして、あなたのメモリをリフレッシュする
ために我々のコースで以前に行われた
EDA
をチェックアウトすることができます。

20
00:01:26.080 --> 00:01:29.150
だから今の機能から始めましょう。

21
00:01:29.150 --> 00:01:33.040
ここでは、機能の4つのパックがあります。

22
00:01:33.040 --> 00:01:37.760
最初の2つは、基本データセットと処理され
たデータセットです。

23
00:01:37.760 --> 00:01:41.560
それをシンプルに保つために、我々は単にか
ら派生した洞察を使用

24
00:01:41.560 --> 00:01:45.690
EDA は、データをきれいに
[聞こえない] と新機能を生成します。

25
00:01:45.690 --> 00:01:49.280
たとえば、重複した機能を削除し、

26
00:01:49.280 --> 00:01:53.729
散布図と相関関係に基づいていくつかのフィ
ーチャインタラクションを編集します。

27
00:01:54.790 --> 00:01:59.815
その後、我々は、成長関係のループを使用し
てすべてのカテゴリ機能を意味エンコード

28
00:01:59.815 --> 00:02:02.050
データとスムージングに署名します。

29
00:02:02.050 --> 00:02:06.704
さらに、平均エンコードされたデータセット
を使用して、最も近い

30
00:02:06.704 --> 00:02:07.620
隣人。

31
00:02:07.620 --> 00:02:12.390
と同様に、クラスゼロの最も近いオブジェク
トでは何ですか?

32
00:02:12.390 --> 00:02:18.280
そして、どのように多くのオブジェクトのう
ち、10の最寄りの隣人クラス1に属してい
る?

33
00:02:18.280 --> 00:02:21.119
これがどのように行われるかを確認すること
ができます

34
00:02:21.119 --> 00:02:24.677
関連トピックでは、デミトリ
Altihof によって導入。

35
00:02:24.677 --> 00:02:31.469
そこで最後に、これらの4つの機能のパック
は、私たちのソリューションのレベル0でし
た。

36
00:02:31.469 --> 00:02:35.952
2番目のレベルは、内のいくつかの異なるグ
ラデーションで表された

37
00:02:35.952 --> 00:02:39.570
デシジョンツリーモデルと1つのニューラル
ネットワーク

38
00:02:39.570 --> 00:02:44.120
ここでの主な考え方は、メタ機能は多様でな
ければならないということです。

39
00:02:44.120 --> 00:02:48.340
各メタ機能は、ターゲットに関する新しい情
報をもたらす必要があります。

40
00:02:48.340 --> 00:02:55.714
だから我々のモデルの両方の異なるパラメー
タと機能のさまざまなセットを使用します。

41
00:02:55.714 --> 00:03:00.449
ニューラルネットワークについては、我々は
さらに事前に処理された機能

42
00:03:00.449 --> 00:03:04.600
共通のスカラー、ランクおよび力の変形。

43
00:03:04.600 --> 00:03:10.960
問題は、ネットワークのトレーニング結果を
スキュー巨大な飛び地にあった。

44
00:03:10.960 --> 00:03:15.120
従ってランクおよび力の変形はこの問題の処
理を助けた。

45
00:03:16.566 --> 00:03:19.990
それに決定を後押しすることで漸進的である
メタ特徴を作り出した後

46
00:03:19.990 --> 00:03:21.230
ニューラルネットワーク、

47
00:03:21.230 --> 00:03:26.280
我々は、次のレベルのモデルを支援するため
にそれらの賃金上昇の違いを計算した。

48
00:03:26.280 --> 00:03:30.570
これはまた、モデルを強制的に興味深いトリ
ックであることに注意してください

49
00:03:30.570 --> 00:03:35.290
最初のレベルのモデルの予測の違いを活用す
る。

50
00:03:35.290 --> 00:03:40.370
ここでは、最も近い近傍に基づいてフィーチ
ャの2つのデータセットを編集します。

51
00:03:40.370 --> 00:03:45.380
1つはレベル0から直接取得され、同じ機能
が含まれています。

52
00:03:45.380 --> 00:03:51.040
しかし、それは、平均符号化されたデータセ
ットで半分の力に計算しました。

53
00:03:51.040 --> 00:03:55.704
ここでのポイントは、これらの機能が完全に
利用されていないということでした

54
00:03:55.704 --> 00:03:57.370
最初のレベルのモデル。

55
00:03:57.370 --> 00:04:02.690
そして確かに、彼らはこのレベルに情報の新
しい部分をもたらした。

56
00:04:03.740 --> 00:04:08.850
今、我々はすでに最初のレベルから自動フォ
ールディング折り曲げる予測を持っていると

57
00:04:08.850 --> 00:04:11.110
我々はそれらのモデルを訓練します。

58
00:04:11.110 --> 00:04:16.230
他の民族のせいで標的が漏れる

59
00:04:16.230 --> 00:04:18.610
また、機能が非常によくないため、

60
00:04:18.610 --> 00:04:23.600
モデルが検出するデータには、ほとんどパタ
ーンが残っていません。

61
00:04:23.600 --> 00:04:29.160
我々は、予測は多様であるべきであることを
念頭に置き、単純な分類器を選んだ。

62
00:04:29.160 --> 00:04:31.670
4種類のモデルを使用しました。

63
00:04:31.670 --> 00:04:34.780
勾配ブーストデシジョンツリー,
ニューラルネットワーク,

64
00:04:34.780 --> 00:04:38.710
ランダムフォレストとロジスティック回帰。

65
00:04:38.710 --> 00:04:42.289
だから、このすべての2番目のレベルのモデ
ルです。

66
00:04:43.340 --> 00:04:48.410
そして最後に、我々は2番目のレベルのモデ
ルのあなたの組み合わせでリニアを取った。

67
00:04:48.410 --> 00:04:54.770
線形モデルは、我々は推定係数に傾いていな
いので、

68
00:04:54.770 --> 00:04:59.890
直接これらの4つの予測とデータを投げるた
めの我々のターゲットを使用します。

69
00:04:59.890 --> 00:05:01.450
だから、これは。

70
00:05:01.450 --> 00:05:06.244
我々は、この積み重ねスキームの各レベルを
経て、学生を行った。

71
00:05:06.244 --> 00:05:08.390
なぜ我々はこのような複雑さが必要ですか?

72
00:05:08.390 --> 00:05:13.795
別のモデルが異なるパターンを利用するので
、まあ、通常それは

73
00:05:13.795 --> 00:05:19.610
データでは、我々は1つの強大なモデルでは
、このパターンのすべてを団結したい。

74
00:05:19.610 --> 00:05:22.930
そして積み重ねは私達のためのそれを丁度す
ることができる。

75
00:05:22.930 --> 00:05:24.970
これはあまりにも複雑に見えるかもしれませ
ん。

76
00:05:24.970 --> 00:05:29.480
もちろん、それは競争の中でスキームのこの
種の上に移動するのに時間がかかります。

77
00:05:29.480 --> 00:05:32.630
しかし、私たちのコースを完了した後、必ず

78
00:05:32.630 --> 00:05:37.310
あなたはすでにこれを行う方法について十分
な知識を持っている。

79
00:05:37.310 --> 00:05:41.580
これらのスキームは、コンペティションの開
始時に最終的な形状には表示されません。

80
00:05:41.580 --> 00:05:44.800
ほとんどの仕事は、通常、最初のレベルで行
われます。

81
00:05:44.800 --> 00:05:51.770
だから、多様なメタ機能を作成しようとする
と、1つのシンプルモデルでそれらを団結。

82
00:05:51.770 --> 00:05:56.880
通常、あなたは、スタッキングの高品位第二
レベルを作成し始める

83
00:05:56.880 --> 00:05:59.362
数日しか残っていないとき。

84
00:05:59.362 --> 00:06:04.480
そして、その後、主にこのスキームの改善に
取り組んでいます。

85
00:06:04.480 --> 00:06:08.262
そうは言っても、あなたはすでに必要な知識
と

86
00:06:08.262 --> 00:06:11.570
今、あなたはちょうどそこにいくつかの練習
を取得する必要があります。

87
00:06:11.570 --> 00:06:16.594
勤勉であり、疑いもなく、あなたは成功しま
す。

88
00:06:16.594 --> 00:06:18.964
音

89
00:06:18.964 --> 00:06:28.964
音楽


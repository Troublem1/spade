1
00:00:00.000 --> 00:00:03.929
音楽

2
00:00:03.929 --> 00:00:04.922
みなさん。

3
00:00:04.922 --> 00:00:08.195
このビデオでは、Crowdflower
の競争を分析します。

4
00:00:08.195 --> 00:00:12.513
私たちは、私は、スタニスラフセミョーノフ
とドミトリー Altukhov
を意味するチームとして参加し、

5
00:00:12.513 --> 00:00:14.140
2位になった。

6
00:00:14.140 --> 00:00:19.000
私はいくつかの詳細と一緒に私たちのソリュ
ーションの最も重要な部分を説明します。

7
00:00:19.000 --> 00:00:21.035
ビデオの概要は以下の通りです。

8
00:00:21.035 --> 00:00:24.815
まず、コンテスト自体について教えていただ
きますと、どのようなデータや

9
00:00:24.815 --> 00:00:26.172
メトリックが提供された。

10
00:00:26.172 --> 00:00:29.490
その後、我々はアプローチ、機能とトリック
が議論されます。

11
00:00:29.490 --> 00:00:33.899
そして、私はどのような競争のためのルック
の種類に価値がある要約されます。

12
00:00:33.899 --> 00:00:37.059
競争のいくつかは CrowdFlower
会社によって組織された。

13
00:00:37.059 --> 00:00:41.131
この競争の目的は、指定された検索結果の関
連性を測定することです

14
00:00:41.131 --> 00:00:45.690
生きている e コマースサイトからのクエ
リと結果の製品の説明。

15
00:00:45.690 --> 00:00:49.558
タスクは、検索アルゴリズムの精度を評価す
ることです。

16
00:00:49.558 --> 00:00:52.812
競争の挑戦は、関連性のスコアを予測するこ
とです

17
00:00:52.812 --> 00:00:54.730
特定のクエリと問題の説明。

18
00:00:55.840 --> 00:00:59.543
画像では、クエリを持っている査定者のユー
ザーインターフェイスを、参照してください

19
00:00:59.543 --> 00:01:02.386
検索クエリ、およびアイテムに関するいくつ
かの情報。

20
00:01:02.386 --> 00:01:07.517
審査員は、各クエリの製品を1のスコアをペ
アリングするように求められた

21
00:01:07.517 --> 00:01:13.572
2、3、または4、4の項目を完全に検索ク
エリを満足を示すと、

22
00:01:13.572 --> 00:01:16.703
と1項目が一致しないことを示します。

23
00:01:16.703 --> 00:01:21.103
トレーニングデータとして、我々は、これら
のスコアの中央値と分散を持っています。

24
00:01:21.103 --> 00:01:24.378
データセットは、3つのテキストフィールド
、要求クエリ、

25
00:01:24.378 --> 00:01:27.586
結果と製品のタイトル、および製品の説明、

26
00:01:27.586 --> 00:01:31.698
と2つの列のターゲットに関連する、中央値
とスコアの分散。

27
00:01:31.698 --> 00:01:35.643
アルゴリズムが任意の HTML スニペッ
トを処理するのに十分な堅牢であることを確
認するには

28
00:01:35.643 --> 00:01:39.976
現実の世界では、プログラムの説明フィール
ドで提供されるデータは、raw と

29
00:01:39.976 --> 00:01:43.550
製品に関連するアクセス許可が含まれる場合
があります。

30
00:01:43.550 --> 00:01:47.077
たとえば、テキストまたはオブジェクト
id の文字列。

31
00:01:47.077 --> 00:01:51.686
手ラベルを阻止するために、実際のセットは
余分データと増強された。

32
00:01:51.686 --> 00:01:54.298
この追加データは、パブリックおよび

33
00:01:54.298 --> 00:01:56.990
プライベートスコアボードのスコアが計算さ
れました。

34
00:01:56.990 --> 00:02:00.314
そしてもちろん、キャンペーンのスコアは、
我々はすでに持っていたオブジェクトを考え
ている

35
00:02:00.314 --> 00:02:01.739
スコアを計算するために使用します。

36
00:02:01.739 --> 00:02:07.042
だから我々は、電車の中で1万サンプルを持
っているとテストで2万が、それは良いデー
タです。

37
00:02:07.042 --> 00:02:09.007
私は、検証がうまく動作し、意味

38
00:02:09.007 --> 00:02:12.646
ローカルスコアは、ランキングスコアに十分
に近いです。

39
00:02:12.646 --> 00:02:17.860
効果的なソリューションは、非標準メトリッ
クは、二次加重カッパを使用した。

40
00:02:17.860 --> 00:02:19.774
それを詳しく見てみましょう。

41
00:02:19.774 --> 00:02:24.990
[コンペティションの評価] ページでは、
メトリックの詳細な説明を確認できます。

42
00:02:24.990 --> 00:02:29.610
我々はすでに我々のコースでは、メトリック
を議論しているが、私はそれを思い出してみ
ましょう。

43
00:02:29.610 --> 00:02:33.195
提出物は、測定する二次加重カッパに基づい
て採点される

44
00:02:33.195 --> 00:02:34.912
2つの評価間の合意。

45
00:02:34.912 --> 00:02:39.290
このメトリックは、通常、0から上昇します
, 評定間のランダムな合意, へ 1,

46
00:02:39.290 --> 00:02:41.275
評定間の完全な一致。

47
00:02:41.275 --> 00:02:46.402
評定との間の合意がランダムで予想より少な
い場合には、

48
00:02:46.402 --> 00:02:48.256
メトリックは0を下回ることがあります。

49
00:02:48.256 --> 00:02:50.301
メトリックを理解するために、

50
00:02:50.301 --> 00:02:53.243
それを計算する方法の例を考えてみましょう
。

51
00:02:53.243 --> 00:02:57.911
まず、n の混乱行列 C
を構築し、正規化の n が必要です。

52
00:02:57.911 --> 00:03:03.342
その障害、または水平方向の予測エラーによ
って私たちの縦軸。

53
00:03:03.342 --> 00:03:07.120
この例では、N は可能な評価の数として4
に等しくなります。

54
00:03:08.390 --> 00:03:11.869
第2に、期待される行列 E の n
個のヒストグラム行列に n が必要です。

55
00:03:11.869 --> 00:03:16.683
これは、評価コストの間に相関関係がないと
仮定して計算されます。

56
00:03:16.683 --> 00:03:21.460
これは、評価のヒストグラムベクトル内とし
て計算されます。

57
00:03:21.460 --> 00:03:24.386
また、我々は、重みの n 行列によって
n を必要とする, W,

58
00:03:24.386 --> 00:03:28.357
要素の位置に基づいて計算されます。

59
00:03:28.357 --> 00:03:33.516
重みのこの特定の数式は、インデックスの間
の平方距離を使用します。

60
00:03:33.516 --> 00:03:37.753
j ので、このメソッドは、二次加重カッパ
と呼ばれる理由です。

61
00:03:37.753 --> 00:03:42.248
最後に、カッパは、この加重合計の1つのマ
イナス分数として計算することができます

62
00:03:42.248 --> 00:03:44.530
分子内の混乱行列の,

63
00:03:44.530 --> 00:03:48.073
分母の期待値行列の重み付き和.

64
00:03:48.073 --> 00:03:52.475
私は、カッパは、分類の損失と同様のプロパ
ティを持っていることに気づきたい

65
00:03:52.475 --> 00:03:53.508
回帰損失。

66
00:03:53.508 --> 00:03:55.122
もっと遠いと予測し、

67
00:03:55.122 --> 00:03:57.921
真の評価は、より多くの罰則があるでしょう
。

68
00:03:57.921 --> 00:04:03.274
そのことを覚えて、我々は後で私たちのビデ
オでそれを使用します。

69
00:04:03.274 --> 00:04:05.913
さて、今私のチームのソリューションについ
て話をしましょう。

70
00:04:05.913 --> 00:04:09.253
これは、いくつかの部分で構成され、非常に
複雑であることが判明した。

71
00:04:09.253 --> 00:04:13.598
クエリの拡張、クエリごとのモデル、バンパ
ー機能などのようになります。

72
00:04:13.598 --> 00:04:15.951
要点をお伝えします。

73
00:04:15.951 --> 00:04:18.969
それでは、テキスト機能から始めましょう。

74
00:04:18.969 --> 00:04:23.573
3つのテキストフィールド、クエリ、タイト
ル、および説明があります。

75
00:04:23.573 --> 00:04:26.587
あなたは私たちのコースで議論するすべての
テクニックを適用することができます

76
00:04:26.587 --> 00:04:28.845
類似性の様々な対策を計算します。

77
00:04:28.845 --> 00:04:30.917
まさに私たちがやったことです。

78
00:04:30.917 --> 00:04:35.209
これは、クエリのタイトルとクエリの説明の
ペアについては、我々は数を計算

79
00:04:35.209 --> 00:04:39.108
魔法の言葉の, TF-IDF
の表現間のコサイン距離,

80
00:04:39.108 --> 00:04:43.551
平均 word2vec ベクトルと
Levensthein 距離の間の距離。

81
00:04:43.551 --> 00:04:47.128
実際には、これはに使用する必要があります
機能の標準的なセットです。

82
00:04:47.128 --> 00:04:47.980
同様のタスク。

83
00:04:47.980 --> 00:04:50.253
そして、未処理のものはありません。

84
00:04:50.253 --> 00:04:52.500
サポートはベースラインとして考慮する必要
があります。

85
00:04:52.500 --> 00:04:55.091
そして今、私たちは面白いことに向ける。

86
00:04:55.091 --> 00:04:58.475
さらに、我々はそれが象徴的な n-グラム
を使用するために有用であることがわかった
。

87
00:04:58.475 --> 00:05:01.815
あなたは彼らと同じように、ワードベースで
作業することができます

88
00:05:01.815 --> 00:05:05.410
各文字が個別の単語として解釈される場合。

89
00:05:05.410 --> 00:05:08.810
我々は、1つの文字から、5文字に象徴的
n-グラムを使用します。

90
00:05:08.810 --> 00:05:13.642
n グラムの大規模なパースメトリックを取
得した後、我々は彼らにそれを適用し、

91
00:05:13.642 --> 00:05:16.717
機能として300の組み合わせに近いだけだ
った。

92
00:05:16.717 --> 00:05:20.922
あなたは我々のコースのこの部分を議論覚え
て、例があります。

93
00:05:20.922 --> 00:05:24.461
我々は3つの興味深いプロパティに気づくの
データを見て。

94
00:05:24.461 --> 00:05:29.636
クエリは非常に短いですが、ユニークなクエ
リの数は261、

95
00:05:29.636 --> 00:05:33.550
とクエリは、列車とテストセットで同じです
。

96
00:05:33.550 --> 00:05:37.617
我々は、クエリの拡張バージョンを構築する
ために、これらの観測を使用することを決め
た

97
00:05:37.617 --> 00:05:38.357
次のように。

98
00:05:38.357 --> 00:05:41.999
各クエリでは、最も関連性の高い対応する項
目を取得し、

99
00:05:41.999 --> 00:05:44.095
関連性のあるものは4つに等しい。

100
00:05:44.095 --> 00:05:47.996
我々は、関連する項目のタイトルからすべて
の単語に参加し、

101
00:05:47.996 --> 00:05:50.077
10の最も人気のある単語を取る。

102
00:05:50.077 --> 00:05:52.159
これは、拡張クエリと呼ばれるものであり、

103
00:05:52.159 --> 00:05:55.782
これは、前述したすべてのテキスト機能を構
築するために使用されます。

104
00:05:55.782 --> 00:05:59.584
このトリックは、コンテキストフレームワー
ク内でのみ適用可能であることに注意してく
ださい。

105
00:05:59.584 --> 00:06:03.709
テストのクエリは、正確に電車の中で同じで
あるという事実のために。

106
00:06:03.709 --> 00:06:05.485
実生活では、我々はそうすることができなか
った

107
00:06:05.485 --> 00:06:10.258
すべての検索クエリに関連する結果を無視す
るのは非現実的です。

108
00:06:10.258 --> 00:06:13.980
列車とテストでクエリのセットが同じである
という事実、

109
00:06:13.980 --> 00:06:18.379
私たちは多くの小さなサブタスクに私たちの
問題を分割する機会を与えます。

110
00:06:18.379 --> 00:06:22.027
具体的には、各クエリについて、別のモデル
を構築することができます

111
00:06:22.027 --> 00:06:24.977
対応する項目の関連性のみを予測します。

112
00:06:24.977 --> 00:06:29.918
もう一度、実生活では、このようなトリック
を適用することはできませんが、コンテキス
トの枠組みの中で、

113
00:06:29.918 --> 00:06:31.099
それは全く問題ありません。

114
00:06:31.099 --> 00:06:34.490
したがって、一意のクエリごとに、対応する
サンプルを取得し、

115
00:06:34.490 --> 00:06:38.614
仕事の類似性、前後のプレゼンテーションを
動作するように計算し、

116
00:06:38.614 --> 00:06:40.489
ランダムな4番目の分類子に合わせます。

117
00:06:40.489 --> 00:06:45.022
最後に、我々は予測が使用された261モデ
ルを持っている

118
00:06:45.022 --> 00:06:47.120
最後の例の機能。

119
00:06:47.120 --> 00:06:51.373
すべての製品項目は、いくつかの人々によっ
てであることを忘れないでください。

120
00:06:51.373 --> 00:06:53.543
評価の分散の中央値。

121
00:06:53.543 --> 00:06:57.000
評価の差異表示は矛盾しています。

122
00:06:57.000 --> 00:06:59.367
直感的に、分散が大きい場合は、

123
00:06:59.367 --> 00:07:03.435
その後、そのようなオブジェクトは、より小
さい重量で考慮する必要があります。

124
00:07:03.435 --> 00:07:08.018
それを行う1つの方法は、クエリの回答に応
じて項目の重みを割り当てることです。

125
00:07:08.018 --> 00:07:11.822
これは、重量としてヒューリスティック
1/1 + 分散された。

126
00:07:11.822 --> 00:07:15.316
別の方法は、中央値を使用して個々の観測を
復元することです

127
00:07:15.316 --> 00:07:16.509
差異の統計。

128
00:07:16.509 --> 00:07:19.267
我々は、3つの審査員があると仮定すること
がわかった

129
00:07:19.267 --> 00:07:22.536
我々は、ほぼ常に確かに元のラベルを復元す
ることができます。

130
00:07:22.536 --> 00:07:26.112
例えば、我々は3に等しい中央値を持ってい
る場合、および

131
00:07:26.112 --> 00:07:31.152
分散は0.66
に等しく、そこはもちろん、2、3、4、

132
00:07:31.152 --> 00:07:36.307
これは、このアプローチによって、各ソース
のサンプルでは、3回生成されます。

133
00:07:36.307 --> 00:07:39.737
しかし、トレーニングデータとしてそれらを
使用すると、訓練に時間がかかった

134
00:07:39.737 --> 00:07:41.206
スコアを改善しなかった。

135
00:07:41.206 --> 00:07:45.812
そして、単純なヒューリスティックは非常に
よく動作し、彼らは最終解決策でそれを使用
してください。

136
00:07:45.812 --> 00:07:49.951
競争では、メトリックを選択する必要がある
、我々はクラスを予測する必要があります

137
00:07:49.951 --> 00:07:52.359
しかし、エラーのペナルティは対称ではあり
ません。

138
00:07:52.359 --> 00:07:54.267
我々はそれを考慮に入れることに決めた

139
00:07:54.267 --> 00:07:58.987
クラス間に人工的に作成された複数のバイナ
リ区切り記号をフィーチャとして追加する。

140
00:07:58.987 --> 00:08:02.701
言い換えれば、我々は、質問に答えるために
分類しようとしている

141
00:08:02.701 --> 00:08:07.280
ターゲットクラスの数が1より大きい、2よ
り大きい、などが true です。

142
00:08:07.280 --> 00:08:12.517
これらの機能は、クラス間のセパレータの一
種であるため、バンパーと呼びます。

143
00:08:12.517 --> 00:08:17.803
我々は、代わりに予測を構築する方法と同様
に、ファッションでそれらを構築します。

144
00:08:17.803 --> 00:08:21.099
それは最終的な解決のために非常に有用だっ
た。

145
00:08:21.099 --> 00:08:23.857
すべての記載された機能は、アンサンブルで
使用されます。

146
00:08:23.857 --> 00:08:26.531
我々は、機能の異なるサブセットにいくつか
のモデルを構築する。

147
00:08:26.531 --> 00:08:30.941
いくつかは、SVM のような比較的単純な
感じ、いくつかは非常に複雑に見える.

148
00:08:30.941 --> 00:08:33.830
私が作成した複雑なモデルの部分を見ること
ができます。

149
00:08:33.830 --> 00:08:37.474
これは、バンパーの機能を使用して、類似点
のすべての種類と

150
00:08:37.474 --> 00:08:40.431
さまざまな組み合わせのクエリ機能。

151
00:08:40.431 --> 00:08:42.756
frostage
モデルもたくさんありますが、

152
00:08:42.756 --> 00:08:45.862
これはセカンドステージのランダムフォレス
トと混同されています。

153
00:08:45.862 --> 00:08:50.124
実際には、チームの各参加者は、彼自身のモ
デルを作ったし、

154
00:08:50.124 --> 00:08:54.473
競争我々は単に最終的な提出のために我々の
モデルを直線的に混合した。

155
00:08:54.473 --> 00:08:58.222
一方のメトリックは、いくつかの適切な分類
を持っていることを覚えてみましょう

156
00:08:58.222 --> 00:09:00.110
クラスを予測する必要があります。

157
00:09:00.110 --> 00:09:04.445
しかし、回帰の答えは、我々はもっと分析す
ることができます。

158
00:09:04.445 --> 00:09:07.009
回帰モデルを構築しましたが、

159
00:09:07.009 --> 00:09:11.266
我々は何とかクラスに実際の値の予測を有効
にする必要がありました。

160
00:09:11.266 --> 00:09:16.461
との簡単なアプローチは、我々はしきい値を
拾うことにしたので、不完全に動作します。

161
00:09:16.461 --> 00:09:17.971
目的のために、我々は正しかった。

162
00:09:17.971 --> 00:09:21.911
しきい値を選択し、クロス検証スコアに重み
付けされた最適な1つを選びます。

163
00:09:21.911 --> 00:09:26.208
バフの手順は、私たちの品質の非常に重要な
増加を与えた。

164
00:09:26.208 --> 00:09:30.635
実際にはそれが頻繁に非標準的な指標との競
争で起こる [聞こえない]

165
00:09:30.635 --> 00:09:34.201
等級対称最適化は大幅な改善をもたらします
。

166
00:09:34.201 --> 00:09:35.545
だから、合計してみましょう。

167
00:09:35.545 --> 00:09:38.679
競争の中で、それは本当に [聞こえない]
のアイデアを使用することが重要だった。

168
00:09:38.679 --> 00:09:42.850
最初の記号とグラム、1回以来、彼らは大幅
な増加を与える

169
00:09:42.850 --> 00:09:46.024
スコアとそれはあなたがそれを使用する必要
が解決されませんでした。

170
00:09:46.024 --> 00:09:50.326
第二に、このコースの大幅な増加につながっ
たクエリの拡大。

171
00:09:50.326 --> 00:09:54.508
また、しきい値の最適化は、ソリューション
の重要な部分でした。

172
00:09:54.508 --> 00:09:57.721
私はあなたの競争の中で、これらのトリック
のいくつかを再利用することを願っています
。

173
00:09:57.721 --> 00:09:59.782
注意していただきありがとうございます。

174
00:09:59.782 --> 00:10:09.782
音楽


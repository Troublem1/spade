1
00:00:00.000 --> 00:00:03.229
音楽

2
00:00:03.229 --> 00:00:04.906
こんにちは、このビデオでは、

3
00:00:04.906 --> 00:00:10.640
私はマイクロソフトのマルウェアの分類の課
題について教えてくれます。

4
00:00:10.640 --> 00:00:15.413
我々は、このコースの他の講師とチームに参
加していた,

5
00:00:15.413 --> 00:00:18.391
ミハイル・トロフィモフとスタニスラフセミ
ョーノフ

6
00:00:18.391 --> 00:00:21.610
この大会で3位になった

7
00:00:22.710 --> 00:00:24.512
プレゼンテーションのためのプランは以下の
とおりです。

8
00:00:24.512 --> 00:00:28.970
私たちは、データの説明と少しの描から始め
ます。

9
00:00:28.970 --> 00:00:32.392
次に、フィーチャの抽出について説明します
。

10
00:00:32.392 --> 00:00:37.444
次に、機能の処理と選択の方法について説明
します。

11
00:00:37.444 --> 00:00:40.684
我々はどのようにモデリングを行ったが表示
されます、そして最終的に我々は

12
00:00:40.684 --> 00:00:45.200
私たちは、ボードのリーグで高くなることが
できたいくつかのトリックを説明します。

13
00:00:46.400 --> 00:00:48.240
それでは、問題の説明から始めましょう。

14
00:00:49.740 --> 00:00:50.460
この大会では、

15
00:00:50.460 --> 00:00:54.450
我々は、悪意のあるソフトウェア実行可能フ
ァイルのテラバイトの約半分を提供します。

16
00:00:55.470 --> 00:00:58.200
各実行可能ファイルは2つの形式で表されま
す。

17
00:00:59.310 --> 00:01:01.150
最初は、16進数のダンプです。

18
00:01:02.230 --> 00:01:09.490
16進数のダンプは、単にバイトのシーケン
スとしてファイルの表現であり、それは行の
形式です。

19
00:01:09.490 --> 00:01:12.730
ディスク上のファイルがシーケンスとして格
納されているか、

20
00:01:12.730 --> 00:01:15.940
バイト、それは正確に我々は16進数のダン
プに表示されます。

21
00:01:17.530 --> 00:01:24.290
2番目の形式は、対話型逆アセンブラー、ま
たは IDA
によって生成された一覧です。

22
00:01:25.310 --> 00:01:30.130
IDA は、16進数のダンプから低レベル
のバイトシーケンスを変換しようとします。

23
00:01:30.130 --> 00:01:33.540
アセンブラ列のシーケンスにします。

24
00:01:33.540 --> 00:01:35.380
下のスクリーンショットを見てみましょう。

25
00:01:35.380 --> 00:01:39.170
左側には、16進数のダンプからのバイトシ
ーケンスが表示されます。

26
00:01:39.170 --> 00:01:43.980
そして、右側に、私たちは、IDA がそれ
らを変換したものを参照してください。

27
00:01:45.640 --> 00:01:50.320
タスクは、9つの家族にマルウェアのファイ
ルを分類することでした。

28
00:01:50.320 --> 00:01:55.751
私達は知られていたラベルが付いている約1
万例の列車セットを提供する

29
00:01:55.751 --> 00:01:58.089
と特異サイズのテストセット。

30
00:01:58.089 --> 00:02:02.149
また、評価指標は複数クラスの対数損失であ
った。

31
00:02:03.260 --> 00:02:07.370
この競争の最終的な損失は非常に、非常に低
かったことに注意してください。

32
00:02:07.370 --> 00:02:14.530
対応する精度は、99.7%
以上であった、それは非常に高い精度です。

33
00:02:15.680 --> 00:02:20.480
メタデータを調べることが有益であることを
覚えておいてください。

34
00:02:20.480 --> 00:02:24.760
この大会では、ファイルを7つの zip
アーカイブを与えられた。

35
00:02:24.760 --> 00:02:27.960
また、ファイル名はハッシュ値のように見え
ます。

36
00:02:29.220 --> 00:02:33.840
実際には、我々のモデルの任意の有用なメタ
データを見つけることができませんでしたが
、

37
00:02:33.840 --> 00:02:38.080
どのように列車のテストの分割は、主催者に
よって行われた面白かった。

38
00:02:39.230 --> 00:02:44.340
主催者は、分割のためのファイル名の最初の
文字を使用していた。

39
00:02:45.630 --> 00:02:52.090
このプロットでは、x 軸に、ファイル名の
最初の文字が表示されます。

40
00:02:52.090 --> 00:02:53.270
y 軸については、

41
00:02:53.270 --> 00:02:57.870
我々は、指定された文字で始まる、その名前
を持つファイルの数を持っています。

42
00:02:59.180 --> 00:03:04.350
プロットは、実際にクールに見えるが、我々
は彼らから取得する唯一の情報

43
00:03:04.350 --> 00:03:09.170
電車のテストの分割は、実際にはランダムで
あり、

44
00:03:09.170 --> 00:03:12.150
我々は、モデルを改善するためにそれらを使
用することはできません。

45
00:03:13.580 --> 00:03:16.969
だから、この競争の中で我々は生のデータを
与えられたので、

46
00:03:16.969 --> 00:03:20.130
我々は、機能を自分自身を抽出する必要があ
りました。

47
00:03:21.210 --> 00:03:22.630
我々が抽出した機能を見てみましょう。

48
00:03:24.930 --> 00:03:28.690
まあ、実際には、私たちのチームから誰もド
メインの知識や

49
00:03:28.690 --> 00:03:31.720
マルウェア分類の以前の経験。

50
00:03:31.720 --> 00:03:35.290
我々は、IDA
の分解が何であるかさえ知りませんでした。

51
00:03:35.290 --> 00:03:37.823
だから我々は本当に簡単に始めた。

52
00:03:37.823 --> 00:03:43.710
データセット内の実行可能ファイルは、2つ
の形式で表されています。

53
00:03:43.710 --> 00:03:48.700
だから私たちの最初の2つの機能は、これら
のファイルのサイズ、または

54
00:03:48.700 --> 00:03:50.670
同等の長さ。

55
00:03:50.670 --> 00:03:56.810
そして、驚くべきことに、これらの2つの機
能を使用するだけで 88%
の精度を得た。

56
00:03:57.980 --> 00:04:03.460
プロットでは、x 軸は列車セット内のオブ
ジェクトのインデックスに対応しています。

57
00:04:03.460 --> 00:04:06.500
ここでは、オブジェクトをクラスごとに並べ
替えています。

58
00:04:06.500 --> 00:04:13.608
y 軸には、すべてのオブジェクトの
aHEX ダンプファイルのファイルサイズ
が表示されます。

59
00:04:13.608 --> 00:04:16.857
そして、我々はこの機能は非常に指示されて
参照してください。

60
00:04:16.857 --> 00:04:21.095
我々はシーケンスのうち派生することが最も
簡単な機能

61
00:04:21.095 --> 00:04:24.920
その要素のアカウントですよね?

62
00:04:24.920 --> 00:04:29.490
だから、これは基本的にどのような関数の値
はパンダから来ています。

63
00:04:29.490 --> 00:04:32.120
だから私たちがしたことです。

64
00:04:32.120 --> 00:04:39.267
我々は、16進数のダンプファイルのバイト
を数え、それは我々が257の機能を取得す
る方法です。

65
00:04:39.267 --> 00:04:44.839
そして、257は256バイトの値を持って
いるので、

66
00:04:44.839 --> 00:04:48.697
そして1つの特別な記号があった。

67
00:04:48.697 --> 00:04:53.329
これらの機能を使用して、ほぼ 99%
の精度を達成しました。

68
00:04:53.329 --> 00:04:57.120
このアセンブリ形式について読み始めたのと
同時に、

69
00:04:57.120 --> 00:04:59.700
マルウェアの分類に関する論文。

70
00:04:59.700 --> 00:05:02.550
そのため、どのような機能が生成されるかを
考えました。

71
00:05:03.960 --> 00:05:06.500
このアセンブリファイルを調べました。

72
00:05:06.500 --> 00:05:10.010
正規表現を使って様々なものを抽出していま
す。

73
00:05:10.010 --> 00:05:13.626
我々が抽出した機能の多くはすぐに捨てられ
た,

74
00:05:13.626 --> 00:05:14.950
いくつかは本当に良かった。

75
00:05:14.950 --> 00:05:20.010
そして、我々は実際に最初にやった、我々は
システムコールを数えた。

76
00:05:20.010 --> 00:05:22.201
あなたは、スライド上で参照してください、

77
00:05:22.201 --> 00:05:27.590
また、Windows の API
呼び出しとも呼ばれます。

78
00:05:27.590 --> 00:05:32.768
そして、ここでは、この機能で得たエラー率
は、それはかなり良いです。

79
00:05:32.768 --> 00:05:37.897
我々は、移動、プッシュのようなアセンブラ
コモンズを数え、

80
00:05:37.897 --> 00:05:42.920
目標とアセンブラ、彼らはむしろうまく動作
します。

81
00:05:42.920 --> 00:05:48.090
我々はまた、共通のエンドグラムのような共
通のシーケンスを抽出しようとすると

82
00:05:48.090 --> 00:05:52.340
それらのうちの機能を抽出するが、我々は良
い結果を得るために管理していない。

83
00:05:53.620 --> 00:05:57.110
我々が持っていた最高の機能は、セクション
数だった。

84
00:05:58.290 --> 00:06:01.060
このアセンブリファイルの行数を数えるだけ
で、

85
00:06:01.060 --> 00:06:07.480
これは、text または data、また
はそのようなもので始まります。

86
00:06:07.480 --> 00:06:12.305
その特徴を持つ分類の正確さは、使用して
99% 以上であった

87
00:06:12.305 --> 00:06:13.485
これらの機能。

88
00:06:13.485 --> 00:06:21.010
これらのすべてを組み込むことにより、我々
は 0.5%
未満のエラー率を得ることができた。

89
00:06:21.010 --> 00:06:22.924
私たちのテキストマイニングの経験から、

90
00:06:22.924 --> 00:06:26.600
我々は、n-グラムは、良い識別機能である
ことを知っていた。

91
00:06:26.600 --> 00:06:28.690
だから我々は大きなグラムを計算した。

92
00:06:29.690 --> 00:06:33.794
我々は、4グラムを使用することを提案した
紙を発見した。

93
00:06:35.260 --> 00:06:41.970
我々も、それらを計算し、我々もさらに行っ
て、10グラムを抽出した。

94
00:06:41.970 --> 00:06:46.932
もちろん、我々は直接10グラムで動作する
ことができなかったので、我々は素晴らしい
を実行

95
00:06:46.932 --> 00:06:52.284
この競争のための最も創造的なアイデアの一
つであった機能の選択、。

96
00:06:52.284 --> 00:06:54.810
我々は、このビデオでどのように正確に我々
はそれをした後で表示されます。

97
00:06:56.040 --> 00:07:01.502
興味深いことに、ちょうど10グラムに機能
の選択を適用することにより、

98
00:07:01.502 --> 00:07:05.610
XGBoost のフィッティングでは、我
々はトップ30の場所を得ることができる。

99
00:07:05.610 --> 00:07:09.540
我々は興味深い発見もう一つの特徴は、エン
トロピーです。

100
00:07:09.540 --> 00:07:13.150
我々は、広いシーケンスの小さなセグメント
のエントロピーを計算した

101
00:07:13.150 --> 00:07:15.870
スライドウィンドウをシーケンスの上に移動
します。

102
00:07:15.870 --> 00:07:19.370
各ウィンドウ内のエントロピーを計算します
。

103
00:07:19.370 --> 00:07:22.420
だから別のシーケンスを持ってる

104
00:07:22.420 --> 00:07:27.700
実行可能ファイルの暗号化された部分に関す
る明示的な情報を格納します。

105
00:07:27.700 --> 00:07:32.890
を参照してください、我々は、データが暗号
化されている場合、エントロピーが高いこと
を期待

106
00:07:32.890 --> 00:07:36.355
圧縮し、データが構造化されている場合は低
い。

107
00:07:38.110 --> 00:07:44.020
ので、動機は、いくつかのマルウェアは、通
常の実行可能ファイルに注入され、

108
00:07:44.020 --> 00:07:46.880
暗号化された形式で保存されます。

109
00:07:48.090 --> 00:07:52.520
プログラムが起動すると、マルウェアは、最
初にバックグラウンドで自分自身を抽出し、

110
00:07:52.520 --> 00:07:53.428
を実行します。

111
00:07:53.428 --> 00:07:58.289
だからエントロピーの機能は、私たちが検出
するのに役立つかもしれない

112
00:07:58.289 --> 00:08:02.394
実行可能ファイル内のトロイの木馬を暗号化
し、

113
00:08:02.394 --> 00:08:06.080
したがって、マルウェアのいくつかのクラス
を検出します。

114
00:08:07.160 --> 00:08:11.960
しかし、我々は可変長のエントロピーシーケ
ンスを得た。

115
00:08:11.960 --> 00:08:16.070
これらのシーケンスを機能として使用するこ
とはできませんでした。

116
00:08:16.070 --> 00:08:22.910
そこで, 平均と中央値のようなエントロピ
ー分布の統計を生成した.

117
00:08:24.070 --> 00:08:28.580
また、我々は20パーセンタイルと逆パーセ
ンタイルを計算し、

118
00:08:28.580 --> 00:08:29.930
機能として使用します。

119
00:08:31.910 --> 00:08:36.994
同じ機能がエントロピーの変化から抽出され
た, 我々は最初のものです

120
00:08:36.994 --> 00:08:42.170
差分関数をエントロピー系列に適用し、統計
を計算します。

121
00:08:42.170 --> 00:08:47.674
を探して16進数のダンプから3つのものを
抽出することができた

122
00:08:47.674 --> 00:08:51.716
0要素で終わる印刷可能なシーケンス。

123
00:08:51.716 --> 00:08:57.600
文字列自体は使用しませんでしたが、文字列
の長さを計算しました。

124
00:08:57.600 --> 00:09:00.820
各ファイルの配布と同様の統計情報を抽出し
、

125
00:09:00.820 --> 00:09:04.597
エントロピー系列から抽出した統計。

126
00:09:05.670 --> 00:09:08.730
さて、我々は機能の抽出を終えた。

127
00:09:08.730 --> 00:09:12.950
それでは、事前にそれらを処理し、機能の選
択を実行する方法を見てみましょう。

128
00:09:14.280 --> 00:09:17.670
我々は多くの機能を生成したときにそれらの
瞬間。

129
00:09:17.670 --> 00:09:22.640
我々は、分類子にそれらのすべてを組み込む
ことを望んでいたが、我々は適合できません
でした

130
00:09:22.640 --> 00:09:27.700
我々は2万の機能を言う得たときに分類子を
効率的に。

131
00:09:29.710 --> 00:09:33.040
ほとんどの機能は、おそらく役に立たないで
しょうので、

132
00:09:33.040 --> 00:09:37.680
我々は、さまざまな機能の選択方法と変換技
術を試してみました。

133
00:09:38.840 --> 00:09:44.380
購入数の特徴を考えてみましょう。

134
00:09:44.380 --> 00:09:49.185
それらの257は、あまりないですが、おそ
らくまだ冗長性があります。

135
00:09:49.185 --> 00:09:53.610
非負行列分解, NMF を試みた.

136
00:09:53.610 --> 00:09:59.060
また、主成分分析である PCA
は、この冗長性を除去するために用いた。

137
00:10:00.150 --> 00:10:05.310
私は NMF と PCA の両方が
factorize
しようとしていることを思い出させる

138
00:10:05.310 --> 00:10:09.940
オブジェクトフィーチャ行列 x
を2つのローランク行列の積にします。

139
00:10:11.020 --> 00:10:13.710
あなたが考えることができるとして見つける

140
00:10:13.710 --> 00:10:18.510
フィーチャ空間内の基底ベクトルの数が少な
いため、すべてのオブジェクトを

141
00:10:18.510 --> 00:10:23.880
それらの基礎ベクトルの線形組合せによって
近似される。

142
00:10:23.880 --> 00:10:27.560
この近似係数は、次のように処理できます。

143
00:10:27.560 --> 00:10:29.090
各オブジェクトの新機能。

144
00:10:30.460 --> 00:10:35.415
NMF と PCA
の唯一の違いは、NMF
が必要とすることです

145
00:10:35.415 --> 00:10:40.570
床のランク行列のすべてのコンポーネントが
非負になります。

146
00:10:40.570 --> 00:10:44.339
基底ベクトルの数を15に設定し、

147
00:10:44.339 --> 00:10:49.280
ここでは、最初の2つの抽出フィーチャ間の
プロットを参照します。

148
00:10:49.280 --> 00:10:52.490
NMF 用と PCA 用のものです。

149
00:10:54.210 --> 00:10:59.280
従ってこれらは実際に最も重要な基礎ベクト
ルのための係数である。

150
00:11:00.400 --> 00:11:02.255
我々は、3d ベースのモデルを使用

151
00:11:02.255 --> 00:11:07.100
これは、NMF の機能は、多くの木のため
に優れていたことは明らかである。

152
00:11:07.100 --> 00:11:13.239
だから NMF は、データの非否定的な場
合には良い作品が不可欠です。

153
00:11:14.290 --> 00:11:18.150
そして私達の場合では私達は性質によって非
否定的である計算と、働いた。

154
00:11:19.326 --> 00:11:23.660
ほとんど何もしないで機能の別のパックを取
得する簡単なトリック

155
00:11:23.660 --> 00:11:26.390
データにログ変換を適用し、

156
00:11:26.390 --> 00:11:30.020
変換されたデータの NMF
を再度計算します。

157
00:11:31.470 --> 00:11:32.740
ここで起きたことを考えよう

158
00:11:34.050 --> 00:11:36.970
NMF の抗議は、もともと MSE
の法律を使用する

159
00:11:36.970 --> 00:11:39.620
それが造る近似の質を測定しなさい。

160
00:11:40.870 --> 00:11:47.420
この策略は、NMF が MSE から
RMSLE
に最適化する法律を暗示的に変えます。

161
00:11:48.660 --> 00:11:53.650
ちょうど RMSLE は、ログ領域に
MSE であることを思い出してください。

162
00:11:53.650 --> 00:11:58.550
だから今分解プロセスは、異なるものに注意
を払う

163
00:11:58.550 --> 00:12:02.640
別の損失のために、したがって、さまざまな
機能を生成します。

164
00:12:03.650 --> 00:12:07.330
我々は、4グラムの機能を選択する小さなパ
イプラインを使用していました。

165
00:12:07.330 --> 00:12:12.714
我々は、L1 正則化に線形 SVM
を適用し、まれな機能を削除

166
00:12:12.714 --> 00:12:15.630
このようなモデルは、機能を選択する傾向が
ある。

167
00:12:15.630 --> 00:12:20.472
そして、その後、我々は
thresholded
ランダムフォレスト機能

168
00:12:20.472 --> 00:12:25.953
importances は、唯一の131
機能の最終的な機能セットを取得することが
できます。

169
00:12:25.953 --> 00:12:30.210
パイプラインは10グラムと少し複雑だった
。

170
00:12:30.210 --> 00:12:34.659
最初に、ハッシュを使用して、元のフィーチ
ャの次元を再利用しました。

171
00:12:35.700 --> 00:12:39.200
私たちは実際には10グラムを計算しながら
、オンラインでした。

172
00:12:39.200 --> 00:12:44.281
その後、L1 定例化 SVM
に基づいて約800の機能を選択し、

173
00:12:44.281 --> 00:12:46.700
RandomForest
importances

174
00:12:46.700 --> 00:12:53.070
これは、我々は28の力に2の代わりに約8
00の機能を得た方法です。

175
00:12:53.070 --> 00:12:57.090
しかし、我々はさらに行った。

176
00:12:58.290 --> 00:13:00.150
これは、実際に私にとって最も興味深い部分
です。

177
00:13:01.410 --> 00:13:03.360
特徴選択の主な問題は、

178
00:13:03.360 --> 00:13:06.855
私がちょうど説明したことは、我々はそれを
やったということです

179
00:13:06.855 --> 00:13:11.670
我々はすでにその瞬間に持っていた他の機能
とは無関係に10グラム。

180
00:13:12.880 --> 00:13:15.730
選択した後、我々は本当に良い機能で終わる
ことができます。

181
00:13:15.730 --> 00:13:19.590
しかし、これらの機能は、同じ情報を含むこ
とができる

182
00:13:19.590 --> 00:13:22.100
我々はすでに他の機能を持っていた。

183
00:13:22.100 --> 00:13:26.590
そして、我々は実際に10グラムで私たちの
機能を向上させると思った。

184
00:13:26.590 --> 00:13:28.650
だからここでは、代わりにしたものです。

185
00:13:29.840 --> 00:13:32.170
我々は、のためのフォールド予測の生成

186
00:13:32.170 --> 00:13:35.910
列車は我々が持っていたすべての機能を使用
して設定します。

187
00:13:35.910 --> 00:13:41.770
我々は、真のクラスの予測確率でオブジェク
トをソートし、検索してみてください

188
00:13:41.770 --> 00:13:47.270
他のものから最もエラーが発生しやすいオブ
ジェクトを分離する機能。

189
00:13:48.320 --> 00:13:52.580
だから実際に、我々はそれのために別のモデ
ルを使用します。

190
00:13:52.580 --> 00:13:57.920
我々は、ラベル1を持つエラーが発生しやす
いオブジェクトを持つ新しいデータセットを
作成しました,

191
00:13:57.920 --> 00:14:00.600
とラベル0を持つ他の。

192
00:14:00.600 --> 00:14:02.820
我々は、ランダムな森林訓練

193
00:14:02.820 --> 00:14:07.440
選択した 14 10-グラム、まあ、実際
に正確にハッシュされます。

194
00:14:08.730 --> 00:14:11.620
我々は、リーダーボード上の素晴らしいパフ
ォーマンスの向上を持っていたとき

195
00:14:11.620 --> 00:14:14.690
これらの14の機能を組み込む。

196
00:14:14.690 --> 00:14:18.350
この方法は、実際にオーバーフィット回避を
断つために私たちを導くことができる

197
00:14:18.350 --> 00:14:20.940
しかし、それは幸いにもうまく働いた。

198
00:14:22.100 --> 00:14:23.540
モデリングを始めるぞ

199
00:14:25.320 --> 00:14:29.750
我々は通常、今のように我々は、この競争の
積み重ねを使用していない。

200
00:14:29.750 --> 00:14:33.210
この大会以降、やや人気となった。

201
00:14:33.210 --> 00:14:36.090
我々は、最初のどこにランダムな森を使用

202
00:14:36.090 --> 00:14:39.120
それはログの損失のためにキャリブレーショ
ンする必要があることが判明した。

203
00:14:39.120 --> 00:14:44.160
だから我々は XGBoost に切り替え
て、すべての私たちのモデリングのためにそ
れを使用。

204
00:14:45.550 --> 00:14:48.730
チーム内のすべての人が自分の特徴を抽出し
、

205
00:14:48.730 --> 00:14:51.820
独自のパラメータで自分のモデルを訓練した
。

206
00:14:51.820 --> 00:14:56.930
だから我々の最終的なソリューションは、多
様なモデルの組み合わせだった。

207
00:14:56.930 --> 00:15:00.456
我々は、このデータセットで非常によく働い
て袋詰めが見つかりました。

208
00:15:00.456 --> 00:15:05.550
私たちも非常に独特の方法で袋詰めをした。

209
00:15:05.550 --> 00:15:10.020
我々は、7倍の大規模なセットと私たちの双
子のセットを連結

210
00:15:10.020 --> 00:15:13.060
交換した列車セットからサンプリングされた
オブジェクト。

211
00:15:14.220 --> 00:15:15.690
そして、我々は、結果のデータセットを使用

212
00:15:16.970 --> 00:15:22.890
それは XGBoost を訓練するために
、元の列車セットより8倍大きい。

213
00:15:22.890 --> 00:15:26.360
もちろん、ランダム性を考慮して約20のモ
デルを平均しました。

214
00:15:28.300 --> 00:15:32.414
そして最後に、我々はこの大会で使用される
いくつかのより多くのトリックについて話し
ましょう。

215
00:15:33.690 --> 00:15:36.990
モデルの精度はかなり高かったし、

216
00:15:36.990 --> 00:15:40.840
我々は、すべてのより多くのデータは、より
良いが知っている。

217
00:15:40.840 --> 00:15:46.120
そこで、テストデータを使用してモデルをト
レーニングすることにしました。

218
00:15:47.340 --> 00:15:49.300
我々は、右のテスターのためのいくつかのラ
ベルが必要ですか?

219
00:15:50.570 --> 00:15:53.020
予測クラスを使用するか、

220
00:15:53.020 --> 00:15:56.150
予測されたクラス分布からラベルをサンプリ
ングします。

221
00:15:57.670 --> 00:16:02.148
生成されたテストセットのラベルは、通常、
擬似ラベルと呼ばれます。

222
00:16:03.170 --> 00:16:07.600
では、擬似ラベルでクロス検証を行うにはど
うすればよいでしょうか。

223
00:16:07.600 --> 00:16:11.560
我々は通常よく行うように我々はフォールド
に私たちの列車セットを分割

224
00:16:11.560 --> 00:16:12.300
クロス検証。

225
00:16:13.400 --> 00:16:15.890
この例では、2つのフォールドでデータを分
割します。

226
00:16:16.900 --> 00:16:21.400
しかし、クロス検証で異なるのは、今、モデ
ルを訓練する前に、

227
00:16:21.400 --> 00:16:25.680
特定の倍、我々はテストデータでこの倍を連
結することができます。

228
00:16:26.860 --> 00:16:29.730
その後、我々は、障害を切り替えると同じこ
とを行う。

229
00:16:30.880 --> 00:16:34.630
我々は緑の色と表記するオブジェクトを訓練
を参照してください

230
00:16:34.630 --> 00:16:36.730
赤で示したものを予測します。

231
00:16:37.840 --> 00:16:41.830
さて、テストセットの予測を取得するには、

232
00:16:41.830 --> 00:16:46.980
我々は再び、前のスライドのように、クロス
検証のことのようなことを行う。

233
00:16:46.980 --> 00:16:50.106
しかし、今では、テストセットをフォールト
で分割し、

234
00:16:50.106 --> 00:16:53.810
テストセットの各フォールドにセットされた
連結列車。

235
00:16:54.950 --> 00:17:00.430
最後に、我々はテストセットのすべての予測
から抜け出す、それは私たちの提出です。

236
00:17:01.700 --> 00:17:04.710
この方法を理解するために重要なことの一つ
は、

237
00:17:04.710 --> 00:17:08.800
時にはそれのために2つの異なるモデルが必
要です。

238
00:17:08.800 --> 00:17:13.660
そして、これは1つのモデルは非常にその予
測に自信を持っている場合です。

239
00:17:13.660 --> 00:17:17.060
つまり、予測確率は非常に0と1に近いです
。

240
00:17:18.200 --> 00:17:22.676
この場合、モデルをトレーニングしてタスク
セットを予測し、

241
00:17:22.676 --> 00:17:26.953
ラベルのサンプルまたはそれを最も可能性の
高いラベルを取る

242
00:17:26.953 --> 00:17:32.840
同じ機能を持つ同じモデルをトリムまたは全
く改善を得る。

243
00:17:32.840 --> 00:17:38.875
我々は、この方法で擬似ラベリングと任意の
情報を導入していない

244
00:17:38.875 --> 00:17:43.790
しかし、もし私が言う、スタニスラフ、彼の
モデルでは予測するように依頼します。

245
00:17:43.790 --> 00:17:46.592
そして、私はテストのために彼のラベルを使
用し、

246
00:17:46.592 --> 00:17:51.310
私は素敵な改善を取得する場所である私のモ
デルを作成します。

247
00:17:52.740 --> 00:17:55.400
これは実際にちょうど別の方法になる

248
00:17:55.400 --> 00:17:58.209
2つの多様なモデルから知識を取り入れるこ
と。

249
00:17:59.290 --> 00:18:04.280
そして、私たちに多くを助けた最後のものは
、クラスごとのミキシングです。

250
00:18:05.300 --> 00:18:09.640
競争の時に、人々は通常、直線的にモデルを
混合した。

251
00:18:09.640 --> 00:18:15.030
さらに、各クラスの結合係数を個別に組み合
わせたモデルを追加しました。

252
00:18:16.380 --> 00:18:20.130
実際に、それについて考える場合、それはと
スタッキングに非常に似ている

253
00:18:20.130 --> 00:18:22.910
2番目のレベルで特別な種類の線形モデル。

254
00:18:24.270 --> 00:18:28.794
しかし、2番目の1カ月で、この大会の後に
人気となった

255
00:18:28.794 --> 00:18:32.700
ここでやったことは、スタッキングの非常に
単純なマニュアル形式です。

256
00:18:34.820 --> 00:18:40.280
私達は私達のソースコードをオンラインで出
版した、従って興味があればそれを点検でき
る。

257
00:18:40.280 --> 00:18:43.610
これは興味深い競争だった

258
00:18:43.610 --> 00:18:48.545
それは技術的な観点から、我々が操作するた
めに必要に挑戦した

259
00:18:48.545 --> 00:18:53.870
データのテラバイトの半分以上が、それは非
常に面白かった。

260
00:18:53.870 --> 00:18:56.110
データは、raw 形式で与えられた

261
00:18:56.110 --> 00:18:59.630
実際の課題は、素敵な機能を思い付くことで
した。

262
00:18:59.630 --> 00:19:05.121
そして、それは我々が創造することができる
場所です、ありがとう。

263
00:19:05.121 --> 00:19:15.121
音楽


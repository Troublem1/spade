1
00:00:00.840 --> 00:00:06.700
アンサンブルの方法との私達の議論を続けて
、次の1つは積み重ねている。

2
00:00:06.700 --> 00:00:08.200
スタッキングは大変ですが、

3
00:00:08.200 --> 00:00:13.908
予測モデリングコンテストを使用して
ensembling
の非常に人気のあるフォーム。

4
00:00:13.908 --> 00:00:19.061
そして、私はほとんどの大会を信じて、フォ
ームがある

5
00:00:19.061 --> 00:00:26.060
あなたができる限り最高のパフォーマンスを
向上させるために、最終的にスタッキング。

6
00:00:26.060 --> 00:00:30.851
積み重ねの定義によって、それは本質的に行
く

7
00:00:30.851 --> 00:00:35.850
ホールドアウトデータセットを使用して複数
の予測を行うことを意味します。

8
00:00:35.850 --> 00:00:40.872
次に、これらの予測を収集または積み重ね

9
00:00:40.872 --> 00:00:46.471
新しいデータセットを形成するには、新しい
モデルをその上に収めることができます。

10
00:00:46.471 --> 00:00:51.520
この新たに形成されたデータを予測から設定
します。

11
00:00:51.520 --> 00:00:56.570
私は非常に単純な、私は世間知らずと言うだ
ろうを介してお連れしたいと思います

12
00:00:56.570 --> 00:01:02.620
概念的にはどのように動作するかを示す例で
す。

13
00:01:02.620 --> 00:01:09.350
私は、我々はこれまでのところ、以前のモデ
ルの予測を使用することができます見ている
ことを意味

14
00:01:09.350 --> 00:01:15.650
新しいモデルに影響を与えるが、入力データ
と常に関連している。

15
00:01:15.650 --> 00:01:20.930
我々は予測を使用しようとしているので、こ
れは新しい概念です

16
00:01:20.930 --> 00:01:25.330
より良いモデルを作るためにいくつかのモデ
ルの。

17
00:01:25.330 --> 00:01:29.860
それでは、これらが実際のシナリオでどのよ
うに動作するかを見てみましょう。

18
00:01:29.860 --> 00:01:35.620
3人の子供がいると仮定しましょう LR
という名前を聞かせて

19
00:01:35.620 --> 00:01:41.340
SVM、KNN、彼らは物理学の質問につい
て議論する。

20
00:01:41.340 --> 00:01:46.494
だから、それぞれ1つの物理学の質問への答
えは異なると考えています。

21
00:01:46.494 --> 00:01:51.105
最初の1つは言う 13, 2 番目の
18, 3 番目 11,

22
00:01:51.105 --> 00:01:55.837
彼らはこの不一致を解決する方法を知らない
。

23
00:01:55.837 --> 00:01:59.684
彼らは立派なことを、彼らは平均を取るよう
に言う、

24
00:01:59.684 --> 00:02:01.360
この場合は14です。

25
00:02:01.360 --> 00:02:05.760
だから、ほとんどの子供を見ることができま
す

26
00:02:05.760 --> 00:02:09.570
ここにはさまざまなモデルがあり、入力デー
タを取ります。

27
00:02:09.570 --> 00:02:13.470
この場合、それは物理学についての質問であ
る。

28
00:02:13.470 --> 00:02:18.319
それらは歴史的情報に基づいてそれを処理し
、

29
00:02:18.319 --> 00:02:22.138
それらは見積もり、予言を出力できる。

30
00:02:22.138 --> 00:02:23.769
彼らはしかし、それを最適に行っている?

31
00:02:26.142 --> 00:02:31.171
もう一つの言い方は、先生がいたと言うこと
ですが、

32
00:02:31.171 --> 00:02:37.930
この議論を見ていたミス DL は、彼女が
ステップアップすることを決めた。

33
00:02:37.930 --> 00:02:44.139
彼女は質問を聞いていないが、彼女は非常に
よく、学生を知っている

34
00:02:44.139 --> 00:02:48.261
彼女はそれぞれの長所と短所を知っている。

35
00:02:48.261 --> 00:02:53.000
彼女はどのようにも、歴史的に物理学の質問
で行っている知っている。

36
00:02:53.000 --> 00:02:58.015
そして、彼らが提供している値の範囲から、
彼女は見積もりを与えることができます。

37
00:02:58.015 --> 00:03:04.450
のは、この概念では、彼女は、SVM は本
当に物理学で良いことを知っているとしまし
ょう

38
00:03:04.450 --> 00:03:10.200
彼女の父親は優秀な物理学専攻で働いている
。

39
00:03:10.200 --> 00:03:15.285
したがって、彼女はこれに大きな貢献をする
必要があります

40
00:03:15.285 --> 00:03:20.687
他のすべての子供よりアンサンブル、従って
答えは17である。

41
00:03:20.687 --> 00:03:26.340
そして、この方法は、メタモデルの作品は、
入力データを知る必要はありません。

42
00:03:26.340 --> 00:03:30.975
それはちょうどモデルが歴史的に行っている
方法を知っている、

43
00:03:30.975 --> 00:03:34.945
それらを結合する最もよい方法を見つけるた
め。

44
00:03:34.945 --> 00:03:37.839
そして、これは実際には非常にうまく機能す
ることができます。

45
00:03:39.957 --> 00:03:43.840
それでは、スタッキングの方法論にもっと行
きましょう。

46
00:03:45.020 --> 00:03:48.359
・ウォルパートは1992でスタッキングを
導入,

47
00:03:48.359 --> 00:03:52.880
異なるモデルを結合するためのメタモデリン
グ手法として。

48
00:03:52.880 --> 00:03:56.650
これは、いくつかの手順で構成されます。

49
00:03:56.650 --> 00:04:01.207
最初のステップは、我々は列車のデータセッ
トを持っていると仮定してみましょう、

50
00:04:01.207 --> 00:04:06.510
2つの部分に分けてみましょう。ので、トレ
ーニングと検証。

51
00:04:06.510 --> 00:04:13.700
その後、訓練の一部を取ると、いくつかのモ
デルを訓練する。

52
00:04:15.200 --> 00:04:18.941
その後、2番目の部分の予測を行うと、

53
00:04:18.941 --> 00:04:21.642
検証データセットを言いましょう。

54
00:04:21.642 --> 00:04:26.720
次に、これらの予測をすべて収集するか、こ
れらの予測をスタックします。

55
00:04:26.720 --> 00:04:32.034
新しいデータセットを形成し、これを新しい
モデルへの入力として使用します。

56
00:04:32.034 --> 00:04:37.199
通常はこれをメタモデルと呼び、モデルを実
行します。

57
00:04:37.199 --> 00:04:40.620
我々は、ベースモデルまたはベースの学習者
と呼んでいます。

58
00:04:43.153 --> 00:04:47.320
スタッキングについてまだ混乱している場合
は、次のアニメーションを検討してください
。

59
00:04:47.320 --> 00:04:52.870
それでは、3つのデータセット A、B、C
があると仮定しましょう。

60
00:04:55.320 --> 00:04:59.690
この場合、A はトレーニングデータセット
の役割を果たし、

61
00:04:59.690 --> 00:05:02.432
B は検証データセットになり、

62
00:05:02.432 --> 00:05:07.590
C は最終的な予測を行いたいテストデータ
セットになります。

63
00:05:07.590 --> 00:05:11.820
それらはすべて同じような建築、4つの特徴
を有する、

64
00:05:11.820 --> 00:05:15.065
と1つのターゲット変数を予測してみてくだ
さい。

65
00:05:15.065 --> 00:05:19.727
この場合、アルゴリズムを選択することがで
きます。

66
00:05:19.727 --> 00:05:24.130
データセット1に基づいてモデルをトレーニ
ングし、

67
00:05:24.130 --> 00:05:30.160
その後、B と C
の予測を同時に行います。

68
00:05:30.160 --> 00:05:35.019
今、我々は、これらの予測を取る、我々は新
しいデータセットに入れてください。

69
00:05:35.019 --> 00:05:42.620
そこで、B1 に検証データの予測を格納す
るためのデータセットを作成します。

70
00:05:42.620 --> 00:05:49.463
c1 と呼ばれるテストデータの予測を保存
するために、c1
というデータセットがあります。

71
00:05:49.463 --> 00:05:52.115
その後、我々は、プロセスを繰り返すつもり
だ

72
00:05:52.115 --> 00:05:55.156
別のアルゴリズムを選ぶんだ

73
00:05:55.156 --> 00:05:58.150
ここでも、データセットに合わせます。

74
00:05:58.150 --> 00:06:03.382
我々は、同時に B と C
の予測を行います

75
00:06:03.382 --> 00:06:10.580
そして、これらの予測を新しく形成されたデ
ータセットに保存します。

76
00:06:10.580 --> 00:06:14.270
そして、我々は本質的にそれらを追加すると
、我々はそれらを互いに横に積み重ね、

77
00:06:14.270 --> 00:06:16.860
これは、スタックの名前がかかります。

78
00:06:16.860 --> 00:06:20.213
そして、我々はさらにこれを継続することが
できます、3番目のアルゴリズムでそれを行
う。

79
00:06:20.213 --> 00:06:25.360
再び同じ, a に収まる, B と C
で予測, 同じ予測.

80
00:06:26.460 --> 00:06:30.678
次に、B
データセットのターゲット変数を取るか、

81
00:06:30.678 --> 00:06:34.000
検証 datadset、我々はすでに知っ
ていた。

82
00:06:34.000 --> 00:06:41.431
そして、我々は、検証データのターゲットと
B1
に新しいモデルを適合させるつもりです

83
00:06:41.431 --> 00:06:45.607
その後、C1 から予測を行います。

84
00:06:45.607 --> 00:06:49.392
そして、これは我々がスタッキングと異なる
モデルを組み合わせる方法です。

85
00:06:49.392 --> 00:06:54.170
うまくいけば、テストや評点データのための
より良い予測をする。

86
00:06:57.505 --> 00:07:03.007
私たちは例を、Python
の簡単な例を通過しましょう

87
00:07:03.007 --> 00:07:09.199
コードのようによく理解するためには、どの
ように動作します。

88
00:07:09.199 --> 00:07:10.760
それは非常にシンプルなので、

89
00:07:10.760 --> 00:07:16.200
非常に Python を経験していない人
々も、このことを理解することができます。

90
00:07:17.410 --> 00:07:23.101
主なロジックは、我々はいくつかの入力デー
タに2つの基本学習を使用することです

91
00:07:23.101 --> 00:07:26.483
ランダムなフォレストと線形回帰。

92
00:07:26.483 --> 00:07:31.367
そして、我々は、メタ学習者から始まる結果
を結合しようとすると、

93
00:07:31.367 --> 00:07:33.860
繰り返しますが、線形回帰になります。

94
00:07:35.110 --> 00:07:38.906
我々は再び列車のデータセットを持っている
と仮定してみましょう, と

95
00:07:38.906 --> 00:07:43.364
このデータセットのターゲット変数、および
テストデータセット。

96
00:07:46.658 --> 00:07:51.850
たぶん、コードは少し威圧的なようだが、我
々は一歩進んでいきます。

97
00:07:51.850 --> 00:07:58.690
我々は最初に我々は列車のデータセットを取
ると我々は2つの部分でそれを分割すること
です。

98
00:07:58.690 --> 00:08:03.914
そこで、トレーニングと有効なデータセット
を作成し、

99
00:08:03.914 --> 00:08:07.670
そして、我々はまた、ターゲット変数を分割
します。

100
00:08:07.670 --> 00:08:12.954
だから我々は、ytraining と
yvalid を作成し、我々は 50%
でこれを分割します。

101
00:08:12.954 --> 00:08:16.400
我々は何か他のものを選択することが、50
% としましょう。

102
00:08:16.400 --> 00:08:22.184
次に、基本学習者を指定するので、mode
l1 はランダム

103
00:08:22.184 --> 00:08:27.864
この場合のフォレスト、および
model2 は線形回帰です。

104
00:08:27.864 --> 00:08:32.510
私たちは、我々は両方のモデルを使用してフ
ィットされますか

105
00:08:32.510 --> 00:08:37.165
トレーニングデータとトレーニングターゲッ
ト。

106
00:08:37.165 --> 00:08:42.078
そして、両方のモデルの検証データの予測を
行い、

107
00:08:42.078 --> 00:08:47.460
同時に、テストデータの予測も行います。

108
00:08:47.460 --> 00:08:52.206
ここでも、両方のモデルについては、pre
ds1、preds2
として、これらを保存し、

109
00:08:52.206 --> 00:08:55.756
テストデータは、test_preds1
と test_preds2。

110
00:08:55.756 --> 00:08:58.997
その後、我々は予測を収集するつもりですが
、

111
00:08:58.997 --> 00:09:03.661
我々は、予測を積み重ね、2つの新しいデー
タセットを作成する予定です。

112
00:09:03.661 --> 00:09:07.943
我々はそれを
stacked_predictions
と呼ぶ検証のための1つ、

113
00:09:07.943 --> 00:09:10.700
preds1 と preds2
で構成されています。

114
00:09:10.700 --> 00:09:14.610
次に、テストの予測のために設定されたデー
タに対して、

115
00:09:14.610 --> 00:09:21.160
stacked_test_predict
ions と呼ばれ、ここで
test_preds1 と
test_preds2
をスタックします。

116
00:09:22.190 --> 00:09:24.540
次に、メタ学習者を指定します。

117
00:09:24.540 --> 00:09:27.960
線形回帰である meta_model
と呼びましょう。

118
00:09:27.960 --> 00:09:33.138
このモデルを検証データに対する予測に適合
させ、

119
00:09:33.138 --> 00:09:39.223
検証データのターゲットであり、この時点で
すべての提示データが設定されていました。

120
00:09:39.223 --> 00:09:42.499
そして、我々は予測を生成することができま
す

121
00:09:42.499 --> 00:09:48.580
stacked_test_predict
ions
にこのモデルを適用してテストデータ。

122
00:09:48.580 --> 00:09:50.140
これはどのように動作します。

123
00:09:51.820 --> 00:09:56.070
今、私はこれが古い例を再訪する良い時間だ
と思う

124
00:09:56.070 --> 00:10:00.590
我々は、単純な平均については、最初のセッ
ションで使用されます。

125
00:10:00.590 --> 00:10:05.010
あなたが覚えていれば、我々はやっていた予
測があった

126
00:10:05.010 --> 00:10:09.518
年齢が50未満だった年齢を予測するために
非常によく、そして

127
00:10:09.518 --> 00:10:14.780
年齢が50以上だったときに非常によくやっ
ていたもう一つの予測。

128
00:10:14.780 --> 00:10:18.964
そして、我々はトリッキーな何かをした、そ
れは50未満である場合、我々は言った

129
00:10:18.964 --> 00:10:24.315
我々は、年齢が50以上の場合、我々は他の
1つを使用します、最初のものを使用します
。

130
00:10:24.315 --> 00:10:29.020
これがトリッキーな理由は、通常、我々はタ
ーゲットを使用するためです

131
00:10:29.020 --> 00:10:31.833
この決定を下すための情報。

132
00:10:31.833 --> 00:10:36.820
ここで、理想的な世界では、これは何を予測
しようとすると、あなたはそれを知らない。

133
00:10:36.820 --> 00:10:42.340
我々は、我々が得ることができる理論的な最
高であるかを示すためにそれを行っている

134
00:10:42.340 --> 00:10:43.740
またははい、最高。

135
00:10:43.740 --> 00:10:46.290
だから、同じ予測を取ると

136
00:10:46.290 --> 00:10:51.390
スタッキングを適用すると、これは最終的な
結果が実際にどのように見えるかです。

137
00:10:52.450 --> 00:10:55.460
あなたが見ることができるように、それはか
なり同様に行っています。

138
00:10:55.460 --> 00:11:02.990
いくつかのエラーがある唯一の領域は、50
のしきい値の周りです。

139
00:11:02.990 --> 00:11:08.693
モデルは、ターゲット変数が表示されないた
め、それは理にかなって、

140
00:11:08.693 --> 00:11:12.361
正確には50のこのカットを識別することは
できません。

141
00:11:12.361 --> 00:11:16.029
したがって、それは、入力モデルに基づいて
のみそれをしようとすると、

142
00:11:16.029 --> 00:11:18.810
この辺りは多少重なりがあります。

143
00:11:18.810 --> 00:11:24.527
しかし、あなたは、スタッキングがこれを識
別することができることがわかります

144
00:11:24.527 --> 00:11:29.510
そしてよりよい予言をするためにそれを使用
しなさい。

145
00:11:31.800 --> 00:11:36.670
あなたがスタッキングを使用するときに留意
する必要がある特定のものがあります。

146
00:11:36.670 --> 00:11:41.152
1つは、時間に敏感なデータを持っていると
きに、と言うように、

147
00:11:41.152 --> 00:11:46.640
時系列は、あなたが時間を尊重するようにあ
なたの積み重ねを策定する必要があります。

148
00:11:47.770 --> 00:11:53.290
私が言いたいのは、あなたの列車と検証デー
タを作成するときに、

149
00:11:53.290 --> 00:11:58.300
あなたの列車は、過去とあなたの検証にある
ことを確認する必要がある

150
00:11:58.300 --> 00:12:03.080
将来的には、理想的なテストデータも将来的
にされています。

151
00:12:03.080 --> 00:12:07.956
だから、この時間の要素を尊重するためにす
る必要がある

152
00:12:07.956 --> 00:12:11.464
あなたのモデルがよく一般化特定。

153
00:12:11.464 --> 00:12:14.131
あなたが見る必要がある他の事は、明らかに
、

154
00:12:14.131 --> 00:12:16.310
シングルモデルのパフォーマンスが重要です
。

155
00:12:16.310 --> 00:12:21.267
しかし、他のことも非常に重要なモデルです

156
00:12:21.267 --> 00:12:26.470
多様性、モデルが互いにどのように異なって
いるか。

157
00:12:26.470 --> 00:12:31.488
各モデルがテーブルにもたらす新しい情報は
何ですか?

158
00:12:31.488 --> 00:12:36.940
今、スタッキングのため、あなたが使用する
アルゴリズムに応じて

159
00:12:36.940 --> 00:12:41.100
スタッキングは、非常に深い関係を探るに行
くことができます。

160
00:12:42.540 --> 00:12:46.850
それは、モデルが良いときに見つけるでしょ
う、と

161
00:12:46.850 --> 00:12:50.800
モデルが実際に悪いか、かなり弱いとき。

162
00:12:50.800 --> 00:12:55.275
だから、すべてのモデルが本当に強いように
あまり心配する必要はありません,

163
00:12:55.275 --> 00:13:02.630
スタッキングは、実際に各予測からジュース
を抽出することができます。

164
00:13:02.630 --> 00:13:07.498
したがって、あなたが本当に焦点を当てる必
要がある、私はもたらすモデルを作っていま
す

165
00:13:07.498 --> 00:13:11.009
ある程度の情報、といっても、一般的に弱い
のでは?

166
00:13:11.009 --> 00:13:15.931
そして、これは本当です、私が作った多くの
状況があった、私は持っていた

167
00:13:15.931 --> 00:13:21.112
私のアンサンブルのいくつかの非常に弱いモ
デルは、私は、トップのパフォーマンスと比
較して意味します。

168
00:13:21.112 --> 00:13:25.942
そしてそれにもかかわらず、彼らは実際に積
み重ねで多くの価値を加えていた。

169
00:13:25.942 --> 00:13:32.140
彼らは、メタモデルが活用できる新しい情報
をもたらしていた。

170
00:13:32.140 --> 00:13:35.523
通常、2つの形態から多様性を導入し、

171
00:13:35.523 --> 00:13:38.240
1つは、別のアルゴリズムを選択することで
す。

172
00:13:38.240 --> 00:13:39.511
理にかなっている

173
00:13:39.511 --> 00:13:44.460
特定のアルゴリズムは、データ内のさまざま
な関係を活用します。

174
00:13:44.460 --> 00:13:49.263
たとえば、線形モデルは線形関係に焦点を合
わせ、

175
00:13:49.263 --> 00:13:52.450
非線形モデルは、非線形の関係をよりよく捉
えることができます。

176
00:13:52.450 --> 00:13:56.060
だから予測は少し違ってくるかもしれません
。

177
00:13:56.060 --> 00:13:59.734
もう一つは、あなたも同じモデルを実行する
ことができますが、

178
00:13:59.734 --> 00:14:03.900
あなたは、入力データの異なる変換でそれを
実行しようとすると、

179
00:14:03.900 --> 00:14:08.470
以下の機能または完全に異なる変換のいずれ
か。

180
00:14:08.470 --> 00:14:09.594
例えば

181
00:14:09.594 --> 00:14:15.410
1つのデータセットでは、カテゴリ機能を1
つの全体エンコードとして扱うことができま
す。

182
00:14:15.410 --> 00:14:20.376
別の方法では、単にコーディングでラベルを
使用することができ、

183
00:14:20.376 --> 00:14:26.890
その結果、おそらく非常に異なるモデルが生
成されます。

184
00:14:29.717 --> 00:14:34.890
一般的に、スタックできるモデルの数に制限
はありません。

185
00:14:34.890 --> 00:14:37.851
しかし、あなたはプラトーがあることを期待
することができます

186
00:14:37.851 --> 00:14:40.501
特定のモデルが追加された後。

187
00:14:40.501 --> 00:14:45.358
だから最初に、あなたは何の指標でいくつか
の重要な隆起が表示されます

188
00:14:45.358 --> 00:14:48.220
は、モデルを実行するたびにテストされます
。

189
00:14:48.220 --> 00:14:55.232
しかし、いくつかのポイントの後、増分隆起
はかなり小さくなります。

190
00:14:55.232 --> 00:15:00.489
一般的に、この前に知っている方法はありま
せんが、

191
00:15:00.489 --> 00:15:07.760
まさに我々がプラトーを開始するモデルの数
です。

192
00:15:07.760 --> 00:15:13.590
しかし、一般的に、これはあなたのデータを
持っているどのように多くの機能によって影
響を受けている

193
00:15:13.590 --> 00:15:18.346
どのくらいの多様性をあなたのモデルに導入
するには、管理

194
00:15:18.346 --> 00:15:21.596
かなり頻繁にどのように多くのデータの行が
あります。

195
00:15:21.596 --> 00:15:25.773
なのでこれを事前に知るのはしんどいですが
、

196
00:15:25.773 --> 00:15:30.360
一般的にこれは何かに留意することです。

197
00:15:30.360 --> 00:15:34.221
しかし、より多くのモデルを追加すると、実
際に追加していない点があります

198
00:15:34.221 --> 00:15:34.950
多くの価値。

199
00:15:38.788 --> 00:15:43.289
とメタモデルのため、メタモデル

200
00:15:43.289 --> 00:15:48.065
他のモデルの予測のみを使用します。

201
00:15:48.065 --> 00:15:53.019
我々は、他のモデルが行っていると仮定する
ことができます、と言ってみましょう

202
00:15:53.019 --> 00:15:56.993
深い仕事や深い仕事は、データを精査する。

203
00:15:56.993 --> 00:16:00.960
したがって、メタモデルはそれほど深くする
必要はありません。

204
00:16:00.960 --> 00:16:04.810
通常、予測はターゲットに関連付けられてい
ます。

205
00:16:04.810 --> 00:16:09.790
そして、それを行う必要がある唯一のものは
、それらを結合する方法を見つけることです

206
00:16:09.790 --> 00:16:12.950
それは通常、それほど複雑ではありません。

207
00:16:12.950 --> 00:16:19.290
したがって、メタモデルが一般的に単純であ
ることは、かなり頻繁にあります。

208
00:16:19.290 --> 00:16:24.350
私がこれをランダムな森の文脈で表現するな
ら

209
00:16:24.350 --> 00:16:32.020
それはあなたのベースモデルで見つかった最
高のものだったものよりも低い深さを持つこ
とになります。

210
00:16:33.710 --> 00:16:38.010
これは、セッションの終わりだった,
ここでは、スタッキングについて議論.

211
00:16:38.010 --> 00:16:42.813
次のいずれかで、我々はスタッキングについ
て非常に興味深い概念を議論し、

212
00:16:42.813 --> 00:16:46.110
スタックネットと呼ばれる複数のレベルで拡
張します。

213
00:16:46.110 --> 00:16:47.370
だから調子にのってください。


1
00:00:00.000 --> 00:00:03.835
みなさん。マリ Michailidis
だ

2
00:00:03.835 --> 00:00:08.775
そして今日、我々は、アンサンブルの方法で
我々の議論を続けるよ

3
00:00:08.775 --> 00:00:14.340
と具体的には、ensembling の非
常に人気のある形でブーストと呼ばれる。

4
00:00:14.340 --> 00:00:16.890
ブーストとは何ですか?

5
00:00:16.890 --> 00:00:22.800
ブーストは、各モデルが構築されているモデ
ルの加重平均の一形態である

6
00:00:22.800 --> 00:00:30.283
前のモデルのパフォーマンスを考慮する方法
で順次。

7
00:00:30.283 --> 00:00:32.530
これをよく理解するためには、

8
00:00:32.530 --> 00:00:36.333
前に、我々は自転車について議論を覚えて、

9
00:00:36.333 --> 00:00:40.680
そして、我々は、我々は多くの異なるモデル
でそれを持つことができることを見た

10
00:00:40.680 --> 00:00:45.420
よりよい予言を得るために互いに独立してい
る。

11
00:00:45.420 --> 00:00:47.400
ブーストは何か違う。

12
00:00:47.400 --> 00:00:52.070
」と言い、今はモデルを作ってみましたが、

13
00:00:52.070 --> 00:00:55.260
しかし、私はアカウントにどのようによく取
る

14
00:00:55.260 --> 00:01:00.460
前のモデルは、より良い予測をするために行
っている。

15
00:01:00.460 --> 00:01:04.745
だから、我々は、アンサンブルに順次追加す
るすべてのモデル、

16
00:01:04.745 --> 00:01:07.510
これは、アカウントにどのようにもかかる

17
00:01:07.510 --> 00:01:12.515
前のモデルは、より良い予測をするために行
っている。

18
00:01:12.515 --> 00:01:18.370
2つの主要なブーストタイプのアルゴリズム
があります。

19
00:01:18.370 --> 00:01:19.870
1つは重量に基づいて、

20
00:01:19.870 --> 00:01:22.630
そして、他の残留エラーに基づいて、

21
00:01:22.630 --> 00:01:25.641
そして、二人とも一つずつ話し合っていきま
す。

22
00:01:25.641 --> 00:01:33.380
重量を高めるために、それをよりよく理解す
るために例を見ることはよい。

23
00:01:33.380 --> 00:01:38.975
表形式のデータセットがあり、4つの機能を
備えているとします。

24
00:01:38.975 --> 00:01:40.230
それらを x0 と呼びましょう

25
00:01:40.230 --> 00:01:42.260
x1、x2、x3

26
00:01:42.260 --> 00:01:48.200
これらの機能を使用して、ターゲット変数
y を予測します。

27
00:01:48.200 --> 00:01:51.266
私たちは体重ブーストで何をするつもりです
が、

28
00:01:51.266 --> 00:01:53.915
モデルに合わせようと思っておりますが、

29
00:01:53.915 --> 00:01:56.655
そして、我々は予測を生成します。

30
00:01:56.655 --> 00:01:58.280
pred と呼んでみよう

31
00:01:58.280 --> 00:02:01.607
これらの予測には、特定のエラーのマージン
があります。

32
00:02:01.607 --> 00:02:05.300
我々は、これらの絶対的なエラーを計算する
ことができます

33
00:02:05.300 --> 00:02:07.595
と私は絶対的なエラーを言うとき、

34
00:02:07.595 --> 00:02:13.150
は y
の絶対値から予測を差し引いたものです。

35
00:02:13.150 --> 00:02:18.360
あなたは非常に、非常に遠く離れている予測
があることがわかります

36
00:02:18.360 --> 00:02:21.444
5番行のように

37
00:02:21.444 --> 00:02:23.962
でも6番みたいな人がいる

38
00:02:23.962 --> 00:02:28.015
これは、モデルが実際に非常によくやってい
る。

39
00:02:28.015 --> 00:02:32.480
だから我々はこれに基づいて行う我々が生成
され、

40
00:02:32.480 --> 00:02:33.978
では、新しい列や新しいベクトルを、としま
しょう

41
00:02:33.978 --> 00:02:39.930
ここでは、重みの列を作成する

42
00:02:39.930 --> 00:02:46.905
そして、我々は、この重みは1プラス絶対的
なエラーであると言う。

43
00:02:46.905 --> 00:02:51.945
この重みを計算するには、さまざまな方法が
あります。

44
00:02:51.945 --> 00:02:55.555
今、私はちょうど例としてこれを与えている
。

45
00:02:55.555 --> 00:02:59.005
これを行うには、さまざまな方法があること
を推論することができます

46
00:02:59.005 --> 00:03:03.270
しかし、全体的な原理は非常に似ています。

47
00:03:03.270 --> 00:03:06.115
だから、次に何をしようとしている

48
00:03:06.115 --> 00:03:12.165
あなたは、同じ機能と同じターゲット変数を
使用して、新しいモデルに適合するつもりだ

49
00:03:12.165 --> 00:03:16.330
しかし、あなたはまた、この体重を追加する
つもりだ。

50
00:03:16.330 --> 00:03:19.675
どのような重量は、モデルには、言う

51
00:03:19.675 --> 00:03:24.225
私はあなたが特定の役割にもっと意義を入れ
てほしい。

52
00:03:24.225 --> 00:03:28.240
あなたはほとんどの重量を解釈することがで
きますの数を持って

53
00:03:28.240 --> 00:03:32.650
特定の行がデータに表示される回数。

54
00:03:32.650 --> 00:03:35.039
だから体重は2だったとしましょう、

55
00:03:35.039 --> 00:03:39.400
これは、この行が2回表示されることを意味
します。

56
00:03:39.400 --> 00:03:47.707
したがって、全体のエラーに大きな貢献して
います。

57
00:03:47.707 --> 00:03:50.930
このプロセスを繰り返し続けることができま
す。

58
00:03:50.930 --> 00:03:55.420
このエラーに基づいて新しいエラーを計算す
ることもできます。

59
00:03:55.420 --> 00:03:57.545
新しいウェイトを計算すると、

60
00:03:57.545 --> 00:04:02.230
そして、これはどのように順番にアンサンブ
ルにモデルを追加することです

61
00:04:02.230 --> 00:04:07.625
各モデルは、特定のケースで行っているかを
考慮してください,

62
00:04:07.625 --> 00:04:13.805
前のモデルがより間違って行っている場所か
らフォーカスを最大化する。

63
00:04:13.805 --> 00:04:18.606
ブーストのこのタイプに関連付けられている
特定のパラメータがあります。

64
00:04:18.606 --> 00:04:19.785
1つは学習率です。

65
00:04:19.785 --> 00:04:23.629
我々はまた、収縮または eta
を呼び出すことができます。

66
00:04:23.629 --> 00:04:26.360
それは異なった名前を有する。今思い出すと

67
00:04:26.360 --> 00:04:30.726
加重平均化の形態として昇圧を説明した。

68
00:04:30.726 --> 00:04:31.730
そして、これは本当です、

69
00:04:31.730 --> 00:04:34.825
なぜなら、通常、この学習率。

70
00:04:34.825 --> 00:04:37.220
我々が言うには

71
00:04:37.220 --> 00:04:39.024
我々が構築したすべての新しいモデル、

72
00:04:39.024 --> 00:04:41.600
私たちは 100%
を信頼しないでください。

73
00:04:41.600 --> 00:04:44.285
少しは信用するべきだ

74
00:04:44.285 --> 00:04:51.205
これは、我々は一般的にあまりにも多くの貢
献を持つ1つのモデルを持っていないことを
保証

75
00:04:51.205 --> 00:04:57.740
そして、完全に非常に一般化されていないも
のを作る。

76
00:04:57.740 --> 00:05:01.705
従ってこれは私達が1つのモデルを信頼しな
いことを保障する、

77
00:05:01.705 --> 00:05:04.250
我々は少し多くのモデルを信頼しています。

78
00:05:04.250 --> 00:05:08.520
フィッティングをコントロールするのはとて
も良いことです。

79
00:05:08.520 --> 00:05:12.625
我々が見ている2番目のパラメータは、推定
の数です。

80
00:05:12.625 --> 00:05:14.430
これは非常に重要です。

81
00:05:14.430 --> 00:05:18.400
と普通に、逆の関係がありますが、

82
00:05:18.400 --> 00:05:20.335
学習率の反対の関係。

83
00:05:20.335 --> 00:05:25.530
だから、より多くの推定我々は、アンサンブ
ルのこれらのタイプに追加すると、

84
00:05:25.530 --> 00:05:28.885
私たちが置く必要があるより小さい学習率。

85
00:05:28.885 --> 00:05:32.629
これは、時には非常に適切な値を見つけるこ
とは困難ですが、

86
00:05:32.629 --> 00:05:36.345
そして、我々はクロス検証の助けを受けてそ
れを行う。

87
00:05:36.345 --> 00:05:42.730
なので普通に、決まった数の推定から始めて
、言いましょうよ、

88
00:05:42.730 --> 00:05:50.495
100、その後、我々はこの100推定のた
めの最適な学習率を見つけることを試みる。

89
00:05:50.495 --> 00:05:54.175
クロス検証のパフォーマンスに基づいて、

90
00:05:54.175 --> 00:05:57.335
我々は、これが0.1
であることがわかります。

91
00:05:57.335 --> 00:05:59.700
私たちにできることは、

92
00:05:59.700 --> 00:06:03.611
としましょう、我々は推定の数を倍増するこ
とができます

93
00:06:03.611 --> 00:06:09.310
それを200にして、学習率を2で割って、

94
00:06:09.310 --> 00:06:12.185
だから、0.05 を置くことができます

95
00:06:12.185 --> 00:06:14.360
そして、我々はパフォーマンスを取る。

96
00:06:14.360 --> 00:06:19.627
私が説明したように関係が直線的ではないの
かもしれませんが、

97
00:06:19.627 --> 00:06:28.590
推定を複製した後、最高の学習率は0.04
または0.06 かもしれませんが、

98
00:06:28.590 --> 00:06:30.295
しかし、これは大体の論理です。

99
00:06:30.295 --> 00:06:33.820
これは、我々は推定を増やすために働く方法
です。

100
00:06:33.820 --> 00:06:40.262
多くの時間を失うことなく、より良いパフォ
ーマンスを与える推定を参照してくださいし
ようとすると、

101
00:06:40.262 --> 00:06:45.040
毎回、最高の学習率を見つけようとしていま
す。

102
00:06:45.040 --> 00:06:49.165
我々が見てもう一つは、入力モデルの種類で
す。

103
00:06:49.165 --> 00:06:55.245
そして一般的に、我々は推定の任意のタイプ
のブーストを実行することができます。

104
00:06:55.245 --> 00:07:00.505
唯一の条件はそれがそれのモデル化プロセス
の重量を受け入れる必要があることである。

105
00:07:00.505 --> 00:07:05.130
だから私はどのくらい我々のデータセットの
各ロールに依存する必要がありますと言うに
重量を量る。

106
00:07:05.130 --> 00:07:10.410
それから、様々なブースティングタイプがあ
ります。

107
00:07:10.410 --> 00:07:14.840
私が言ったように、私は大まかにどのように
使用することができますあなたに説明

108
00:07:14.840 --> 00:07:20.820
別の行に集中するための手段としての重み、

109
00:07:20.820 --> 00:07:23.420
モデルが間違って行っている別のケース、

110
00:07:23.420 --> 00:07:25.970
しかし、これを表現するさまざまな方法があ
ります。

111
00:07:25.970 --> 00:07:28.160
例えば、ある特定の昇圧アルゴリズムがある

112
00:07:28.160 --> 00:07:31.278
それはエラーのマージンを気にしない、

113
00:07:31.278 --> 00:07:36.075
あなたが正しいかどうかの分類をした場合、
彼らは気に。

114
00:07:36.075 --> 00:07:38.595
だから、さまざまなバリエーションがありま
す。

115
00:07:38.595 --> 00:07:41.720
私が本当に好きな1つは、AdaBoost
です。

116
00:07:41.720 --> 00:07:45.230
sklearn
には非常に優れた実装があります

117
00:07:45.230 --> 00:07:46.675
任意の入力アルゴリズムを選択できます。

118
00:07:46.675 --> 00:07:49.360
本当にいいと思いますよ。

119
00:07:49.360 --> 00:07:53.330
そして、私が本当に好きなもう一つは、通常
、

120
00:07:53.330 --> 00:07:56.313
ロジスティック回帰のためだけに良いのです
が、

121
00:07:56.313 --> 00:08:02.880
そして、あなたがしようとする場合、Jav
a のための Weka
で非常に良い実装があります。

122
00:08:02.880 --> 00:08:07.230
さあ、ブーストの私達の時間に移動してみま
しょう、

123
00:08:07.230 --> 00:08:10.130
これは、最も成功している。

124
00:08:10.130 --> 00:08:15.820
私は、任意の予測モデリングの競争の中で信
じている

125
00:08:15.820 --> 00:08:22.745
画像の分類やビデオの予測ではありませんで
した。

126
00:08:22.745 --> 00:08:27.850
これは、アルゴリズムの最も支配的なタイプ
は、実際に1つを持ってされている

127
00:08:27.850 --> 00:08:33.922
これらの課題は、このタイプのブーストは非
常に成功しているので、

128
00:08:33.922 --> 00:08:35.650
しかし、それは何ですか?

129
00:08:35.650 --> 00:08:42.580
私は概念を理解するために再度同じような例
を与えることを試みる。

130
00:08:42.580 --> 00:08:46.605
同じデータセット、同じ機能を再度持ってい
るとしましょう。

131
00:08:46.605 --> 00:08:48.778
y 変数を予測しようとすると、

132
00:08:48.778 --> 00:08:53.390
我々は、モデルに合う、我々は予測を行う。

133
00:08:53.390 --> 00:08:55.160
次に何をするか、

134
00:08:55.160 --> 00:08:58.925
我々は、これらの予測のエラーを計算します
が、今回は、

135
00:08:58.925 --> 00:09:04.725
我々は、エラーの方向について興味を持って
いるので、絶対条件ではありません。

136
00:09:04.725 --> 00:09:13.420
我々は次に何をすべきかは、このエラーを取
ると我々はそれを追加する

137
00:09:13.420 --> 00:09:18.955
新しい y
変数は、エラーが今になるように

138
00:09:18.955 --> 00:09:26.290
このエラーを予測するために、新しいターゲ
ット変数と同じ機能を使用します。

139
00:09:26.290 --> 00:09:29.590
それは興味深い概念だと我々が望んでいた場
合、

140
00:09:29.590 --> 00:09:34.420
Rownum
に匹敵する予測をするように言いましょう

141
00:09:34.420 --> 00:09:37.405
私たちがすることは、私たちが取ることです

142
00:09:37.405 --> 00:09:43.855
私たちの最初の予測とし、我々は、新しい予
測を追加します

143
00:09:43.855 --> 00:09:48.220
これは、最初の予測のエラーに基づいていま
す。

144
00:09:48.220 --> 00:09:54.190
だから当初、我々は0.75
を持っているし、我々は0.2
を予測した。

145
00:09:54.190 --> 00:09:57.220
最終的な予測をするためには、

146
00:09:57.220 --> 00:10:02.060
我々は、1つのプラスは、他の0.95
に等しいと言うだろう。

147
00:10:02.060 --> 00:10:06.385
思い出すと、この列のターゲットは、1つだ
った。

148
00:10:06.385 --> 00:10:11.720
2つのモデルを使用して、我々は実際の答え
に近づくことができた。

149
00:10:11.720 --> 00:10:14.560
ブーストのこのフォームは、本当に作品

150
00:10:14.560 --> 00:10:18.630
本当によくエラーを最小限に抑えるために。

151
00:10:18.630 --> 00:10:24.215
ブーストのこのタイプに関連付けられている
特定のパラメータが再びあります。

152
00:10:24.215 --> 00:10:29.990
最初は再び学習率であり、それはかなり私は
前にそれを説明したように動作します。

153
00:10:29.990 --> 00:10:36.535
あなたが考慮する必要があるものは、これが
適用される方法です。

154
00:10:36.535 --> 00:10:41.045
我々は0.1
の学習率を持っているとしましょう。

155
00:10:41.045 --> 00:10:43.160
前の例では、

156
00:10:43.160 --> 00:10:49.850
予測は、2番目のモデルの0.2
だったところ、

157
00:10:49.850 --> 00:10:58.970
あなたが言うことは、私はその方向に向かっ
て私の予測を移動したいです 10%.

158
00:10:58.970 --> 00:11:01.860
あなたは予測が0.2
だった覚えていれば、

159
00:11:01.860 --> 00:11:05.590
これの 10% は0.02 です。

160
00:11:05.590 --> 00:11:11.160
これはどのくらい我々は、エラーの予測に向
かって移動します。

161
00:11:11.160 --> 00:11:13.750
これは、フィッティングを制御するための良
い方法です。

162
00:11:13.750 --> 00:11:16.890
ここでも、1つのモデルに頼らないようにし
ています。

163
00:11:16.890 --> 00:11:22.935
繰り返しになりますが、どのように多くの推
定を置く非常に重要です。

164
00:11:22.935 --> 00:11:28.705
通常、より良いですが、右の学習率でこれを
相殺する必要があります。

165
00:11:28.705 --> 00:11:34.615
すべてのモデルに適切な貢献があることを確
認する必要があります。

166
00:11:34.615 --> 00:11:36.656
多く置くことを意図すれば、

167
00:11:36.656 --> 00:11:41.780
その後、あなたのモデルは非常に、非常に小
さな貢献を持っていることを確認する必要が
あります。

168
00:11:41.780 --> 00:11:44.135
ここでも、これらのパラメータに基づいて決
定します。

169
00:11:44.135 --> 00:11:49.355
クロス検証とロジックは、前に説明したよう
に非常によく似ています。

170
00:11:49.355 --> 00:11:54.115
本当によく働く他の事は取っている

171
00:11:54.115 --> 00:11:59.445
モデルを構築するときに、行のサブセットま
たは列のサブセット。

172
00:11:59.445 --> 00:12:05.773
実際には、我々は前のアルゴリズムでこれを
使用しない理由はありません。

173
00:12:05.773 --> 00:12:06.806
方法は、そのベース、

174
00:12:06.806 --> 00:12:10.895
これは、ブーストのこのタイプでは、より一
般的です

175
00:12:10.895 --> 00:12:14.185
と内部的に非常によく動作します。

176
00:12:14.185 --> 00:12:18.310
入力モデルについては、私はこのメソッドを
見てきました

177
00:12:18.310 --> 00:12:22.330
この増加と実際によく働くが、理論的には、

178
00:12:22.330 --> 00:12:24.360
あなたが欲しいものを置くことができます。

179
00:12:24.360 --> 00:12:27.310
繰り返しになりますが、様々なブーストタイ
プがあります。

180
00:12:27.310 --> 00:12:32.570
私は2つの最も一般的な、またはより成功し
たと思う今

181
00:12:32.570 --> 00:12:38.245
予測モデリングコンテキストは、グラデーシ
ョンに基づく

182
00:12:38.245 --> 00:12:43.429
どれが実際に私はあなたとどのように予測し
、あなたが移動しない説明です

183
00:12:43.429 --> 00:12:49.045
あなたが学習率を適用する場合、その方向と
100パーセント。

184
00:12:49.045 --> 00:12:50.690
他の非常に興味深いもの、

185
00:12:50.690 --> 00:12:53.305
私が実際にそれを非常に効率的見つける

186
00:12:53.305 --> 00:12:57.190
特に分類の問題ではダーツです。

187
00:12:57.190 --> 00:13:02.900
ダーツ、それはドロップを課す

188
00:13:02.900 --> 00:13:09.075
木の貢献を制御するためにメカニズムを。

189
00:13:09.075 --> 00:13:13.035
これは、あなたが言う深い学習に由来する概
念です。

190
00:13:13.035 --> 00:13:17.180
"私は私のサンプルで新しい予測を行うたび
に、

191
00:13:17.180 --> 00:13:21.275
私は新しい見積もりを追加するたびに、また
は私は依存していないよ

192
00:13:21.275 --> 00:13:25.805
すべての以前の推定が、それらのサブセット
にのみ。

193
00:13:25.805 --> 00:13:27.510
ちょうどあなたの例を与えるために、

194
00:13:27.510 --> 00:13:31.660
我々は 20% のドロップアウト率を持っ
ているとしましょう。

195
00:13:31.660 --> 00:13:35.060
これまでのところ、我々は10の木を構築し
ている

196
00:13:35.060 --> 00:13:40.010
我々は、または10のモデルをし、我々は見
てみたい、

197
00:13:40.010 --> 00:13:43.400
我々は、新しい、11 1
を構築してください。

198
00:13:43.400 --> 00:13:49.550
2つの木を無作為に除外する

199
00:13:49.550 --> 00:13:55.820
我々は、11番目のツリーまたはその11モ
デルの予測を生成します。

200
00:13:55.820 --> 00:13:59.600
いくつかのモデルを無作為に除外することで
、

201
00:13:59.600 --> 00:14:02.630
この種の乱雑性を導入することにより、

202
00:14:02.630 --> 00:14:06.605
これは、正則化の形式として機能します。

203
00:14:06.605 --> 00:14:10.370
したがって、それは作るために多くのことが
できます

204
00:14:10.370 --> 00:14:14.900
同じデータに対して非常に十分に一般化モデ
ル。

205
00:14:14.900 --> 00:14:19.006
この概念は非常によく動作する傾向がある

206
00:14:19.006 --> 00:14:25.285
このタイプのブーストアルゴリズムは非常に
成功しているためです。

207
00:14:25.285 --> 00:14:28.434
多くの実装をしようとしている

208
00:14:28.434 --> 00:14:32.020
これらのアルゴリズムのさまざまな部分を改
善する。

209
00:14:32.020 --> 00:14:34.510
1つの本当に成功したアプリケーション

210
00:14:34.510 --> 00:14:38.835
特に比較予測モデリングの世界では
Xgboost です。

211
00:14:38.835 --> 00:14:44.230
それは非常にスケーラブルであり、それは多
くの損失関数をサポートしています。

212
00:14:44.230 --> 00:14:49.675
同時に、データ科学のためのすべての主要な
プログラミング言語で利用可能です。

213
00:14:49.675 --> 00:14:51.865
別の良い実装は Lightgbm です。

214
00:14:51.865 --> 00:14:54.659
名前暗示として、

215
00:14:54.659 --> 00:14:56.620
それは雷が速いです。

216
00:14:56.620 --> 00:15:03.515
また、多くのプログラミング言語でサポート
されており、多くの損失関数をサポートして
います。

217
00:15:03.515 --> 00:15:07.361
もう一つの興味深いケースは、水からの勾配
ブーストマシンです。

218
00:15:07.361 --> 00:15:09.760
何が本当に面白いの

219
00:15:09.760 --> 00:15:14.800
この実装では、カテゴリ変数を処理できる

220
00:15:14.800 --> 00:15:18.620
ボックスとそれはまた、実際のセットが付属
しています

221
00:15:18.620 --> 00:15:24.480
あなたが非常に徹底的にモデリングプロセス
を制御することができますパラメータ。

222
00:15:24.480 --> 00:15:29.110
またかなり新しいであるもう一つの興味深い
場合は Catboost である。

223
00:15:29.110 --> 00:15:35.525
これについて本当に良いのは、それがパラメ
ータの強力な初期設定が付属しているという
ことです。

224
00:15:35.525 --> 00:15:38.980
したがって、多くの時間のチューニングを費
やす必要はありません。

225
00:15:38.980 --> 00:15:40.375
私が前に述べたように、

226
00:15:40.375 --> 00:15:43.360
これは非常に時間のかかるプロセスすること
ができます。

227
00:15:43.360 --> 00:15:46.830
また、カテゴリ変数をボックスから処理する
こともできます。

228
00:15:46.830 --> 00:15:52.616
最終的に、私は実際に Scikit-学ぶ
の勾配ブーストマシンの実装が好きです。

229
00:15:52.616 --> 00:16:01.413
私が本当にこれについて好きなことは、あな
たがベースとして任意の scikit-学
習推定を置くことができるということです。

230
00:16:01.413 --> 00:16:03.835
これは、このビデオの終わりです。

231
00:16:03.835 --> 00:16:05.080
次のセッションでは、

232
00:16:05.080 --> 00:16:06.640
ドッキングについて説明します

233
00:16:06.640 --> 00:16:10.000
これも非常に人気があるので、ご期待くださ
い。


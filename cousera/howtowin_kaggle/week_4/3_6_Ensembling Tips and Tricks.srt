1
00:00:00.580 --> 00:00:09.095
さて、私はあなたの良いアンサンブルを作る
ために役立つだろういくつかのヒントをあげ
る

2
00:00:09.095 --> 00:00:12.505
または少なくともそれはあなたを開始するの
に役立ちます。

3
00:00:12.505 --> 00:00:15.590
とスタッキングの話をした時に前にも述べま
したが、

4
00:00:15.590 --> 00:00:19.070
何が非常に重要なの多様性を導入することで
す

5
00:00:19.070 --> 00:00:23.900
これを行う1つの方法は、使用するアルゴリ
ズムに基づいています。

6
00:00:23.900 --> 00:00:26.570
だから私は非常に発見したアーキテクチャ

7
00:00:26.570 --> 00:00:32.205
便利なのは、常に2つまたは3つのグラデー
ションブーストツリーを作ることです。

8
00:00:32.205 --> 00:00:37.520
そして、私はここで何をしようとしている私
はどちらか別の実装を試していないです

9
00:00:37.520 --> 00:00:42.050
または私はより大きな深さを持つものを作る
しようとすると、

10
00:00:42.050 --> 00:00:44.410
中間の深さの1つ、

11
00:00:44.410 --> 00:00:46.150
そして、1つの低深さと、

12
00:00:46.150 --> 00:00:49.880
そして、私は順番にそれの周りのパラメータ
を調整してみてください

13
00:00:49.880 --> 00:00:54.050
それらは可能な限り同様のパフォーマンスを
持っているようにする。

14
00:00:54.050 --> 00:00:56.900
もう一度、最終的な結果を期待する

15
00:00:56.900 --> 00:01:00.945
お互いにかなり多様であるいくつかのモデル
があります。

16
00:01:00.945 --> 00:01:02.500
もう一つ好きなのは、

17
00:01:02.500 --> 00:01:07.195
Keras か PyTorch
のどちらかから神経ネットを使ってる

18
00:01:07.195 --> 00:01:08.760
そしてもう一度、私がやろうとしていること
は、

19
00:01:08.760 --> 00:01:13.600
私は3つの隠された層を取るかなり深いもの
を作るしようとすると、

20
00:01:13.600 --> 00:01:15.105
そして、1つのミドルですが、

21
00:01:15.105 --> 00:01:17.090
2つの隠された層のように、

22
00:01:17.090 --> 00:01:20.130
としているものは、1つだけ隠し層としまし
ょう。

23
00:01:20.130 --> 00:01:23.540
やはり、多様化してみて、

24
00:01:23.540 --> 00:01:25.770
私はそれらをわずかに異なるようにしようと
すると、

25
00:01:25.770 --> 00:01:28.745
ためにしようとすると、新しい情報を取得し
ます。

26
00:01:28.745 --> 00:01:32.715
それから私はいくつかの
ExtraTrees
またはランダムフォレストを使用して、

27
00:01:32.715 --> 00:01:36.440
彼らは非常によく働く時間のほとんどは、彼
らは通常、追加します。

28
00:01:36.440 --> 00:01:40.810
私もいくつかの線形モデルまたはリッジ回帰
を追加します。

29
00:01:40.810 --> 00:01:47.560
私も scikit からリニアサポートベ
クトルマシンのように-学ぶ。

30
00:01:47.560 --> 00:01:52.245
KNN モデルは、多くの問題で非常に良い
値をしたい傾向がある

31
00:01:52.245 --> 00:01:55.830
個別に見れば意外なので、

32
00:01:55.830 --> 00:02:00.360
彼らはめったに出口ブーストと比較して良い
パフォーマンスを持っている

33
00:02:00.360 --> 00:02:07.135
彼らは一般的にメタモデルのコンテキストで
かなりの値を追加する傾向があること。

34
00:02:07.135 --> 00:02:09.515
私は個人的に因数分解機が好きですが、

35
00:02:09.515 --> 00:02:12.232
私はそれらを非常に有用見つける

36
00:02:12.232 --> 00:02:18.188
特に libFM
は、すべての一対の相互作用を因数分解。

37
00:02:18.188 --> 00:02:24.360
データが許可されている場合、データがそれ
ほど大きくない場合は、

38
00:02:24.360 --> 00:02:32.550
私はまた、RBF のような非線型のカーネ
ルのいくつかの並べ替えで、役に立つサポー
トベクトルマシンを見つける。

39
00:02:32.550 --> 00:02:35.580
彼らは非常によく、特に回帰では動作しませ
ん。

40
00:02:35.580 --> 00:02:38.520
あなたは多様性を導入することができます他
の方法

41
00:02:38.520 --> 00:02:44.666
は、独自の入力データで作成した変換で、

42
00:02:44.666 --> 00:02:47.220
一方、実際に実行することができます

43
00:02:47.220 --> 00:02:52.740
わずかに異なる入力データを持つだけで、ま
ったく同じモデル、

44
00:02:52.740 --> 00:02:55.830
多様性を生成するのに十分です。

45
00:02:55.830 --> 00:03:00.345
だから、我々はカテゴリの機能のために見て
1つのホットエンコーディングトレインされ
、

46
00:03:00.345 --> 00:03:06.120
カテゴリ値をインデックスに置き換える場合
と同様に、ラベルのエンコード。

47
00:03:06.120 --> 00:03:09.422
私は、尤度符号化またはターゲット符号化を
使用することができます

48
00:03:09.422 --> 00:03:13.860
または私は頻度か数と分類を取り替えること
ができる。

49
00:03:13.860 --> 00:03:19.788
数値的な特徴については、外れ値かどうかに
気をつけてみます。

50
00:03:19.788 --> 00:03:25.290
私は、変数を X から Z に bin
に、

51
00:03:25.290 --> 00:03:28.480
Z からすべて、など。

52
00:03:28.480 --> 00:03:31.770
私は滑らかする方法であるデリバティブを使
用して

53
00:03:31.770 --> 00:03:37.950
あなたの変数または私はパーセンタイルまた
はスケーリングを使用することができます

54
00:03:37.950 --> 00:03:45.030
これらは私が別のモデルで私の数値機能を変
更するために使用するさまざまな方法です。

55
00:03:45.030 --> 00:03:47.360
それから私も、列1のような相互作用を探る

56
00:03:47.360 --> 00:03:51.620
複数列2、または列1プラス列2。

57
00:03:51.620 --> 00:03:57.660
私はすべての可能な相互作用を探るので、3
つまたは4つのレベルに行くことができます
。

58
00:03:57.660 --> 00:04:04.380
相互作用を探索するもう1つの方法は、gr
oupby ステートメントを使用すると、

59
00:04:04.380 --> 00:04:08.625
カテゴリー機能のすべてのカテゴリを指定す
ると、

60
00:04:08.625 --> 00:04:11.565
たとえば、別の変数の平均を計算します。

61
00:04:11.565 --> 00:04:15.290
特定の状況では、これは非常によく動作しま
す。

62
00:04:15.290 --> 00:04:17.955
もう一つは、

63
00:04:17.955 --> 00:04:21.600
私は試してみて、k-手段のような技術を監
督する

64
00:04:21.600 --> 00:04:27.748
または SVM、または
PCA、または数値の特徴。

65
00:04:27.748 --> 00:04:33.315
繰り返しますが、それはかなり頻繁に値を追
加する傾向がある。

66
00:04:33.315 --> 00:04:35.045
今、他のすべての層で、

67
00:04:35.045 --> 00:04:38.730
あなたが心に留めておく必要があるものは、
あなたが作る必要があるということです

68
00:04:38.730 --> 00:04:44.805
あなたのアルゴリズムは小さくまたは浅く、
より制約があります。

69
00:04:44.805 --> 00:04:46.210
これはどういう意味ですか?

70
00:04:46.210 --> 00:04:47.452
グラデーションブーストツリーでは、

71
00:04:47.452 --> 00:04:49.130
あなたは非常に小さな深さを置く必要がある
ことを意味し、

72
00:04:49.130 --> 00:04:51.280
2、3のように

73
00:04:51.280 --> 00:04:55.350
線形モデルは、高い正則化を置く必要がある
。

74
00:04:55.350 --> 00:04:58.755
余分な木は、ちょうどそれらが大きすぎるこ
とはありません

75
00:04:58.755 --> 00:05:01.735
彼らは非常によく動作する傾向がある。

76
00:05:01.735 --> 00:05:04.150
浅いニューラルネットワーク、再び、

77
00:05:04.150 --> 00:05:07.610
私は通常、ここに1つの層の最大2層を置く

78
00:05:07.610 --> 00:05:09.830
その多くの隠されたニューロンで。

79
00:05:09.830 --> 00:05:15.845
我々は、BrayCurtis 距離や
KNN を試すことができます

80
00:05:15.845 --> 00:05:22.360
時にはそれが実際に我々が使用できる最高の
直線的な重みをブルートフォースに優れてい
る。

81
00:05:22.360 --> 00:05:30.218
実際には、クロス検証では、再び、対称最高
の線形重みを見つけることを試みる。

82
00:05:30.218 --> 00:05:34.900
また、この後のレベルでさまざまな機能エン
ジニアリングを展開することもできます。

83
00:05:34.900 --> 00:05:36.420
私たちにできることの一つは、

84
00:05:36.420 --> 00:05:41.238
我々は、モデルの予測の間に一対の違いを作
成することが、

85
00:05:41.238 --> 00:05:44.922
彼らは非常に相関する傾向があるため、これ
は助けることができる。

86
00:05:44.922 --> 00:05:47.220
そのため、違いを作成すると、

87
00:05:47.220 --> 00:05:57.030
基本的に、各新しいモデルがもたらすものに
焦点を当てるようにモデルを強制します。

88
00:05:57.030 --> 00:05:59.935
また、行のような統計情報を作成することが
できます

89
00:05:59.935 --> 00:06:03.520
すべてのモデルの平均値または標準偏差。

90
00:06:03.520 --> 00:06:06.565
これはほぼアンサンブルのようなもので、

91
00:06:06.565 --> 00:06:12.691
いくつかのアンサンブル機能を自分で作成し
ます。

92
00:06:12.691 --> 00:06:16.050
また、標準の機能選択テクニックを展開する
こともできます。

93
00:06:16.050 --> 00:06:20.765
どの機能が重要かを見つけるために使用する
ので、任意のテクニック。

94
00:06:20.765 --> 00:06:24.390
あなたはここでどのモデルが重要であり、そ
れらを除外見つけるために使用することがで
きます。

95
00:06:24.390 --> 00:06:29.960
経験則として、経験則として言いましょう、

96
00:06:29.960 --> 00:06:33.770
私は非常によく働くことがわかりました。

97
00:06:33.770 --> 00:06:38.555
私は、100% の信頼ではなく、一般的な
アイデアとして、意味

98
00:06:38.555 --> 00:06:43.220
それは1つの層の7ポイント5つのモデルご
とに、

99
00:06:43.220 --> 00:06:48.635
我々は、後続の層に1つのモデルを追加しま
す。

100
00:06:48.635 --> 00:06:50.885
7つのモデルがあるなら

101
00:06:50.885 --> 00:06:53.315
metamodel が1人いる

102
00:06:53.315 --> 00:06:55.040
我々は15のモデルを持っている場合、

103
00:06:55.040 --> 00:07:00.095
その後、我々は2つのメタモデルなどがあり
ます。

104
00:07:00.095 --> 00:07:03.356
我々は非常に留意する必要があるということ
です,

105
00:07:03.356 --> 00:07:06.455
このホールドアウト機構を使っているにもか
かわらず、

106
00:07:06.455 --> 00:07:09.790
我々はまだリークを導入する可能性がありま
す。

107
00:07:09.790 --> 00:07:19.463
どのように我々はこれを制御することができ
ます右 K を選択して、

108
00:07:19.463 --> 00:07:22.165
私はクロス検証で K を述べた。

109
00:07:22.165 --> 00:07:25.430
そこで非常に高い値を選択すると、

110
00:07:25.430 --> 00:07:28.985
これは、各モデルが使用することを意味しま
す

111
00:07:28.985 --> 00:07:31.920
より多くのトレーニングデータは、それが作
るとき

112
00:07:31.920 --> 00:07:36.205
予測したがって、それは非常によく一般化し
ない場合があります。

113
00:07:36.205 --> 00:07:41.985
同時に、トレーニングデータに関するすべて
の情報が排出されます。

114
00:07:41.985 --> 00:07:48.950
ここでも、このバイアス分散のしきい値を見
つけようとしています。

115
00:07:48.950 --> 00:07:52.677
だから、ここで間違いを見つける簡単な方法
はありません。

116
00:07:52.677 --> 00:07:55.033
通常は、テストデータセットがあり、

117
00:07:55.033 --> 00:08:00.710
そして、あなたのクロス検証では、次の改善
がある場合は、参照してください

118
00:08:00.710 --> 00:08:03.644
テストデータには表示されません。

119
00:08:03.644 --> 00:08:10.340
その後、戻って、K-ひだの数を減らすため
にしようとする必要があります。

120
00:08:10.340 --> 00:08:13.985
そしてうまくいけば、これはより一般化する
、

121
00:08:13.985 --> 00:08:20.665
少なくともそれは実際に働いた方法である。

122
00:08:20.665 --> 00:08:23.485
私はあなたがスタッキングのために使用でき
るいくつかのソフトウェアをリストアップし
ます

123
00:08:23.485 --> 00:08:27.686
一つは私の研究の産物である
StackNet である。

124
00:08:27.686 --> 00:08:30.261
あなたが望むなら、それに打撃を与えること
ができます。

125
00:08:30.261 --> 00:08:32.435
あなたが試すことができるもう一つの事、

126
00:08:32.435 --> 00:08:33.594
H2O
から積み上げられたアンサンブルです。

127
00:08:33.594 --> 00:08:36.110
という新しいソフトもありますが、

128
00:08:36.110 --> 00:08:44.475
Xcessic と Python はまた
、非常に多様な、そして大きなアンサンブル
を作成することができます。

129
00:08:44.475 --> 00:08:50.210
それを使用したい場合は StackNet
について知っているいくつかのより多くの事
、

130
00:08:50.210 --> 00:08:55.190
それは今、我々が使用する一般的な機械学習
ツールの多くをサポートしているということ
です

131
00:08:55.190 --> 00:08:56.390
xgboost、lightgbm、H2O
のように。

132
00:08:56.390 --> 00:09:00.420
だから、あなたはかなり持っていることがで
きます

133
00:09:00.420 --> 00:09:05.570
強力なアンサンブルを構築するために利用で
きるすべての偉大なツール。

134
00:09:05.570 --> 00:09:12.090
我々は多くの機会を議論する必要はありませ
んでしたが、興味深いの追加、それにもかか
わらず、

135
00:09:12.090 --> 00:09:14.170
結構面白いですが、

136
00:09:14.170 --> 00:09:21.515
は、回帰問題で分類子を実行でき、その逆も
可能です。

137
00:09:21.515 --> 00:09:24.710
つまり、エイズを予測するのではなく、

138
00:09:24.710 --> 00:09:26.400
予測できる

139
00:09:26.400 --> 00:09:30.350
この人は50歳以上住んでいるかどうか。

140
00:09:30.350 --> 00:09:37.845
これは、特定の分野では、モデルの焦点にな
り、これは非常にうまく機能する傾向がある
、

141
00:09:37.845 --> 00:09:40.410
とメタモデルができるようになります

142
00:09:40.410 --> 00:09:44.288
この情報を活用して、エイズの予測を改善し
ます。

143
00:09:44.288 --> 00:09:46.190
だから、これは非常によく動作する傾向があ
る。

144
00:09:46.190 --> 00:09:48.530
私はそれが非常に多くの有用な発見した。

145
00:09:48.530 --> 00:09:51.395
従って、これはあなたが探検するべきである
何かである。

146
00:09:51.395 --> 00:09:57.490
一般的に、ソフトウェアはすでに多くのトッ
プ10のソリューションを持って、

147
00:09:57.490 --> 00:09:59.200
私だけじゃない

148
00:09:59.200 --> 00:10:02.535
だから、テストされています。

149
00:10:02.535 --> 00:10:05.980
そして、例のセクションでは、

150
00:10:05.980 --> 00:10:10.840
私は本当に面白い例があると思う

151
00:10:10.840 --> 00:10:16.340
アマゾンによって催された競争の非常に普及
した一種。

152
00:10:16.340 --> 00:10:19.255
この例では StackNet を使用し、

153
00:10:19.255 --> 00:10:22.561
そして、あなたはトップ10を得ることがで
きる方法を見ることができます。

154
00:10:22.561 --> 00:10:25.930
しかし、原則的には、これは非常に素晴らし
い競争です。

155
00:10:25.930 --> 00:10:29.790
それは非常に大きなデータを持っていない,
も非常に小さい.

156
00:10:29.790 --> 00:10:34.415
特にカテゴリデータでは、多くの変換を試す
ことができます。

157
00:10:34.415 --> 00:10:38.600
そして、それは非常に良い場所を開始するこ
とです。

158
00:10:38.600 --> 00:10:45.475
私が言いたかった他の物は、StackNe
t が教育の味をまた持っているということ
です。

159
00:10:45.475 --> 00:10:47.715
それなりに作ってましたが、

160
00:10:47.715 --> 00:10:49.680
私は心にこの焦点を持っている。

161
00:10:49.680 --> 00:10:55.800
だから、あなたはそれがすべての異なるツー
ルを残してパラメータのセクションに行く場
合、

162
00:10:55.800 --> 00:11:02.335
どのパラメータが最も重要であるかを伝える
セクションを見つけることができます。

163
00:11:02.335 --> 00:11:04.285
これは私の経験に基づいています。

164
00:11:04.285 --> 00:11:09.320
たとえば、xgboost
では、num_round
は重要ですが、eta は重要です。

165
00:11:09.320 --> 00:11:14.883
あなたは、その後、この情報を取ることがで
きると StackNet
外でもそれを使用してください。

166
00:11:14.883 --> 00:11:18.361
たとえば、これを使用する場合は、Pyth
on に由来しています。

167
00:11:18.361 --> 00:11:20.850
パラメータは一般的に同じですので。

168
00:11:20.850 --> 00:11:23.150
それで、どこから始めたらいいのかわからな
いのであれば、

169
00:11:23.150 --> 00:11:26.265
どのようにここを見て、これらのパラメータ
が重要である参照してください。

170
00:11:26.265 --> 00:11:32.361
と良い解像度を取得しようとするためにそれ
らに焦点を当てる。

171
00:11:32.361 --> 00:11:35.665
このセッションを閉じる前に、

172
00:11:35.665 --> 00:11:38.410
教えていただきたいことがいくつかあります
。

173
00:11:38.410 --> 00:11:41.785
そこに行って、学んだことを適用してくださ
い。

174
00:11:41.785 --> 00:11:46.225
理論的にしか学べないようなことはありませ
ん。

175
00:11:46.225 --> 00:11:49.550
学ぶべき最もよい事は戦場で出血することで
ある。

176
00:11:49.550 --> 00:11:50.860
コンペティションを選択します。

177
00:11:50.860 --> 00:11:55.518
いくつかのチュートリアルとして命名されて
から始めることができます。

178
00:11:55.518 --> 00:11:59.285
そして、あなたは本当の大会に行くことがで
きます。

179
00:11:59.285 --> 00:12:00.455
これはあなたが学んだ方法です。

180
00:12:00.455 --> 00:12:04.443
あなたは、明らかに、より実践的な経験を得
る必要があります。

181
00:12:04.443 --> 00:12:11.940
上の人とのギャップがまだあるのを見たら士
気ないで、

182
00:12:11.940 --> 00:12:14.106
調整するのに時間がかかるからです。

183
00:12:14.106 --> 00:12:16.275
あなたはダイナミクスを学ぶ必要があります
。

184
00:12:16.275 --> 00:12:18.865
あなたは、どのように作業する必要が理解す
る必要があります

185
00:12:18.865 --> 00:12:20.743
ここで、あなたの仕事を最適化する

186
00:12:20.743 --> 00:12:23.572
どのように強度を最大化します。

187
00:12:23.572 --> 00:12:25.560
だから、それは少し時間がかかります。

188
00:12:25.560 --> 00:12:27.285
しかし、あなたはそこに着くでしょう。

189
00:12:27.285 --> 00:12:29.815
私の主なポイントは、失望を取得していない

190
00:12:29.815 --> 00:12:31.590
あなたは間違いなくそこに着くでしょう。

191
00:12:31.590 --> 00:12:36.755
常に私を助けている何か私のコードを保存す
ることです。

192
00:12:36.755 --> 00:12:40.740
それは沈黙の最後に言ってみましょう。それ
はいいですね。

193
00:12:40.740 --> 00:12:44.640
次の競争でこのコードを家に持っていくこと
ができるので、

194
00:12:44.640 --> 00:12:46.315
そして、それを改善してみてください。

195
00:12:46.315 --> 00:12:51.775
だから、これは徐々に、はるかに強力なパイ
プラインを構築するのに役立ちます

196
00:12:51.775 --> 00:12:55.619
同時に、時間を節約できます。

197
00:12:55.619 --> 00:13:01.160
個人的に助けてくれたものは、コラボレーシ
ョンを模索することです。

198
00:13:01.160 --> 00:13:03.255
これらは一般的に、と思いますが、

199
00:13:03.255 --> 00:13:05.025
そこに2つの要素があります。

200
00:13:05.025 --> 00:13:07.813
一つは、あなたは間違いなく、あなたの結果
を向上させる

201
00:13:07.813 --> 00:13:11.610
すべての人が異なる角度から問題を押収する
ので、

202
00:13:11.610 --> 00:13:14.230
異なる情報を抽出することができます。

203
00:13:14.230 --> 00:13:18.085
従って、力を合わせるときスコアはよりよい
、

204
00:13:18.085 --> 00:13:20.085
しかし、それはまた、より楽しいです。

205
00:13:20.085 --> 00:13:22.595
そして、あなたがそれをしているので、

206
00:13:22.595 --> 00:13:24.800
あなたもそれを楽しむかもしれない。

207
00:13:24.800 --> 00:13:27.920
そして私が強調する必要がある他の事は一般
に、

208
00:13:27.920 --> 00:13:29.785
あなたは、フォーラムで接続する必要があり
ます

209
00:13:29.785 --> 00:13:31.700
とコード、およびカーネル、

210
00:13:31.700 --> 00:13:33.512
コツがあるかもしれないので、

211
00:13:33.512 --> 00:13:37.520
出てくる最先端の解決策もあるかもしれませ
んが、

212
00:13:37.520 --> 00:13:41.675
そして、彼らは大幅にリーダーボードをふる
いにかけることができます。

213
00:13:41.675 --> 00:13:44.060
だから一般的に、あなたが読み続ける必要が
ある、

214
00:13:44.060 --> 00:13:46.829
それを念頭に

215
00:13:46.829 --> 00:13:51.750
これは、我々が持っているシリーズの最後の
ビデオです。

216
00:13:51.750 --> 00:13:57.165
検査とサンプルメソッドは、単純なサンプリ
ングになります。

217
00:13:57.165 --> 00:13:59.432
それから袋詰めに行って、

218
00:13:59.432 --> 00:14:03.397
ブースティング、スタッキング、多層積層。

219
00:14:03.397 --> 00:14:06.640
うまくいけば、この便利な発見した。

220
00:14:06.640 --> 00:14:09.875
この度は私に感謝します

221
00:14:09.875 --> 00:14:11.365
私も楽しかったです。

222
00:14:11.365 --> 00:14:13.920
そして、そこに行くと、

223
00:14:13.920 --> 00:14:15.670
私たちを誇りに思って、誰が知っている?

224
00:14:15.670 --> 00:14:19.000
リーダーボードの次の2人はあなたかもしれ
ません。


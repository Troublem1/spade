1
00:00:00.000 --> 00:00:04.740
みなさん。これはマリ
Michailidis
であり、我々は継続する

2
00:00:04.740 --> 00:00:09.425
アンサンブルの方法についての私達の議論。

3
00:00:09.425 --> 00:00:12.555
以前は、いくつかの簡単な平均化方法を見ま
した。

4
00:00:12.555 --> 00:00:14.935
今回は、袋詰めについて話し合いますが、

5
00:00:14.935 --> 00:00:19.140
これは、ensembling
の非常に人気のある効率的なフォームです。

6
00:00:19.140 --> 00:00:23.670
袋詰めは何ですか?袋詰めは平均を意味する

7
00:00:23.670 --> 00:00:31.110
予測力を向上させるための手段として、同じ
モデルのわずかに異なるバージョン。

8
00:00:31.110 --> 00:00:35.935
袋詰めの一般的な、非常に成功したアプリケ
ーションは、ランダムな森林です。

9
00:00:35.935 --> 00:00:38.790
ここで、多くの異なるバージョンを実行する

10
00:00:38.790 --> 00:00:42.900
デシジョンツリーは、より良い予測を得るた
めに。

11
00:00:42.900 --> 00:00:45.510
なぜ袋詰めを考慮する必要があります?

12
00:00:45.510 --> 00:00:48.188
一般的に、モデリングプロセスでは、

13
00:00:48.188 --> 00:00:52.030
エラーの主な原因は2つあります。

14
00:00:52.030 --> 00:00:56.885
多くの場合、underfitting と
呼ばれるバイアスによるエラーがあります。

15
00:00:56.885 --> 00:01:01.750
そして、分散によるエラーはしばしばオーバ
ーフィット回避と呼ばれます。

16
00:01:01.750 --> 00:01:03.874
これをよく理解するためには、

17
00:01:03.874 --> 00:01:07.500
私はあなたに2つの反対の例をあげる。

18
00:01:07.500 --> 00:01:10.347
高バイアスと低分散の1つ

19
00:01:10.347 --> 00:01:14.490
その逆の順序でより良い概念を理解する。

20
00:01:14.490 --> 00:01:18.280
高バイアスと低分散の例を見てみましょう。

21
00:01:18.280 --> 00:01:21.655
私たちには、若く言わせている人がいますが
、

22
00:01:21.655 --> 00:01:24.840
30歳未満と私たちは知っているこの人は

23
00:01:24.840 --> 00:01:28.110
かなり裕福で彼を見つけようとしてる

24
00:01:28.110 --> 00:01:32.685
この人は、レースや高価な車を購入します。

25
00:01:32.685 --> 00:01:35.610
私達のモデルは高い分散を、

26
00:01:35.610 --> 00:01:39.665
この人だと言えば偏りが高い

27
00:01:39.665 --> 00:01:45.550
若いと私は彼が高価な車を購入するつもりは
ないと思う。

28
00:01:45.550 --> 00:01:49.015
モデルがここで行ったことは、

29
00:01:49.015 --> 00:01:52.720
データ内の非常に深い関係を探る。

30
00:01:52.720 --> 00:01:57.150
この人は関係ない

31
00:01:57.150 --> 00:02:01.925
それが車を買うことに関してはたくさんのお
金があれば若い。

32
00:02:01.925 --> 00:02:05.850
それは別の関係を模索していない。

33
00:02:05.850 --> 00:02:10.125
つまり、underfitted
されてしまったのです。

34
00:02:10.125 --> 00:02:17.175
ただし、これは、この関係のため、低分散に
関連付けられても、

35
00:02:17.175 --> 00:02:23.310
一般的に若い人が高価な車を買わないという
ことは、一般的に

36
00:02:23.310 --> 00:02:30.570
この情報は、予見されたデータで十分に一般
化することを期待するので、真。

37
00:02:30.570 --> 00:02:34.435
したがって、この例では、分散は低くなって
います。

38
00:02:34.435 --> 00:02:38.300
今は、他の方法で周りを見てみようと、

39
00:02:38.300 --> 00:02:43.470
高分散と低バイアスの例。

40
00:02:43.470 --> 00:02:46.275
人がいると仮定しましょう。

41
00:02:46.275 --> 00:02:48.045
名前はジョン

42
00:02:48.045 --> 00:02:50.285
彼は、緑の家に住んでいる

43
00:02:50.285 --> 00:02:56.300
茶色の目をしており、我々は彼が車を購入す
る見てみたい。

44
00:02:56.300 --> 00:03:02.090
これらの関係を見つけるためにとても深くな
ったモデル

45
00:03:02.090 --> 00:03:05.155
それは持っているので、実際には低バイアス
を持っている

46
00:03:05.155 --> 00:03:09.455
実際には、トレーニングデータに関する多く
の情報を探った。

47
00:03:09.455 --> 00:03:12.720
しかし、それは間違いを犯している

48
00:03:12.720 --> 00:03:17.690
これらの特性を持っているすべての人が車を
購入する予定です。

49
00:03:17.690 --> 00:03:22.375
したがって、それはすべきではない何かのた
めに一般化。

50
00:03:22.375 --> 00:03:26.310
言い換えれば、それはすでに情報を使い果た
している

51
00:03:26.310 --> 00:03:30.900
トレーニングデータと結果は重要ではありま
せん。

52
00:03:30.900 --> 00:03:36.250
だから、ここでは、実際には高分散が低バイ
アスしている。

53
00:03:36.250 --> 00:03:42.090
予測誤差とモデルの複雑さの関係を視覚化す
る場合は、

54
00:03:42.090 --> 00:03:43.805
それはそのようになります。

55
00:03:43.805 --> 00:03:47.865
我々は、モデルの訓練を開始すると、

56
00:03:47.865 --> 00:03:50.910
我々は、トレーニングエラーは、エラーを確
認することができます

57
00:03:50.910 --> 00:03:53.730
そのトレーニングデータが減少し、

58
00:03:53.730 --> 00:03:59.970
予測が簡単に一般化ため、テストデータでも
同じことが起こります。

59
00:03:59.970 --> 00:04:04.575
彼らは簡単です。しかし、ポイントの後、

60
00:04:04.575 --> 00:04:10.300
トレーニングエラーの改善は、テストデータ
には実現されません。

61
00:04:10.300 --> 00:04:16.599
これは、モデルが疲れる情報を介して起動す
るポイントです,

62
00:04:16.599 --> 00:04:20.475
一般化されていない予測を作成します。

63
00:04:20.475 --> 00:04:27.285
これは、袋詰めが実際に遊びに来て、それが
最大限の価値を提供しています。

64
00:04:27.285 --> 00:04:33.717
わずかに異なるか、またはランダム化された
モデルと言わせることで、

65
00:04:33.717 --> 00:04:39.160
我々は、予測は非常に高い分散を読んでいな
いことを確認します。

66
00:04:39.160 --> 00:04:41.410
彼らは一般的により一般化ている。

67
00:04:41.410 --> 00:04:45.835
私たちは、トレーニングデータの情報を排出
しません。

68
00:04:45.835 --> 00:04:47.185
同時に

69
00:04:47.185 --> 00:04:53.365
私たちは、その前に、わずかに異なるモデル
の平均を見た

70
00:04:53.365 --> 00:04:59.855
我々は一般的に良い予測を得ることができる
と我々は10のモデルでは、と仮定すること
ができます

71
00:04:59.855 --> 00:05:06.155
我々はまだトレーニングデータに関する非常
に重要な情報を見つけることができます。

72
00:05:06.155 --> 00:05:11.490
したがって、これはなぜ袋詰めは非常によく
、個人的に動作する傾向がある

73
00:05:11.490 --> 00:05:12.915
いつも袋詰めを使っています。

74
00:05:12.915 --> 00:05:17.290
私が「モデルに合わせて」と言ったら、実際
に持っているモデルに合わなくて

75
00:05:17.290 --> 00:05:23.835
このモデルのようにおそらく別のモデルの袋
詰めのバージョンに合わせてください。

76
00:05:23.835 --> 00:05:27.935
袋詰めに関連付けられているパラメータ

77
00:05:27.935 --> 00:05:30.210
最初は種です。

78
00:05:30.210 --> 00:05:35.305
我々は、多くのアルゴリズムはいくつかの無
作為化手続きを理解することができます

79
00:05:35.305 --> 00:05:41.630
従って種を変えることによってそれらがわず
かに別様になされることを保障する。

80
00:05:41.630 --> 00:05:48.485
同時に、少ない行数でモデルを実行すること
も、ブートストラップを使用することもでき
ます。

81
00:05:48.485 --> 00:05:53.760
ブートストラップは、作成する意味での行サ
ブサンプリングとは異なります。

82
00:05:53.760 --> 00:05:56.820
人工的なデータセットを

83
00:05:56.820 --> 00:06:00.151
データがトレーニングデータを 3 ~ 4
回行しているとします。

84
00:06:00.151 --> 00:06:05.335
トレーニングデータからランダムデータセッ
トを作成します。

85
00:06:05.335 --> 00:06:09.570
乱雑性の異なる形式は、シャッフルで帰属す
ることができます。

86
00:06:09.570 --> 00:06:10.840
いくつかのアルゴリズムがありますが、

87
00:06:10.840 --> 00:06:13.840
これは、データの順序に敏感です。

88
00:06:13.840 --> 00:06:18.580
順序を変えることによってモデルがかなり異
なっているようになることを保障する。

89
00:06:18.580 --> 00:06:21.680
別の方法は、列のランダムなサンプルをデー
トすることです

90
00:06:21.680 --> 00:06:27.275
ので、異なる機能やデータの異なる変数に入
札モデル。

91
00:06:27.275 --> 00:06:30.300
次に、モデル固有のパラメータがあります。

92
00:06:30.300 --> 00:06:32.295
たとえば、線形モデルでは、

93
00:06:32.295 --> 00:06:36.300
あなたは10の異なる let
のを構築しようとするでしょう

94
00:06:36.300 --> 00:06:42.115
わずかに異なる正則化パラメータを持つロジ
スティック回帰。

95
00:06:42.115 --> 00:06:46.250
明らかに、また、モデルの数を制御すること
ができます

96
00:06:46.250 --> 00:06:50.995
あなたのアンサンブルに含めるか、この場合
には、バッグを呼び出します。

97
00:06:50.995 --> 00:06:55.120
通常、我々は10以上の値をここに置くが、

98
00:06:55.120 --> 00:06:57.631
原則、入れた袋が多ければ多いほど、

99
00:06:57.631 --> 00:06:59.310
それはあなたを傷つけることはありません。

100
00:06:59.310 --> 00:07:05.370
それはより良い結果になりますが、いくつか
のポイントの後、パフォーマンスがプラトー
を開始します。

101
00:07:05.370 --> 00:07:10.470
従って時間との費用の利点があるが、原則的
には、

102
00:07:10.470 --> 00:07:14.930
より多くの袋は、一般的に優れているとオプ
ションで、

103
00:07:14.930 --> 00:07:16.681
並列処理を適用することもできます。

104
00:07:16.681 --> 00:07:21.317
モデルの袋詰めはお互いに独立しており、

105
00:07:21.317 --> 00:07:24.680
それはあなたが同時にそれらの多くを構築し
、作ることができることを意味

106
00:07:24.680 --> 00:07:29.035
あなたの計算力の完全な使用。

107
00:07:29.035 --> 00:07:33.460
今、我々は袋詰めについての例を見ることが
できますが、私はそれを行う前に、

108
00:07:33.460 --> 00:07:35.210
ただ、それを知らせるために

109
00:07:35.210 --> 00:07:42.220
scikit が Python で持って
いる袋詰めの推定は、実際には非常にクール
です。

110
00:07:42.220 --> 00:07:45.330
したがって、私はそれらをお勧めします。

111
00:07:45.330 --> 00:07:51.955
これは、私がかなり頻繁に使用する典型的な
15行のコードです。

112
00:07:51.955 --> 00:07:55.915
彼らは本当に単純なようだが、実際には非常
に効率的だ。

113
00:07:55.915 --> 00:08:00.968
テストデータセットにトレーニングがあり、
変数をターゲットにすると仮定すると、

114
00:08:00.968 --> 00:08:05.360
何をすべきかは、いくつかの袋詰めパラメー
タを指定します。

115
00:08:05.360 --> 00:08:10.060
ランダムフォレストで使用するモデルを教え
てください。

116
00:08:10.060 --> 00:08:11.850
どのように多くの袋を実行するつもりですか
?

117
00:08:11.850 --> 00:08:13.960
10. どのような私の種になります?

118
00:08:13.960 --> 00:08:16.575
1 つ。次に、オブジェクトを作成し、

119
00:08:16.575 --> 00:08:20.570
予測を保存する空のオブジェクト

120
00:08:20.570 --> 00:08:24.950
次に、指定した数のバッグに対してループを
実行します。

121
00:08:24.950 --> 00:08:27.480
このループでは、同じことを繰り返します。

122
00:08:27.480 --> 00:08:30.510
種を変えてモデルに餌をやる

123
00:08:30.510 --> 00:08:35.600
テストデータで予測を行い、これらの予測を
保存すると、

124
00:08:35.600 --> 00:08:38.970
あなただけのこれらの予測の平均を取る。

125
00:08:38.970 --> 00:08:41.230
これは、セッションの終わりです。

126
00:08:41.230 --> 00:08:46.245
このセッションでは、ensembling
の一般的な形式として袋詰めについて議論し
た。

127
00:08:46.245 --> 00:08:50.146
我々は、バリアントと関連して袋詰めを見て

128
00:08:50.146 --> 00:08:55.380
バイアスと我々はまた、それを使用する方法
についての例で見た。

129
00:08:55.380 --> 00:08:59.935
ありがとうございました。次のセッションで
は、ブーストについて説明します

130
00:08:59.935 --> 00:09:04.000
これも非常に調子に滞在し、良い一日を持っ
て人気があります。


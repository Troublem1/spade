1
00:00:00.025 --> 00:00:05.950
音こんにちは、戻ってお待ちしております。

2
00:00:05.950 --> 00:00:10.632
以前のビデオでは、検証とオーバーフィット
回避の概念について説明しました。

3
00:00:10.632 --> 00:00:14.250
検証戦略に基づいて選択する方法について説
明しました

4
00:00:14.250 --> 00:00:16.460
我々が持っているデータのプロパティについ
て。

5
00:00:16.460 --> 00:00:22.450
そして最後に、私たちは、主催者によって行
われたデータ分割を識別することを学んだ。

6
00:00:22.450 --> 00:00:27.363
すべてのこの作業が行われている後、我々は
正直に、関係が意志を期待し、

7
00:00:27.363 --> 00:00:30.230
ある意味では、私たちのためのリーダーボー
ドに置き換えます。

8
00:00:30.230 --> 00:00:34.928
それは我々が検証で参照してくださいスコア
は同じになります

9
00:00:34.928 --> 00:00:35.890
プライベートリーダーボード。

10
00:00:35.890 --> 00:00:38.640
または、少なくとも、我々のモデルを改善し
、

11
00:00:38.640 --> 00:00:42.810
検証では、プライベートリーダーボードの改
善が行われます。

12
00:00:42.810 --> 00:00:48.290
そして、これは通常、本当ですが、時にはこ
こでいくつかの問題が発生します。

13
00:00:48.290 --> 00:00:53.410
ほとんどの場合、これらの問題は2つの大き
なグループに分けることができます。

14
00:00:53.410 --> 00:00:58.430
最初のグループでは、ローカル検証中に発生
する問題があります。

15
00:00:58.430 --> 00:01:02.760
通常、彼らは、データの不整合によって引き
起こされる

16
00:01:02.760 --> 00:01:08.150
広範な例では、さまざまなフォールトに対し
て異なる最適なパラメータが得られます。

17
00:01:08.150 --> 00:01:11.900
この場合は、より徹底した検証を行う必要が
あります。

18
00:01:11.900 --> 00:01:14.510
第2グループからの問題は、

19
00:01:14.510 --> 00:01:19.320
多くの場合のみ、我々はプラットフォームに
私たちの提出を送信する自分自身を明らかに
する。

20
00:01:19.320 --> 00:01:25.250
、検証とスコアボードのスコアが一致しない
ことを確認します。

21
00:01:25.250 --> 00:01:28.200
この場合、問題は通常発生します。

22
00:01:28.200 --> 00:01:33.600
我々は正確な列車のテストを模倣することは
できませんので、我々の検証に分割。

23
00:01:33.600 --> 00:01:38.630
これらは厳しい問題であり、我々は間違いな
くそれらを処理できるようにしたい。

24
00:01:38.630 --> 00:01:43.320
だから我々が開始する前に、私はこのビデオ
の概要を提供してみましょう。

25
00:01:43.320 --> 00:01:48.180
検証と送信の両方の段階では、主な問題につ
いて説明します。

26
00:01:48.180 --> 00:01:50.370
彼らの原因、それらを処理する方法。

27
00:01:51.470 --> 00:01:58.190
次に、リーダーボードシャッフルが期待でき
るタイミングについて少しお話しします。

28
00:01:58.190 --> 00:02:02.340
まず、検証段階の問題について説明します。

29
00:02:02.340 --> 00:02:05.956
通常、彼らは検証中に私たちの注目を集める
。

30
00:02:05.956 --> 00:02:10.428
一般的に、主な問題は、スコアの有意差であ
り、

31
00:02:10.428 --> 00:02:14.316
異なる列車の検証分割のための最適なパラメ
ータ。

32
00:02:14.316 --> 00:02:16.400
例から始めましょう。

33
00:02:16.400 --> 00:02:19.360
だから、簡単にこの問題を説明することがで
きます。

34
00:02:19.360 --> 00:02:23.970
2月のお店での売り上げを予測する必要があ
ると考えてください。

35
00:02:23.970 --> 00:02:26.060
我々は目標値を持っていると言う

36
00:02:26.060 --> 00:02:31.135
最後の年、そして、通常、我々は、検証で先
月かかります。

37
00:02:31.135 --> 00:02:37.775
これは1月を意味するが、明らかに1月は2
月より多くの休日を過す。

38
00:02:37.775 --> 00:02:42.995
そして、人々はより多くを購入する傾向があ
る, これは全体的に高いことがターゲット
値を引き起こす.

39
00:02:42.995 --> 00:02:46.835
そして、それは私たちの予測の二乗誤差を意
味する

40
00:02:46.835 --> 00:02:50.600
1月は2月よりも大きくなります。

41
00:02:50.600 --> 00:02:55.500
これは、モジュールが2月のために悪化を実
行することを意味しますか?

42
00:02:55.500 --> 00:02:59.730
おそらくない、少なくともオーバーフィット
回避の面で。

43
00:02:59.730 --> 00:03:05.280
我々が見ることができるように、時にはモデ
ルの動作のこの種の期待することができます
。

44
00:03:05.280 --> 00:03:11.490
しかし、明確な理由がない場合は、スコアが
異なるひだの違いは何ですか?

45
00:03:11.490 --> 00:03:16.380
このためのいくつかの一般的な理由を識別し
、我々はそれについて何ができるかを確認し
ましょう。

46
00:03:16.380 --> 00:03:22.450
我々が考慮すべき最初の仮説と我々はあまり
にも少ないデータを持っていること.

47
00:03:22.450 --> 00:03:28.230
たとえば、データのパターンや傾向が多い場
合について考えてみます。

48
00:03:28.230 --> 00:03:32.690
しかし、これらのパターンを一般化するのに
十分なサンプルがありません。

49
00:03:33.760 --> 00:03:38.561
その場合、モデルはいくつかの一般的なパタ
ーンのみを利用します。

50
00:03:38.561 --> 00:03:43.465
また、各列車の検証の分割については、これ
らのパターンは部分的に異なります。

51
00:03:43.465 --> 00:03:48.330
これは確かに、モデルのスコアの違いにつな
がる。

52
00:03:48.330 --> 00:03:53.081
さらに、検証サンプルは毎回異なる

53
00:03:53.081 --> 00:03:57.264
別のひだのスコアの分散を増加させる。

54
00:03:57.264 --> 00:04:02.390
この2番目のタイプは、データが多すぎると
矛盾しています。

55
00:04:02.390 --> 00:04:07.627
たとえば、ターゲットの差異が異なるサンプ
ルが非常に類似している場合は、

56
00:04:07.627 --> 00:04:09.580
モデルはそれらを混同することができます。

57
00:04:09.580 --> 00:04:12.270
2つのケースを考えて、まず、

58
00:04:12.270 --> 00:04:17.850
そのような例のいずれかが列車内にある場合
は、別の検証にあります。

59
00:04:17.850 --> 00:04:21.570
我々は、2番目のサンプルのための非常に高
いエラーを得ることができます。

60
00:04:21.570 --> 00:04:25.658
2つ目の例では、両方のサンプルが検証中の
場合、

61
00:04:25.658 --> 00:04:29.250
我々は彼らのために小さなエラーを取得しま
す。

62
00:04:29.250 --> 00:04:33.200
またはさまざまなデータの別の例を覚えてみ
ましょう

63
00:04:33.200 --> 00:04:35.468
我々はすでに少し前に議論している。

64
00:04:35.468 --> 00:04:41.080
1月と2月の売上予測の例について話してい
ます。

65
00:04:41.080 --> 00:04:45.330
ここでは、スコアの違いの性質や理由があり
ます。

66
00:04:45.330 --> 00:04:50.860
簡単なメモとして、この例では、この多様性
を減らすことができることに注意してくださ
い。

67
00:04:50.860 --> 00:04:56.070
ビットは、我々は、前年から2月に検証する
場合。

68
00:04:56.070 --> 00:05:00.370
したがって、スコアと最適なモデルパラメー
タの違いの主な理由

69
00:05:00.370 --> 00:05:04.270
異なるひだは、最初に、あまりにも少ないデ
ータを持っている、と

70
00:05:04.270 --> 00:05:07.530
第二に、あまりにも多様で一貫性のないデー
タを持つ。

71
00:05:07.530 --> 00:05:10.960
次に、ここでの行動を概説しましょう。

72
00:05:10.960 --> 00:05:13.290
もし我々がこの種の問題に直面しているなら
、

73
00:05:13.290 --> 00:05:17.140
これは、より徹底した検証を行うのに役立ち
ます。

74
00:05:17.140 --> 00:05:22.290
あなたは KFold で K を増やすこ
とができますが、通常は5襞は十分です。

75
00:05:22.290 --> 00:05:26.122
異なるランダム分割を使用して KFold
検証を数回行います。

76
00:05:26.122 --> 00:05:31.070
と平均スコアは、モデルの品質のより安定し
た推定値を取得します。

77
00:05:31.070 --> 00:05:33.850
我々は最高のパラメータを選択することがで
きます同じように

78
00:05:33.850 --> 00:05:37.110
overfit 機会があればモデル。

79
00:05:37.110 --> 00:05:42.060
KFold 分割の1つのセットを使用して
パラメータを選択すると便利です。

80
00:05:42.060 --> 00:05:45.970
モデルの品質をチェックするために、KFo
ld の別のセットが分割されます。

81
00:05:47.170 --> 00:05:51.770
広範な検証を必要とする競技の例としては、

82
00:05:51.770 --> 00:05:56.600
自由相互グループの特性の点検の予測の競争
および

83
00:05:56.600 --> 00:06:00.160
サンタンデールの顧客満足度の競争。

84
00:06:00.160 --> 00:06:05.920
どちらにしても、競技者のスコアは互いに非
常に近かった。

85
00:06:05.920 --> 00:06:10.060
したがって、参加者は、データからより多く
のスクイズを試みた。

86
00:06:10.060 --> 00:06:15.240
しかし、徹底的な検証が重要だったので、o
verfit しないでください。

87
00:06:15.240 --> 00:06:18.021
さて、検証段階の問題について議論したとこ
ろ、

88
00:06:18.021 --> 00:06:20.910
提出段階の問題に移りましょう。

89
00:06:20.910 --> 00:06:26.735
場合によっては、慎重に行うプロセスでこれ
らの問題を診断することができます。

90
00:06:26.735 --> 00:06:30.170
しかし、それでも、多くの場合、問題のこれ
らのタイプが発生する

91
00:06:30.170 --> 00:06:32.950
ソリューションをプラットフォームに送信す
る場合にのみ使用できます。

92
00:06:34.000 --> 00:06:35.470
しかし、その後、再び、

93
00:06:35.470 --> 00:06:41.360
それが問題の根本を見つけることに来るとき
あなたの友人はある。

94
00:06:41.360 --> 00:06:45.070
一般的に言えば、これらの問題の2つのケー
スがあります。

95
00:06:45.070 --> 00:06:49.020
最初のケースでは、ランキングスコアは一貫
して高いか

96
00:06:49.020 --> 00:06:51.580
検証スコアよりも低い。

97
00:06:51.580 --> 00:06:57.300
もう1つは、スコアボードスコアが検証スコ
アと相関していないことです。

98
00:06:57.300 --> 00:07:01.780
だから最悪の場合、我々は検証のスコアを向
上させることができます。

99
00:07:01.780 --> 00:07:06.130
一方、それどころか、スコアボードの得点が
減少します。

100
00:07:06.130 --> 00:07:11.448
あなたが想像できるように、これらの問題は
はるかにトラブルになることができます。

101
00:07:11.448 --> 00:07:15.600
今は、信頼性の高い検証を行うのは、主なル
ールを覚えて、

102
00:07:15.600 --> 00:07:19.710
は、事前に主催者によって作られた列車のテ
ストを模倣することです。

103
00:07:19.710 --> 00:07:23.420
私はあなたにうそをつかない、それは非常に
識別するのは難しいことができます

104
00:07:23.420 --> 00:07:25.930
ここに正確な列車のテストを模倣する。

105
00:07:25.930 --> 00:07:30.620
そのため、私は非常にあなたのソリューショ
ンを提出を開始する

106
00:07:30.620 --> 00:07:32.820
あなたが競争を入力した直後に。

107
00:07:32.820 --> 00:07:37.780
この問題の他の可能なルーツを模索し始める
のは良いことだ。

108
00:07:37.780 --> 00:07:41.808
まず、検証段階で観察できる原因を整理して
みましょう。

109
00:07:41.808 --> 00:07:46.705
リコールは、我々はすでに別のモデルのスコ
アを持っている

110
00:07:46.705 --> 00:07:49.480
検証中にフォールドします。

111
00:07:49.480 --> 00:07:54.510
ここでは、別の検証フォールドとしてリーダ
ーボードを見ると便利です。

112
00:07:54.510 --> 00:07:58.660
その後、我々はすでに KFold
で別のスコアを持っている場合、

113
00:07:58.660 --> 00:08:04.330
リーダーボードではあまり似ていない結果を
得ることは意外ではありません。

114
00:08:04.330 --> 00:08:09.930
より多くの我々は、検証スコアの平均値と標
準偏差を計算することができます

115
00:08:09.930 --> 00:08:14.240
ランキングスコアが予想されるかどうかを見
積もります。

116
00:08:14.240 --> 00:08:18.250
しかし、もしこれがそうでないならば、何か
は、はっきりと間違っています。

117
00:08:19.290 --> 00:08:22.360
この問題には、さらに2つの理由があります
。

118
00:08:22.360 --> 00:08:26.500
最初の理由は、我々は、パブリックリーダー
ボードのデータが少なすぎる、

119
00:08:26.500 --> 00:08:28.610
これはかなり自明です。

120
00:08:28.610 --> 00:08:32.230
ちょうどあなたの検証を信頼し、すべてが正
常になります。

121
00:08:32.230 --> 00:08:37.830
そして、2番目の列車とテストデータは、異
なる分布からです。

122
00:08:37.830 --> 00:08:42.056
私は私が異なるディストリビューションにつ
いて話すときに私が何を意味するか説明しま
しょう。

123
00:08:42.056 --> 00:08:46.410
人の身長を予測する回帰テストを検討する

124
00:08:46.410 --> 00:08:49.440
Instagram の上の写真で。

125
00:08:49.440 --> 00:08:53.190
青い線は人間のための高さの分布を表し、

126
00:08:53.190 --> 00:08:58.410
赤い線が女性のための高さの分布を表してい
る間。

127
00:08:58.410 --> 00:09:02.140
ご覧のとおり、これらのディストリビューシ
ョンは異なります。

128
00:09:02.140 --> 00:09:07.050
今は、電車のデータは、女性だけで構成され
ていることを考慮してみましょう

129
00:09:07.050 --> 00:09:11.067
テストデータは男性のみで構成されます。

130
00:09:11.067 --> 00:09:16.540
その後、すべてのモデルの予測は、女性の平
均身長の周りになります。

131
00:09:16.540 --> 00:09:20.960
そして、これらの予測の分布は非常にそれに
似ている

132
00:09:20.960 --> 00:09:22.695
列車のデータ。

133
00:09:22.695 --> 00:09:27.985
私たちのモデルは、テストデータにひどいス
コアを持っていることも不思議ではありませ
ん。

134
00:09:27.985 --> 00:09:32.665
今、私たちのコースは実用的なものですので
、時間を割いてみましょう

135
00:09:32.665 --> 00:09:37.196
あなたが競争の中でこれらに遭遇した場合、
何ができるか考えてください。

136
00:09:37.196 --> 00:09:41.895
さて、このような問題への一般的なアプロー
チから始めましょう。

137
00:09:41.895 --> 00:09:43.285
最も広いレベルでは、

138
00:09:43.285 --> 00:09:48.250
我々は、電車やテストで異なる分布に取り組
むための方法を見つける必要があります。

139
00:09:48.250 --> 00:09:52.316
場合によっては、問題のこれらの種類を調整
することによって解決できる

140
00:09:52.316 --> 00:09:55.240
トレーニング手順中に解決します。

141
00:09:55.240 --> 00:09:58.080
しかし、時には、この問題を解決することが
できます

142
00:09:58.080 --> 00:10:01.527
リーダーボードを使用してソリューションを
調整するだけです。

143
00:10:01.527 --> 00:10:04.088
それはリーダーボードプロービングを通じて
です。

144
00:10:04.088 --> 00:10:08.990
競争のこの特定の状態を解決する最も簡単な
方法は試みることである

145
00:10:08.990 --> 00:10:13.310
列車およびテストデータのための最適の一定
した予測を把握するため。

146
00:10:13.310 --> 00:10:16.960
との違いであなたの予測をシフトします。

147
00:10:16.960 --> 00:10:22.590
ここでは、電車のデータから女性の平均身長
を計算することができます。

148
00:10:22.590 --> 00:10:25.788
男性の平均身長を計算すると、大きなトリッ
キーです。

149
00:10:25.788 --> 00:10:29.890
場合は、競争のメトリックは、二乗誤差を意
味する

150
00:10:29.890 --> 00:10:34.460
我々は、単純な数式を書き留め、2つの定数
の提出を送信することができます。

151
00:10:34.460 --> 00:10:40.290
そして、テストの平均目標値は70インチに
等しいことを確認してください。

152
00:10:40.290 --> 00:10:44.420
一般に、この手法はリーダーボードプロービ
ングと呼ばれます。

153
00:10:44.420 --> 00:10:48.593
そして、それについてのトピックで議論しま
す。

154
00:10:48.593 --> 00:10:53.240
だから今、我々は電車の平均目標値の違いを
知っていると

155
00:10:53.240 --> 00:10:56.670
7インチに等しいテストデータ。

156
00:10:56.670 --> 00:11:01.160
また、リーダーボードへの提出を調整する3
番目のステップとして、

157
00:11:01.160 --> 00:11:06.130
すべての予測に7を追加しようとするだけで
した。

158
00:11:06.130 --> 00:11:13.140
しかし、この時点からそれはリーダーボード
のプロービングとリストである
validational
ではありません。

159
00:11:13.140 --> 00:11:18.130
はい我々はおそらく探索的データ分析中にこ
れを発見することができると

160
00:11:18.130 --> 00:11:21.460
私たちの検証スキームで補正を行うようにし
てください。

161
00:11:21.460 --> 00:11:25.090
しかし、時にはそれは、リーダーボードプロ
ービングなしでは不可能です

162
00:11:25.090 --> 00:11:27.220
この例と同じように。

163
00:11:27.220 --> 00:11:33.090
類似したものを持っている競争は
Quora の質問の組の競争である。

164
00:11:33.090 --> 00:11:38.190
そこでは、列車からのターゲットの分布とテ
ストが異なっていた。

165
00:11:38.190 --> 00:11:41.860
従って1つはスコアのよい改善を得ることが
できる

166
00:11:41.860 --> 00:11:44.591
自分の予測をスコアボードに調整する。

167
00:11:45.840 --> 00:11:49.010
しかし、幸いにも、このケースは十分にまれ
です。

168
00:11:49.010 --> 00:11:54.080
より多くの場合、我々は、次のようなケース
に似ている状況が発生します。

169
00:11:54.080 --> 00:11:58.500
現在の列車は、女性だけでなく、構成されて
いることを考慮

170
00:11:58.500 --> 00:12:01.640
主に女性の, とテスト, その逆.

171
00:12:01.640 --> 00:12:04.640
男性だけでなく、主に男性の構成されます。

172
00:12:05.690 --> 00:12:09.740
このような状況に対処するための主な戦略は
簡単です。

173
00:12:09.740 --> 00:12:13.870
繰り返しますが、列車のテストの分割を模倣
することを忘れない。

174
00:12:13.870 --> 00:12:16.780
テストはほとんどの男性で構成されている場
合、

175
00:12:16.780 --> 00:12:20.770
検証に同じディストリビューションを強制的
に配置します。

176
00:12:20.770 --> 00:12:25.190
その場合は、検証が公平であることを確認し
ます。

177
00:12:26.420 --> 00:12:31.230
これは、raw スコアと最適なパラメータ
を正しく取得する場合に当てはまります。

178
00:12:31.230 --> 00:12:34.430
例えば、我々はかなり異なるスコアを持つこ
とができると

179
00:12:34.430 --> 00:12:39.160
データセットの女性と男性の部分のための最
適なパラメータ。

180
00:12:40.280 --> 00:12:45.550
テストと検証で同じ分布を確保することによ
り、スコアを取得し、

181
00:12:45.550 --> 00:12:48.890
テストに関連するパラメータ。

182
00:12:48.890 --> 00:12:52.460
私はここの2つの例を言及したい。

183
00:12:52.460 --> 00:12:57.630
最初のデータサイエンスゲームの資格段階:
音楽の推薦の挑戦。

184
00:12:57.630 --> 00:13:00.230
と第二に、競争

185
00:13:00.230 --> 00:13:05.060
CTR の予測は、データのトピックで前に
説明した。

186
00:13:05.060 --> 00:13:07.110
2つ目から始めましょう

187
00:13:07.110 --> 00:13:12.250
問題を覚えていますか, 我々は、CTR
を予測するテストを持っている.

188
00:13:12.250 --> 00:13:17.250
だから、基本的に表示された広告の歴史だっ
た列車のデータは、

189
00:13:17.250 --> 00:13:21.750
明らかに表示されていない広告が含まれてい
ない。

190
00:13:21.750 --> 00:13:27.310
それどころか、テストデータは可能なすべて
の広告で構成されていました。

191
00:13:27.310 --> 00:13:33.211
これは、列車とテストで異なる分布の正確な
ケースであることに注意してください。

192
00:13:34.420 --> 00:13:39.260
ここでも、テストを模倣するために検証を設
定する必要があります。

193
00:13:39.260 --> 00:13:44.330
だから我々は、電車の中でそれを示すに向か
って、この巨大なバイアスを持っている

194
00:13:44.330 --> 00:13:46.500
正しい検証を設定します。

195
00:13:46.500 --> 00:13:51.384
表示されていない広告の行で検証セットを完
成させなければなりませんでした。

196
00:13:51.384 --> 00:13:55.018
さて、最初の例に戻りましょう。

197
00:13:55.018 --> 00:13:58.320
その競争の中で、参加者は予測しなければな
らなかった

198
00:13:58.320 --> 00:14:03.150
ユーザーがアシスタントが推奨する曲を聴く
かどうか。

199
00:14:03.150 --> 00:14:07.350
したがって、テストに含まれるのは推奨され
る曲だけです。

200
00:14:07.350 --> 00:14:12.200
しかし、列車は、逆に、両方のお勧めの曲が
含まれて

201
00:14:12.200 --> 00:14:15.250
ユーザーが自分で選択した曲。

202
00:14:15.250 --> 00:14:21.900
そう再度、1つはユーザーによって選ばれる
50の有名な歌によって彼の妥当性を調節で
きる。

203
00:14:21.900 --> 00:14:27.551
そして再び、我々はその事実を考慮しない場
合、我々のモデルを改善する

204
00:14:27.551 --> 00:14:33.127
実際に選択した曲では、検証スコアが上がっ
てしまうことがあります。

205
00:14:33.127 --> 00:14:38.168
しかし、それは、スコアボードのための同じ
改善をもたらす必要はありません。

206
00:14:38.168 --> 00:14:42.269
さてここでは、検証の問題の処理の概要につ
いて説明します。

207
00:14:42.269 --> 00:14:44.460
提出の段階。

208
00:14:44.460 --> 00:14:50.030
パブリックスコアボードのデータが少なすぎ
る場合は、検証を信頼するだけです。

209
00:14:50.030 --> 00:14:53.705
そうでない場合は、overfit
しなかったことを確認してください。

210
00:14:55.250 --> 00:14:58.880
その後、正しい列車/テストの分割を行った
かどうかを確認し、

211
00:14:58.880 --> 00:15:01.770
我々は前のビデオで説明したように。

212
00:15:01.770 --> 00:15:08.170
そして最後に、あなたが列車とテストで異な
る分布を持っているかどうかを確認してくだ
さい。

213
00:15:08.170 --> 00:15:11.890
グレートは、このビデオの次のポイントに移
動してみましょう。

214
00:15:11.890 --> 00:15:15.470
今のところ、私はあなたがすべての権利をし
たと思います。

215
00:15:15.470 --> 00:15:17.750
まず、広範な検証を行いました。

216
00:15:17.750 --> 00:15:22.150
次に、列車の検証を分割するための正しい分
割方法を選択します。

217
00:15:22.150 --> 00:15:28.020
最後に、検証とテストで同じディストリビュ
ーションを確保しました。

218
00:15:28.020 --> 00:15:33.190
しかし、場合によっては、とにかくリーダー
ボードシャッフルを期待する必要があります

219
00:15:33.190 --> 00:15:36.330
そして、あなたのためだけでなく、誰にとっ
ても。

220
00:15:36.330 --> 00:15:41.060
最初に、それを聞いたことがない人のために
、ランキングシャッフルが起こる

221
00:15:41.060 --> 00:15:46.980
参加者がいくつかのパブリックとプライベー
トのリーダーボードを大幅に異なる位置。

222
00:15:46.980 --> 00:15:50.950
挑戦の2つのシグマの金融モデルからこのス
クリーンショットを見てみましょう

223
00:15:50.950 --> 00:15:52.570
競争。

224
00:15:52.570 --> 00:15:57.510
緑と赤の矢印は、チームがどこまで動いたか
を意味します。

225
00:15:57.510 --> 00:16:02.095
例えば、3回目を終えた参加者は、プライベ
ート

226
00:16:02.095 --> 00:16:08.240
リーダーボードは、公開リーダーボードの3
92nd でした。

227
00:16:08.240 --> 00:16:12.995
そのシャッフル、ランダム、の3つの主な理
由を議論してみましょう

228
00:16:12.995 --> 00:16:18.100
あまりにも少ないデータ、および異なるパブ
リック、プライベートディストリビューショ
ン。

229
00:16:18.100 --> 00:16:20.170
そこでまず、乱雑性、

230
00:16:20.170 --> 00:16:24.920
これは、すべての参加者が非常に類似したス
コアを持っている場合です。

231
00:16:24.920 --> 00:16:29.230
これは非常に良いスコアまたは非常に貧しい
もののいずれかになります。

232
00:16:29.230 --> 00:16:32.745
しかし、ここでの主なポイントは、主な理由
は、

233
00:16:32.745 --> 00:16:35.780
スコアの違いはランダムです。

234
00:16:35.780 --> 00:16:40.602
これをもう少し理解するために、ここで2つ
の簡単な例を見ていきましょう。

235
00:16:40.602 --> 00:16:43.470
最初の1つは自由の相互グループである、

236
00:16:43.470 --> 00:16:45.765
不動産検査の予測競争。

237
00:16:45.765 --> 00:16:50.750
その競争では、競合他社のスコアは非常に近
かった。

238
00:16:50.750 --> 00:16:54.820
ランダムではないが、その競争の中で大きな
役割を果たしていない

239
00:16:54.820 --> 00:16:59.580
それでも多くの人々は、パブリックリーダー
ボードに overfit。

240
00:16:59.580 --> 00:17:02.410
第2の例では、最初の

241
00:17:02.410 --> 00:17:06.540
は、2つのシグマの金融モデルとチャレンジ
競争です。

242
00:17:06.540 --> 00:17:11.530
その競争の財務データは非常に予測できなか
ったので、

243
00:17:11.530 --> 00:17:14.470
乱数はそれの主要な役割を担った。

244
00:17:14.470 --> 00:17:18.790
だから一つは、ランキングシャッフルが間に
あったと言うことができる

245
00:17:18.790 --> 00:17:21.920
KFold
プラットフォーム上で最大のシャッフル。

246
00:17:21.920 --> 00:17:26.790
さて、それはランダムだった、第2の理由は
、ランキングシャッフルを期待する

247
00:17:26.790 --> 00:17:31.524
は、全体的に少なすぎるデータであり、特に
プライベートテストで設定されます。

248
00:17:31.524 --> 00:17:36.760
この例では、レストランの収益予測競争です
。

249
00:17:36.760 --> 00:17:42.210
その競争では、訓練されたセットはより少し
から成っていた200総体.

250
00:17:42.210 --> 00:17:46.100
そして、このセットは、400未満の総から
成っていた。

251
00:17:46.100 --> 00:17:49.110
ここでシャッフルを見ることができるように
予想以上だった。

252
00:17:50.850 --> 00:17:53.590
リーダーボードシャッフルの最後の理由は、

253
00:17:53.590 --> 00:17:57.660
パブリックおよびプライベートテストセット
間の異なる分布。

254
00:17:57.660 --> 00:18:00.764
これは通常、時系列予測の場合、

255
00:18:00.764 --> 00:18:04.100
ロスマン店の販売競争のように。

256
00:18:04.100 --> 00:18:09.140
我々は時間ベースの分割を持っているとき、
我々は通常、最初の数週間を持っている

257
00:18:09.140 --> 00:18:14.400
パブリックリーダーボード、およびプライベ
ートリーダーボードの次の数週間。

258
00:18:14.400 --> 00:18:18.576
人々は、パブリックリーダーボードへの提出
を調整する傾向があると

259
00:18:18.576 --> 00:18:23.160
overfit、我々はプライベートリーダ
ーボード上の悪い結果を期待することができ
ます。

260
00:18:23.160 --> 00:18:27.920
ここでも、あなたの検証を信頼し、すべてが
正常になります。

261
00:18:27.920 --> 00:18:31.700
さて、リーダーボードをシャッフルする理由
を見ていきましょう。

262
00:18:31.700 --> 00:18:37.110
次に、このビデオと検証トピック全体につい
て説明します。

263
00:18:37.110 --> 00:18:39.220
ビデオから始めましょう。

264
00:18:39.220 --> 00:18:43.820
まず、検証段階でスコアの大きな分散がある
場合

265
00:18:43.820 --> 00:18:46.790
我々は、広範な検証を行う必要があります。

266
00:18:46.790 --> 00:18:51.668
それは別の KFold
の分割からすべてのスコアを意味し、

267
00:18:51.668 --> 00:18:57.350
一方の分割でチームモデルは、他のスコアを
評価しながら。

268
00:18:57.350 --> 00:19:02.180
次に、送信がローカルの検証スコアと一致し
ない場合は、

269
00:19:02.180 --> 00:19:07.170
まず、パブリックリーダーボードのデータが
少なすぎるかどうかを確認する必要がありま
す。

270
00:19:07.170 --> 00:19:13.080
2番目に、overfit しなかったかど
うかを確認し、正しい分割戦略を選択したか
どうかを確認します。

271
00:19:13.080 --> 00:19:18.090
そして最後に、訓練されたテストが異なった
配分を有するかどうか点検。

272
00:19:18.090 --> 00:19:23.519
あなたは3つの重要なこと、乱数のためにラ
ンキングシャッフルを期待することができま
す

273
00:19:23.519 --> 00:19:29.750
データの量が少なく、パブリック/プライベ
ートテストの分布が異なります。

274
00:19:29.750 --> 00:19:33.319
そこで、このトピックでは検証を定義し、

275
00:19:33.319 --> 00:19:36.290
オーバーフィット回避への接続。

276
00:19:36.290 --> 00:19:39.370
一般的な検証方法について説明します。

277
00:19:39.370 --> 00:19:42.780
主なデータ分割戦略を示した。

278
00:19:42.780 --> 00:19:47.970
そして、最終的に分析し、どのように主要な
検証の問題に取り組むことを学んだ。

279
00:19:47.970 --> 00:19:53.070
これを覚えて、それは絶対に競争の中であな
たを助ける。

280
00:19:53.070 --> 00:19:57.570
検証の主なアイデアをよく理解していること
を確認してください。

281
00:19:57.570 --> 00:20:00.130
つまり、訓練されたテストの分割を模倣する
必要があります。

282
00:20:00.130 --> 00:20:09.386
音楽


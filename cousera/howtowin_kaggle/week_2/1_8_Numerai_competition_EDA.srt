1
00:00:02.790 --> 00:00:06.285
ねえ皆さん。このビデオでは、

2
00:00:06.285 --> 00:00:08.290
私は具体的について教えてくれます

3
00:00:08.290 --> 00:00:12.731
年間2016を通じて開催された
Numerai の競争。

4
00:00:12.731 --> 00:00:17.980
Numerai の主催者は2017でフォ
ーマットを変更したことに注意してください
。

5
00:00:17.980 --> 00:00:22.335
従って、私が読むことを行っている調査結果
は新しいデータで働かない。

6
00:00:22.335 --> 00:00:24.860
問題を述べましょう。

7
00:00:24.860 --> 00:00:28.250
参加者は、バイナリ分類のタスクを解決して
いた

8
00:00:28.250 --> 00:00:32.320
21匿名の数値機能を持つデータセット。

9
00:00:32.320 --> 00:00:38.305
異常な部分は、列車とテストデータセットの
両方が毎週更新されているということです。

10
00:00:38.305 --> 00:00:41.660
データセットも列単位でシャッフルされまし
た。

11
00:00:41.660 --> 00:00:44.215
だから、毎週新しい仕事のようだった。

12
00:00:44.215 --> 00:00:47.405
かなりやりがいがあります。それが判明した
として、

13
00:00:47.405 --> 00:00:50.210
この競争は、データリークしていた。

14
00:00:50.210 --> 00:00:55.320
主催者は、データセットの性質についての情
報を開示していない。

15
00:00:55.320 --> 00:00:59.120
しかし、容疑者は、それがターゲットといく
つかの時系列データだった

16
00:00:59.120 --> 00:01:03.770
時間ポイント間の遷移に大きく依存する変数
。

17
00:01:03.770 --> 00:01:07.910
ここで株式市場の価格の変化を予測するよう
なものを考えてみてください。

18
00:01:07.910 --> 00:01:13.165
我々は真の順序を知っていた場合、またはタ
イムスタンプ変数を持っていることを意味

19
00:01:13.165 --> 00:01:15.890
我々は簡単にほぼ完璧なスコアを得ることが
できる。

20
00:01:15.890 --> 00:01:20.140
したがって、我々は何とかこの順序を再構築
しなければならなかった。

21
00:01:20.140 --> 00:01:21.805
もちろん、おおよそ。

22
00:01:21.805 --> 00:01:27.440
しかし、大まかな近似は、他の参加者よりも
大きな利点を与えていた。

23
00:01:27.440 --> 00:01:30.725
最初で最も重要なステップは、

24
00:01:30.725 --> 00:01:33.995
データセット内のすべてのポイントに最も近
い近傍

25
00:01:33.995 --> 00:01:39.230
その隣人から元のポイントにすべての21の
機能を追加します。

26
00:01:39.230 --> 00:01:43.160
これらの42の特徴の簡単なロジスティック
回帰、

27
00:01:43.160 --> 00:01:46.610
21元から、と21近隣のポイントから、

28
00:01:46.610 --> 00:01:50.285
リーダーボード上のトップ10に入るために
許可されています。

29
00:01:50.285 --> 00:01:54.945
もちろん、我々はいくつかの筋金入りの江田
とより良いスコアを得ることができます。

30
00:01:54.945 --> 00:01:59.500
新しい21の機能の相関関係の指標を模索し
てみましょう。

31
00:01:59.500 --> 00:02:03.943
相互に最も高い相関係数を持つグループフィ
ーチャの場合、

32
00:02:03.943 --> 00:02:06.735
右の写真を撮る

33
00:02:06.735 --> 00:02:10.340
この写真は、2つの異なる方法で私たちを助
けることができる。

34
00:02:10.340 --> 00:02:13.810
まず、実際にいくつかの列の順序を修正する
ことができます。

35
00:02:13.810 --> 00:02:17.735
そのためには、毎週の列をシャッフル我々の
モデルには影響しません。

36
00:02:17.735 --> 00:02:20.480
第二に、我々は明らかに気づくことができる

37
00:02:20.480 --> 00:02:25.115
それらのそれぞれの3つの非常に相関機能を
持つ7つのグループ。

38
00:02:25.115 --> 00:02:29.600
したがって、データは実際にはいくつかの非
自明な構造を持っています。

39
00:02:29.600 --> 00:02:35.615
次に、新しいデータセットを毎週取得するこ
とを覚えておいてください。何よりですか?

40
00:02:35.615 --> 00:02:40.110
毎週、列車のデータセットは、ポイントの同
じ数を持っています。

41
00:02:40.110 --> 00:02:45.170
連続するデータセット間に何らかの接続があ
ると仮定することができます。

42
00:02:45.170 --> 00:02:49.360
我々はすでに時系列を持っているので、これ
は少し奇妙です。

43
00:02:49.360 --> 00:02:53.200
それでは、異なる週のデータ間の接続とは何
ですか。

44
00:02:53.200 --> 00:02:56.480
まあ、我々は最寄りの隣人を見つける場合

45
00:02:56.480 --> 00:03:00.065
現在のデータセット内のすべてのポイントは
、以前のデータセットから、

46
00:03:00.065 --> 00:03:02.195
とプロットの距離分布、

47
00:03:02.195 --> 00:03:04.910
我々は、最初の隣人は、多くのことに気づく
ことができる

48
00:03:04.910 --> 00:03:07.370
2番目よりはるかに近い。

49
00:03:07.370 --> 00:03:11.585
したがって、我々は確かに連続したデータセ
ット間のいくつかの接続を持っている。

50
00:03:11.585 --> 00:03:16.000
そして、それは我々がそれらの間の
bijective マッピングを構築する
ことができますように見えます。

51
00:03:16.000 --> 00:03:21.470
しかし、すぐに結論に飛び込むのではなく、
より多くの探査を行うことができます。

52
00:03:21.470 --> 00:03:25.650
大丈夫です。以前のデータセットで最も近い
隣人を見つけました。

53
00:03:25.650 --> 00:03:28.070
間の距離を調べてみたらどうでしょうか。

54
00:03:28.070 --> 00:03:32.793
個々の機能のレベルでの隣接オブジェクト?

55
00:03:32.793 --> 00:03:36.735
我々は明らかに7つの機能の3種類のグルー
プがあります。

56
00:03:36.735 --> 00:03:40.090
今度は、ソートされた相関行列を覚えていま
すか?

57
00:03:40.090 --> 00:03:46.470
これは、3つの高相関機能のそれぞれが異な
るグループに属していることがわかった。

58
00:03:46.470 --> 00:03:48.140
完全に一致します。

59
00:03:48.140 --> 00:03:52.245
最初のグループの7つの機能を3で乗算する
と

60
00:03:52.245 --> 00:03:56.565
元のデータセットで2番目のグループからの
7つの特徴は、

61
00:03:56.565 --> 00:04:01.500
データセット内の最も近い近傍フィーチャを
再計算します。

62
00:04:01.500 --> 00:04:03.165
我々のモデルを再訓練して

63
00:04:03.165 --> 00:04:06.020
我々は良い改善を取得します。

64
00:04:06.020 --> 00:04:09.650
だから、この魔法の乗算の後、もちろん、

65
00:04:09.650 --> 00:04:11.445
私は他の定数を試してみたのですが、

66
00:04:11.445 --> 00:04:15.450
私たちの真の秩序近似は少し良くなりました
。

67
00:04:15.450 --> 00:04:20.840
すごい。今は、本当の関係に移りましょう。

68
00:04:20.840 --> 00:04:23.835
新しいデータ、毎週更新、

69
00:04:23.835 --> 00:04:25.955
全て嘘だった

70
00:04:25.955 --> 00:04:31.290
覚えて、どのように連続したデータセット間
の隣人を計算していた?

71
00:04:31.290 --> 00:04:33.685
consecutiveness
のことは忘れよう

72
00:04:33.685 --> 00:04:36.750
現在のデータセット間の近傍を計算し、

73
00:04:36.750 --> 00:04:40.550
そして2週間前か2ヶ月前からデータセット
。

74
00:04:40.550 --> 00:04:45.350
何があっても、我々はほぼ同じ距離を取得さ
れます。

75
00:04:45.350 --> 00:04:51.535
なぜでしょうか。最も簡単な答えは、データ
が実際には変更されませんでした。

76
00:04:51.535 --> 00:04:54.505
毎週同じデータを得てた

77
00:04:54.505 --> 00:04:56.275
プラス少しの雑音だ

78
00:04:56.275 --> 00:05:00.750
したがって、我々は、以前のデータセットの
それぞれで最も近い隣人を見つけることがで
きる

79
00:05:00.750 --> 00:05:02.305
そして、それらすべての平均

80
00:05:02.305 --> 00:05:05.770
追加されたノイズの分散が正常に減少します
。

81
00:05:05.770 --> 00:05:10.720
平均化した後、真の次数近似がさらに良くな
った。

82
00:05:10.720 --> 00:05:16.115
私は、テストデータの少しは、実際には随時
変更したと言わなければならない。

83
00:05:16.115 --> 00:05:20.765
しかしそれにもかかわらず、ほとんどの役割
は週から週に移行しました。

84
00:05:20.765 --> 00:05:23.320
そのため、プローブが可能であった

85
00:05:23.320 --> 00:05:26.395
さらに役立った全体の国民のリーダー板は、

86
00:05:26.395 --> 00:05:28.150
などなどなど。

87
00:05:28.150 --> 00:05:31.495
もちろん、その競争についての詳細がありま
すが、

88
00:05:31.495 --> 00:05:33.715
しかし、彼らは非常に興味深いものではない
。

89
00:05:33.715 --> 00:05:37.745
私はリバースエンジニアリングのプロセスに
焦点を当てると思った。

90
00:05:37.745 --> 00:05:41.875
とにかく、こういう推理小説が好きだといい
のですが

91
00:05:41.875 --> 00:05:46.880
探索的データ分析がどの程度重要であるかを
理解しました。

92
00:05:46.880 --> 00:05:51.710
あなたの注意をありがとう、常に江田に敬意
を払う。


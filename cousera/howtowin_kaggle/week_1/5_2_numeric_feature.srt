1
00:00:03.050 --> 00:00:05.550
こんにちは。このビデオでは、

2
00:00:05.550 --> 00:00:07.341
我々は、基本的なアプローチをカバーする

3
00:00:07.341 --> 00:00:11.060
フィーチャの前処理とフィーチャーの生成
(数値フィーチャ)。

4
00:00:11.060 --> 00:00:14.970
モデル選択がフィーチャー前処理にどのよう
に影響するかを理解します。

5
00:00:14.970 --> 00:00:19.500
最も頻繁に使用される前処理方法を特定しま
す。

6
00:00:19.500 --> 00:00:23.655
そして、我々は、機能の生成を議論し、いく
つかの例を経る。

7
00:00:23.655 --> 00:00:26.370
前処理から始めましょう。

8
00:00:26.370 --> 00:00:29.880
あなたが数字の機能の処理について知る必要
がある最初の事は

9
00:00:29.880 --> 00:00:34.230
機能スケールに依存しないモデルが存在する
こと。

10
00:00:34.230 --> 00:00:36.540
とりあえず、大まかに分けることにします

11
00:00:36.540 --> 00:00:40.760
ツリーベースのモデルと非ツリーベースのモ
デルにすべてのモデル。

12
00:00:40.760 --> 00:00:43.068
たとえば、デシジョンツリーの分類子は

13
00:00:43.068 --> 00:00:46.275
機能ごとに最も便利な分割を見つけるには、

14
00:00:46.275 --> 00:00:49.410
そして、それはその動作とその予測を変更し
ません。

15
00:00:49.410 --> 00:00:53.655
これは、定数によって機能を乗算し、モデル
を再トレーニングすることができます。

16
00:00:53.655 --> 00:00:58.490
反対側には、これらの変換の種類に依存する
モデルがあります。

17
00:00:58.490 --> 00:01:01.585
あなたの最寄りの隣人に基づいてモデルは、

18
00:01:01.585 --> 00:01:04.380
線形モデルとニューラルネットワーク

19
00:01:04.380 --> 00:01:06.900
次の例を考えてみましょう。

20
00:01:06.900 --> 00:01:10.615
2つの機能を持つバイナリ分類テストがあり
ます。

21
00:01:10.615 --> 00:01:13.740
ピクチャ内のオブジェクトは、異なるクラス
に属しています。

22
00:01:13.740 --> 00:01:15.480
クラスゼロへの赤い円、

23
00:01:15.480 --> 00:01:17.310
そしてクラス1への青い十字、

24
00:01:17.310 --> 00:01:21.375
そして最後に、緑のオブジェクトのクラスは
不明です。

25
00:01:21.375 --> 00:01:24.369
ここでは、1つの最も近い隣人のモデルを使
用します。

26
00:01:24.369 --> 00:01:26.785
緑のオブジェクトのクラスを予測します。

27
00:01:26.785 --> 00:01:29.700
我々は、距離を平方距離を使用して測定され
ます

28
00:01:29.700 --> 00:01:32.500
altometric とも呼ばれます。

29
00:01:32.500 --> 00:01:36.970
レッドサークルとブルークロスの距離を計算
すれば

30
00:01:36.970 --> 00:01:40.380
我々のモデルは、クラスの1つを予測するこ
とがわかります

31
00:01:40.380 --> 00:01:45.795
緑のオブジェクトは、クラス1の青い十字が
赤い円よりもはるかに近いためです。

32
00:01:45.795 --> 00:01:48.540
しかし、我々は10で最初の機能を乗算する
場合、

33
00:01:48.540 --> 00:01:49.949
赤い円が最も近いオブジェクトになります。

34
00:01:49.949 --> 00:01:53.096
そして、我々は反対の予測を取得します。

35
00:01:53.096 --> 00:01:55.885
2つの極端なケースを考えてみましょう。

36
00:01:55.885 --> 00:02:00.880
最初の機能を0と100万で乗算するとどう
なるでしょうか。

37
00:02:00.880 --> 00:02:03.300
フィーチャに0が乗算されている場合は、

38
00:02:03.300 --> 00:02:06.765
その後、すべてのオブジェクトは、ゼロの機
能リレーを持つことになります

39
00:02:06.765 --> 00:02:09.840
KNN の結果は、その機能を無視します。

40
00:02:09.840 --> 00:02:13.155
逆に、機能に100万を掛けると、

41
00:02:13.155 --> 00:02:17.565
その機能の値のわずかな違いは、予測に影響
を与える

42
00:02:17.565 --> 00:02:22.335
そして、これは他のすべての上にその機能を
優遇 KNN になります。

43
00:02:22.335 --> 00:02:25.098
素晴らしいが、他のモデルはどうですか?

44
00:02:25.098 --> 00:02:30.595
線形モデルは、異なるスケーリング機能でも
問題が発生しています。

45
00:02:30.595 --> 00:02:33.660
まず、正規化を適用する必要があります。

46
00:02:33.660 --> 00:02:37.450
線形モデルに等しい量の特徴のための係数。

47
00:02:37.450 --> 00:02:43.230
しかし、実際には、正則化の影響は、機能の
スケールに比例することが判明した。

48
00:02:43.230 --> 00:02:48.820
そして、2番目の勾配降下法は、適切なスケ
ーリングなしに夢中になることができます。

49
00:02:48.820 --> 00:02:50.828
同じ理由により、

50
00:02:50.828 --> 00:02:52.740
ニューラルネットワークは、

51
00:02:52.740 --> 00:02:56.710
特徴の前処理のための条件の線形モデル。

52
00:02:56.710 --> 00:02:58.930
それを理解することが重要です

53
00:02:58.930 --> 00:03:03.035
異なった特徴スケーリングは異なったモデル
質で起因する。

54
00:03:03.035 --> 00:03:08.205
この意味では、それはあなたが最適化する必
要があるだけで、別のハイパーパラメータで
す。

55
00:03:08.205 --> 00:03:12.580
これを行う最も簡単な方法は、すべてのフィ
ーチャを同じ縮尺に尺度することです。

56
00:03:12.580 --> 00:03:18.875
たとえば、フィーチャの最小値を0に、最大
値を1に等しくするには、

57
00:03:18.875 --> 00:03:20.740
これは、2つの手順で実現できます。

58
00:03:20.740 --> 00:03:23.565
まず、我々は最小値でセクタ。

59
00:03:23.565 --> 00:03:27.240
次に、差分ベースの最大値を除算します。

60
00:03:27.240 --> 00:03:31.382
それは sklearn から
MinMaxScaler
で行うことができます。

61
00:03:31.382 --> 00:03:34.950
例を挙げて説明しましょう。

62
00:03:34.950 --> 00:03:37.320
我々は、いわゆる
MinMaxScaler を適用する

63
00:03:37.320 --> 00:03:41.355
拘束データセット、Age、SibSp
の2つの機能。

64
00:03:41.355 --> 00:03:46.320
ヒストグラムを見て、我々は、機能が異なる
スケールを参照してください、

65
00:03:46.320 --> 00:03:48.380
ゼロと80の間の年齢、

66
00:03:48.380 --> 00:03:51.595
SibSp はゼロから8の間です。

67
00:03:51.595 --> 00:03:55.800
MinMaxScaling を適用し、そ
れが何をするかを見てみましょう。

68
00:03:55.800 --> 00:03:58.515
確かに、我々は、この変換後、参照してくだ
さい

69
00:03:58.515 --> 00:04:04.815
age と SibSp
の両方の機能は、0, 1
の同じ値の範囲に正常に変換されました。

70
00:04:04.815 --> 00:04:11.000
ヒストグラムから観測される値の分布は変化
しなかったことに注意してください。

71
00:04:11.000 --> 00:04:12.535
あなたに別の例を与えるために、

72
00:04:12.535 --> 00:04:16.365
sklearn で
StandardScaler という名前
のスカラーを適用することができます。

73
00:04:16.365 --> 00:04:20.980
これは基本的に最初の機能からの平均値を減
算

74
00:04:20.980 --> 00:04:25.060
、結果をフィーチャ標準偏差で除算します。

75
00:04:25.060 --> 00:04:27.785
このように、我々は、標準化された配布を取
得します

76
00:04:27.785 --> 00:04:31.670
ゼロの平均と1の標準偏差を持つ。

77
00:04:31.670 --> 00:04:36.747
MinMaxScaling または
StandardScaling
変換のいずれかの後に、

78
00:04:36.747 --> 00:04:41.460
非ツリーベースのモデルに対する機能の影響
はほぼ同じです。

79
00:04:41.460 --> 00:04:44.045
さらに、KNN を使いたいのであれば、

80
00:04:44.045 --> 00:04:48.920
我々は一歩先に行くことができますし、大き
な特徴は、リコール

81
00:04:48.920 --> 00:04:51.810
より重要なのは KNN のためである。

82
00:04:51.810 --> 00:04:56.180
そのため、スケーリングパラメータを最適化
して、機能を強化することができ

83
00:04:56.180 --> 00:05:01.106
私たちにとってより重要であるようで、これ
が役立つかどうかを確認します。

84
00:05:01.106 --> 00:05:03.475
線形モデルで作業する場合は、

85
00:05:03.475 --> 00:05:08.185
モデルのトレーニング結果に影響を与えるも
う一つの重要な瞬間があります。

86
00:05:08.185 --> 00:05:10.655
outiers の話だ

87
00:05:10.655 --> 00:05:13.130
たとえば、このプロットでは、我々は1つの
機能を持って、

88
00:05:13.130 --> 00:05:16.550
X、およびターゲット変数 Y。

89
00:05:16.550 --> 00:05:18.865
シンプルなリニアモデルに合わせると、

90
00:05:18.865 --> 00:05:22.850
その予測は、赤い線のように見えることがで
きます。

91
00:05:22.850 --> 00:05:29.065
しかし、もしあなたが X の特徴といくつ
かの巨大な値に等しい1つの外れを持ってい
る

92
00:05:29.065 --> 00:05:33.940
線形モデルの予測は、紫色の線のようになり
ます。

93
00:05:33.940 --> 00:05:36.419
同じことが、機能の値のためだけでなく、保
持

94
00:05:36.419 --> 00:05:38.915
目標値についても。

95
00:05:38.915 --> 00:05:41.815
例えば、我々はモデルを訓練している想像し
てみましょう

96
00:05:41.815 --> 00:05:45.245
0から1の間のターゲット値を持つデータ。

97
00:05:45.245 --> 00:05:48.690
新しいサンプルを追加するとどうなるか考え
てみましょう。

98
00:05:48.690 --> 00:05:52.390
目標値が1000のトレーニングデータ。

99
00:05:52.390 --> 00:05:53.950
モデルを再トレーニングするときに、

100
00:05:53.950 --> 00:05:57.185
モデルは異常に高い値を予測します。

101
00:05:57.185 --> 00:06:00.160
明らかに、我々は何とかこれを修正する必要
があります。

102
00:06:00.160 --> 00:06:03.295
外れ値から線形モデルを保護するために、

103
00:06:03.295 --> 00:06:09.635
我々は、下限と上限の2つの選択された値の
間にフィーチャ値をクリップすることができ
ます。

104
00:06:09.635 --> 00:06:13.105
我々は、その機能のいくつかのパーセンタイ
ルとしてそれらを選択することができます。

105
00:06:13.105 --> 00:06:16.575
たとえば、まず、99s パーセンタイル。

106
00:06:16.575 --> 00:06:19.750
クリッピングのこの手順は、でよく知られて
います

107
00:06:19.750 --> 00:06:23.468
財務データと winsorization
と呼ばれています。

108
00:06:23.468 --> 00:06:26.980
例については、このヒストグラムを見てみま
しょう。

109
00:06:26.980 --> 00:06:32.330
我々は、特徴値の大部分はゼロと400の間
にあることがわかります。

110
00:06:32.330 --> 00:06:37.760
しかし、-1000
の周りの値を持つ飛び地の数があります。

111
00:06:37.760 --> 00:06:42.495
それらは私達の素晴らしく、簡単な線形モデ
ルのために生命をたくさん困難にさせること
ができる。

112
00:06:42.495 --> 00:06:45.940
この機能の値の範囲をクリップして、まず、

113
00:06:45.940 --> 00:06:49.570
下限と上限値を計算します。

114
00:06:49.570 --> 00:06:53.810
最初と99s パーセンタイルの機能の値。

115
00:06:53.810 --> 00:06:55.260
フィーチャの値をクリップした後、

116
00:06:55.260 --> 00:06:59.655
我々は、機能の分布が正常に見えることがわ
かります,

117
00:06:59.655 --> 00:07:03.743
そして、我々はこの機能は、より我々のモデ
ルのために有用であることを願っています。

118
00:07:03.743 --> 00:07:09.985
数値フィーチャのもう1つの効果的な前処理
として、ランク変換があります。

119
00:07:09.985 --> 00:07:15.210
基本的には、適切な分類値の間のスペースを
等しくするように設定します。

120
00:07:15.210 --> 00:07:17.160
この変換は、例えば、

121
00:07:17.160 --> 00:07:22.005
我々は外れ値を持っている場合
MinMaxScaler
よりも良いオプションをすることができます

122
00:07:22.005 --> 00:07:28.160
ランク変換は、他のオブジェクトに近い外れ
値を移動するためです。

123
00:07:28.160 --> 00:07:31.140
この例を使用してランクを理解してみましょ
う。

124
00:07:31.140 --> 00:07:34.165
配列のソースにランクを適用すると、

125
00:07:34.165 --> 00:07:37.585
それはちょうど彼らのインデックスに値を変
更します。

126
00:07:37.585 --> 00:07:41.110
ここで、並べ替えられていない配列にランク
を適用すると、

127
00:07:41.110 --> 00:07:42.765
この配列をソートします。

128
00:07:42.765 --> 00:07:46.610
この配列のソースの値とインデックスの間の
マッピングを定義します。

129
00:07:46.610 --> 00:07:49.528
、このマッピングを初期配列に適用します。

130
00:07:49.528 --> 00:07:54.180
線形モデル、KNN、およびニューラルネッ
トワークの恩恵を受けることができます

131
00:07:54.180 --> 00:07:59.640
この種の変換は、手動で外れ値を処理する時
間がない場合に行われます。

132
00:07:59.640 --> 00:08:04.868
ランクは scipy からランダムデータ
関数としてインポートすることができます。

133
00:08:04.868 --> 00:08:10.314
ランク変換に関するもう1つの重要な注意点
は、テストデータに適用することです。

134
00:08:10.314 --> 00:08:15.580
フィーチャ値からランク値へのクリエイティ
ブマッピングを保存する必要があります。

135
00:08:15.580 --> 00:08:18.540
あるいは、連結することもできますが、

136
00:08:18.540 --> 00:08:22.855
ランク変換を適用する前にデータをトレーニ
ングし、テストします。

137
00:08:22.855 --> 00:08:27.390
数値特徴の前処理の1つのより多くの例があ
る

138
00:08:27.390 --> 00:08:32.440
多くの場合、非ツリーベースのモデルと特に
ニューラルネットワークに役立ちます。

139
00:08:32.440 --> 00:08:35.805
データを使用してログ変換を適用したり、

140
00:08:35.805 --> 00:08:37.845
また別の可能性がある

141
00:08:37.845 --> 00:08:41.440
データの平方根を抽出することができます。

142
00:08:41.440 --> 00:08:44.880
これらの変換はどちらも便利です。

143
00:08:44.880 --> 00:08:49.425
機能の平均値に近い大きすぎる値をドライブ
します。

144
00:08:49.425 --> 00:08:55.095
これに加えて、ゼロに近い値は、もう少し区
別がつくようになりつつあります。

145
00:08:55.095 --> 00:08:58.320
シンプルにもかかわらず、これらの変換の1
つは

146
00:08:58.320 --> 00:09:02.213
あなたのニューラルネットワークの結果を大
幅に向上させます。

147
00:09:02.213 --> 00:09:08.210
すべての preprocessings 
に当てはまるもう一つの重要な瞬間は、時に
は、

148
00:09:08.210 --> 00:09:10.335
これは、上のモデルを訓練することが有益で
ある

149
00:09:10.335 --> 00:09:14.370
異なる preprocessings
によって生成された連結データフレーム

150
00:09:14.370 --> 00:09:19.325
または、異なる方法でプリプロセスされたデ
ータのトレーニングモデルを混ぜる。

151
00:09:19.325 --> 00:09:22.385
繰り返しになりますが、線形モデル、KNN
、

152
00:09:22.385 --> 00:09:26.804
そして、ニューラルネットワークは非常にこ
れから恩恵を受けることができます。

153
00:09:26.804 --> 00:09:30.945
このために、我々は、数値特徴の前処理を議
論している

154
00:09:30.945 --> 00:09:33.915
モデル選択がフィーチャーの前処理にどのよ
うに影響するか

155
00:09:33.915 --> 00:09:37.745
そして、最もよく使われる前処理方法は何で
すか。

156
00:09:37.745 --> 00:09:40.395
ここでは、機能の生成に移りましょう。

157
00:09:40.395 --> 00:09:43.290
フィーチャ生成は、

158
00:09:43.290 --> 00:09:47.155
機能とタスクに関するナレッジを使用した新
機能。

159
00:09:47.155 --> 00:09:51.495
それは、よりシンプルで効果的なモデルのト
レーニングを行うことによって私たちを助け
ます。

160
00:09:51.495 --> 00:09:55.270
場合によっては、事前の知識とロジックを使
用してこれらの機能を設計できます。

161
00:09:55.270 --> 00:09:57.345
データを掘り起こすこともある

162
00:09:57.345 --> 00:09:59.310
仮説を作成し、確認しなさい、

163
00:09:59.310 --> 00:10:04.060
そして、この派生知識と私たちの直感を使用
して、新機能を導出する。

164
00:10:04.060 --> 00:10:08.325
ここでは、先行知識による特徴生成について
議論し、

165
00:10:08.325 --> 00:10:09.990
しかし結局のところ

166
00:10:09.990 --> 00:10:12.450
データを掘り起こす能力と、

167
00:10:12.450 --> 00:10:17.380
洞察力を引き出すことは良い競争相手は素晴
らしいものになります。

168
00:10:17.380 --> 00:10:20.220
我々は徹底的に分析し、このスキルを説明す
る

169
00:10:20.220 --> 00:10:23.313
探索的データ分析の次のレッスン。

170
00:10:23.313 --> 00:10:28.950
ここでは、数値フィーチャのフィーチャ生成
の例について説明します。

171
00:10:28.950 --> 00:10:31.385
まずは、簡単なものから始めてみましょう。

172
00:10:31.385 --> 00:10:32.825
列がある場合は、

173
00:10:32.825 --> 00:10:37.430
データセット内の不動産価格と不動産の二乗
面積、

174
00:10:37.430 --> 00:10:40.155
我々はすぐに1つ以上の機能を追加すること
ができます

175
00:10:40.155 --> 00:10:42.090
平方メートルあたりの価格。

176
00:10:42.090 --> 00:10:45.430
簡単で、これは非常に合理的だ。

177
00:10:45.430 --> 00:10:51.615
または、フォレストカバー型予測データセッ
トから別の簡単な例を挙げてみましょう。

178
00:10:51.615 --> 00:10:54.660
我々は水源に水平距離を持っている場合、

179
00:10:54.660 --> 00:10:58.980
点と水源内の高さの上下差は、

180
00:10:58.980 --> 00:11:02.065
我々は、同様に示す結合機能を追加すること
があります

181
00:11:02.065 --> 00:11:05.750
この点から水への直接の距離。

182
00:11:05.750 --> 00:11:10.745
他のものの中で、それは、乗算を追加するこ
とを知っておくと便利です

183
00:11:10.745 --> 00:11:16.540
分割、およびその他の機能の相互作用は、線
形モデルだけでなく、支援することができま
す。

184
00:11:16.540 --> 00:11:21.900
たとえば、デシジョンツリー内のグラデーシ
ョンは非常に強力なモデルですが、

185
00:11:21.900 --> 00:11:26.620
それはまだ乗算および部門の近似の難しさを
経験する。

186
00:11:26.620 --> 00:11:29.580
また、サイズの機能を明示的に追加

187
00:11:29.580 --> 00:11:33.410
木の少ない量でより堅牢なモデルにつながる
。

188
00:11:33.410 --> 00:11:39.035
数値フィーチャのフィーチャ生成の3番目の
例も非常に興味深いものです。

189
00:11:39.035 --> 00:11:42.750
場合によっては、我々は機能として製品の価
格を持っている場合、

190
00:11:42.750 --> 00:11:47.745
我々は、これらの価格の小数部を示す新しい
機能を追加することができます。

191
00:11:47.745 --> 00:11:51.730
たとえば、一部の製品のコストが2.49
の場合、

192
00:11:51.730 --> 00:11:56.115
その価格の小数部は0.49 です。

193
00:11:56.115 --> 00:11:58.945
この機能は、モデルを活用することができま
す

194
00:11:58.945 --> 00:12:03.000
これらの価格の人々の知覚の違い。

195
00:12:03.000 --> 00:12:06.450
また、我々はタスクで同様のパターンを見つ
けることができます

196
00:12:06.450 --> 00:12:10.760
人間とロボットを区別する必要がある

197
00:12:10.760 --> 00:12:15.465
たとえば、オークションのような財務データ
があるとします。

198
00:12:15.465 --> 00:12:20.030
我々は、人々が価格としてラウンド番号を設
定する傾向があることを観察できる

199
00:12:20.030 --> 00:12:22.925
と0.935 のようなものがありますが、

200
00:12:22.925 --> 00:12:25.440
何とか、何とか、何とか、非常に長い番号を
ここに。

201
00:12:25.440 --> 00:12:29.420
または、我々は社会的なネットワーク上でス
パムを見つけようとしている場合、

202
00:12:29.420 --> 00:12:36.610
我々は、人間が今まで1秒の正確な間隔でメ
ッセージを読むことを確認することができま
す。

203
00:12:36.610 --> 00:12:42.050
素晴らしい、これらの3つの例では、アイデ
アを提供している必要があります

204
00:12:42.050 --> 00:12:48.193
創造性とデータの理解は、生産性の高い機能
の生成の鍵です。

205
00:12:48.193 --> 00:12:50.820
これをまとめましょう

206
00:12:50.820 --> 00:12:54.195
このビデオでは、数値機能について説明しま
した。

207
00:12:54.195 --> 00:12:59.400
まず、フィーチャー前処理の影響はモデルに
よって異なります。

208
00:12:59.400 --> 00:13:02.100
ツリーベースのモデルはスケーリングに依存
しません。

209
00:13:02.100 --> 00:13:05.735
一方、非ツリーベースのモデルは、通常、そ
れらに依存します。

210
00:13:05.735 --> 00:13:08.480
第二に、我々はスケーリングを扱うことがで
きます

211
00:13:08.480 --> 00:13:11.185
ケースの重要なハイパーパラメータ

212
00:13:11.185 --> 00:13:15.075
スケーリングの選択は、予測の品質に影響を
与えるとき。

213
00:13:15.075 --> 00:13:18.125
そして、最後に、我々は覚えておくべき

214
00:13:18.125 --> 00:13:23.240
その機能の生成は、データの理解によって供
給されます。

215
00:13:23.240 --> 00:13:29.910
この教訓を覚えて、この知識は確かにあなた
の次の競争のお手伝いをします。


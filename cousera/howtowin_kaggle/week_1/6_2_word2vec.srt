1
00:00:03.240 --> 00:00:06.335
こんにちは、戻ってお待ちしております。

2
00:00:06.335 --> 00:00:09.580
このビデオでは、我々は Word2vec
のアプローチについてお話します

3
00:00:09.580 --> 00:00:14.355
テキストとし、我々は特徴の抽出や画像につ
いて説明します。

4
00:00:14.355 --> 00:00:16.615
のパイプラインをまとめた後

5
00:00:16.615 --> 00:00:20.235
前のビデオでの単語のアプローチのバッグと
機能の抽出,

6
00:00:20.235 --> 00:00:23.250
別のアプローチの概要を説明しましょう。

7
00:00:23.250 --> 00:00:24.843
Word2vec
として広く知られている。

8
00:00:24.843 --> 00:00:28.460
ただ言葉のバッグが近づくにつれ、

9
00:00:28.460 --> 00:00:32.600
我々は、単語やテキストのベクトル表現を取
得したい

10
00:00:32.600 --> 00:00:34.980
しかし、今は以前よりも簡潔。

11
00:00:34.980 --> 00:00:37.925
Word2vec
はまさにそれをしています。

12
00:00:37.925 --> 00:00:42.585
これは、いくつかの洗練された空間内のいく
つかのベクトルに各単語を変換する

13
00:00:42.585 --> 00:00:45.665
これは通常、数百の寸法を持っている。

14
00:00:45.665 --> 00:00:47.679
単語の埋め込みを学習するには、

15
00:00:47.679 --> 00:00:50.985
Word2vec は近くの言葉を使う。

16
00:00:50.985 --> 00:00:55.950
基本的には、同じ文脈で使用されることが多
い異なる単語、

17
00:00:55.950 --> 00:00:58.915
これらの偏向表現に非常に近いでしょう、

18
00:00:58.915 --> 00:01:02.020
これは、もちろん、我々のモデルの利益にな
る。

19
00:01:02.020 --> 00:01:05.070
さらに、いくつかの顕著な例がある

20
00:01:05.070 --> 00:01:07.860
のような基本的な操作を適用できることを示
す

21
00:01:07.860 --> 00:01:10.515
これらのベクトルの加算と減算

22
00:01:10.515 --> 00:01:13.610
そのような操作の結果が解釈されることを期
待する。

23
00:01:13.610 --> 00:01:18.330
あなたはすでにどこかでこの例を見ているは
ずです。

24
00:01:18.330 --> 00:01:24.330
基本的に、我々は単語の女王と王のベクトル
の違いを計算する場合、

25
00:01:24.330 --> 00:01:28.765
女と男の言葉のベクトルの違い、

26
00:01:28.765 --> 00:01:33.525
我々は、これらの違いは非常にお互いに似て
いることがわかります。

27
00:01:33.525 --> 00:01:36.930
そして、我々は別の観点からこれを見てみる
と、

28
00:01:36.930 --> 00:01:42.450
そして男のベクトルと王のベクトルから女性
のベクトルを減算し、

29
00:01:42.450 --> 00:01:46.140
はかなり再び単語の女王のベクトルになりま
す。

30
00:01:46.140 --> 00:01:48.135
ちょっと考えてみてください。

31
00:01:48.135 --> 00:01:51.715
これは魅惑的な事実であり、実際の作成

32
00:01:51.715 --> 00:01:57.470
Word2vec のアプローチは、フィー
ルド内の多くの広範な、はるかに到達する結
果につながった。

33
00:01:57.470 --> 00:01:59.370
いくつかの実装があります。

34
00:01:59.370 --> 00:02:03.060
Word2vec、すなわち手袋以外にも、
この埋め込みのアプローチは、

35
00:02:03.060 --> 00:02:06.225
これは単語の表現のためのグローバルベクト
ルの略です。

36
00:02:06.225 --> 00:02:09.100
FastText といくつかの他の。

37
00:02:09.100 --> 00:02:16.270
我々は単語のためではなく、文のベクトルを
導出する必要がある場合、合併症が発生する
ことがあります。

38
00:02:16.270 --> 00:02:18.800
ここでは、異なるアプローチを取ることがあ
ります。

39
00:02:18.800 --> 00:02:22.610
例えば、我々は平均または合計の計算するこ
とができます

40
00:02:22.610 --> 00:02:28.318
単語のベクトルまたは我々は別の方法を選択
し、Doc2vec のような特別なモデル
で行くことができます。

41
00:02:28.318 --> 00:02:33.320
ここで進むためのすべての方法を選択すると
、特定の状況に依存します。

42
00:02:33.320 --> 00:02:37.490
通常は、両方のアプローチを確認し、ベスト
を選択した方が良いです。

43
00:02:37.490 --> 00:02:42.265
Word2vec
の訓練はかなり長い時間を取ることができる

44
00:02:42.265 --> 00:02:45.670
そして、あなたはテキストやいくつかの共通
の起源を使用する場合は、

45
00:02:45.670 --> 00:02:49.155
あなたは、インターネット上で有用な事前に
訓練されたモデルを見つけることができます
。

46
00:02:49.155 --> 00:02:52.620
例えば、ウィキペディアで訓練されているも
の。

47
00:02:52.620 --> 00:02:55.570
そうでなければ、覚えて、

48
00:02:55.570 --> 00:02:59.737
Word2vec のトレーニングは、テキ
ストからのターゲット値を必要としません。

49
00:02:59.737 --> 00:03:05.045
これは、各単語のコンテキストを抽出するテ
キストが必要です。

50
00:03:05.045 --> 00:03:08.675
前に説明したすべての前処理は、

51
00:03:08.675 --> 00:03:12.145
すなわち小文字ステミング、分類、

52
00:03:12.145 --> 00:03:18.980
また、ストップワードの使用は、Word2
vec モデルをトレーニングする前にテキ
ストに適用できます。

53
00:03:18.980 --> 00:03:22.310
さて、我々は袋の違いをまとめる準備ができ
ている

54
00:03:22.310 --> 00:03:26.710
言葉と Word2vec
のアプローチは、競争の文脈で。

55
00:03:26.710 --> 00:03:31.950
単語の袋で、ベクトルはかなり大きいが、よ
い利点である。

56
00:03:31.950 --> 00:03:34.805
ベクター内の各値の意味が知られている。

57
00:03:34.805 --> 00:03:38.756
Word2vec
では、ベクトルの長さが比較的小さい

58
00:03:38.756 --> 00:03:43.220
ただし、ベクター内の値は、場合によっては
解釈できますが、

59
00:03:43.220 --> 00:03:46.890
これは時々欠点として見ることができます。

60
00:03:46.890 --> 00:03:51.560
Word2vec
の他の利点は、競争の中で重要である

61
00:03:51.560 --> 00:03:57.395
同じような意味を持つ単語は、同様のベクト
ル表現を持つことになります。

62
00:03:57.395 --> 00:04:00.750
通常、両方の袋の言葉と

63
00:04:00.750 --> 00:04:03.915
Word2vec
アプローチは非常に異なる結果を与える

64
00:04:03.915 --> 00:04:06.740
あなたのソリューションで一緒に使用するこ
とができます。

65
00:04:06.740 --> 00:04:09.905
今の画像に進みましょう。

66
00:04:09.905 --> 00:04:12.680
言葉の Word2vec と同じように、

67
00:04:12.680 --> 00:04:17.495
畳み込みニューラルネットワークは、私たち
に画像の圧縮表現を与えることができます。

68
00:04:17.495 --> 00:04:19.755
私はあなたに簡単な説明を提供しましょう。

69
00:04:19.755 --> 00:04:22.440
画像のネットワーク出力を計算すると、

70
00:04:22.440 --> 00:04:25.305
最後の層の出力を得ることの側で、

71
00:04:25.305 --> 00:04:28.275
また、内側の層からの出力があります。

72
00:04:28.275 --> 00:04:30.690
ここでは、これらの出力記述子を呼び出しま
す。

73
00:04:30.690 --> 00:04:34.560
後のレイヤーからの記述子

74
00:04:34.560 --> 00:04:38.745
1つのネットワークに類似したテキストを解
決するよりよい方法は訓練されたである。

75
00:04:38.745 --> 00:04:45.015
逆に、初期レイヤーからの記述子には、テキ
ストに依存しない情報があります。

76
00:04:45.015 --> 00:04:49.235
たとえば、ネットワークがイメージとデータ
セットでトレーニングされた場合、

77
00:04:49.235 --> 00:04:50.570
正常に使用できます。

78
00:04:50.570 --> 00:04:55.483
いくつかの嘉モデル分類テキストの最後の層
の表現。

79
00:04:55.483 --> 00:04:59.270
しかし、いくつかの医療特定のテキストでネ
ットワークを使用する場合は、

80
00:04:59.270 --> 00:05:03.260
あなたが使用する場合は、おそらくより良い
行います

81
00:05:03.260 --> 00:05:07.500
以前の接続層、あるいはゼロからネットワー
クを再教育。

82
00:05:07.500 --> 00:05:10.910
ここでは、事前に訓練されたモデルを探すこ
とができる

83
00:05:10.910 --> 00:05:15.785
あなたが正確な競争に持っているものと同様
のデータに訓練を受けた。

84
00:05:15.785 --> 00:05:19.930
時々、我々はわずかに受信するネットワーク
を調整することができます

85
00:05:19.930 --> 00:05:25.895
私たちの画像に関連付けられているターゲッ
ト値を使用してより適切な表現。

86
00:05:25.895 --> 00:05:31.960
一般的に、事前に訓練されたモデルのチュー
ニングのプロセスは、微調整と呼ばれていま
す。

87
00:05:31.960 --> 00:05:33.935
前の例のように、

88
00:05:33.935 --> 00:05:36.395
我々はいくつかの医学的特定のタスクを解決
しているとき、

89
00:05:36.395 --> 00:05:39.755
我々は、チューニング VGG
RestNet
を見つけることができますか

90
00:05:39.755 --> 00:05:45.130
他の事前訓練されたネットワークと、これら
の特定のテキストを解決するために指定しま
す。

91
00:05:45.130 --> 00:05:48.830
微調整、特に小さなデータセットでは、

92
00:05:48.830 --> 00:05:50.870
通常トレーニングよりも優れている

93
00:05:50.870 --> 00:05:55.110
記述子または最初からトレーニングネットワ
ークのスタンドアロンモデル。

94
00:05:55.110 --> 00:05:59.185
ここでの直感はかなり簡単です。

95
00:05:59.185 --> 00:06:02.310
一方で、トレーニングよりも微調整の方が

96
00:06:02.310 --> 00:06:05.250
記述子のスタンドアロンモデル

97
00:06:05.250 --> 00:06:08.310
すべてのネットワークパラメータを調整する
ことができ、

98
00:06:08.310 --> 00:06:12.430
したがって、より効果的な画像表現を抽出し
ます。

99
00:06:12.430 --> 00:06:15.520
一方、トレーニングよりも微調整の方が

100
00:06:15.520 --> 00:06:18.690
ゼロからのネットワークデータが少なすぎる
場合は、

101
00:06:18.690 --> 00:06:24.270
または我々が解決しているテキストは、テキ
ストモデルに似ている場合に訓練された。

102
00:06:24.270 --> 00:06:29.970
この場合、モデルでは、既にネットワークパ
ラメータでエンコードされた my
ナレッジを使用することができます。

103
00:06:29.970 --> 00:06:33.950
これは、より良い結果と迅速な再訓練の手順
につながることができます。

104
00:06:33.950 --> 00:06:38.665
を使用して最も頻繁にシナリオを議論するこ
とができます

105
00:06:38.665 --> 00:06:43.852
オンラインステージまたはデータサイエンス
ゲーム2016で微調整。

106
00:06:43.852 --> 00:06:50.665
タスクは、4つのカテゴリのいずれかに屋根
のこれらの敷設写真を分類することでした。

107
00:06:50.665 --> 00:06:54.345
いつものように、ロゴは、最初に他のメトリ
ックに選ばれました。

108
00:06:54.345 --> 00:06:58.480
競合他社は8000の異なる画像を持ってい
た。

109
00:06:58.480 --> 00:07:02.145
この設定では、変更するには良い選択だった

110
00:07:02.145 --> 00:07:04.090
いくつかの事前訓練を受けたネットワークを
予測する

111
00:07:04.090 --> 00:07:06.305
これらの4つのクラスと微調整のための確率
。

112
00:07:06.305 --> 00:07:09.710
を見てみましょう

113
00:07:09.710 --> 00:07:16.416
VGG-16 アーキテクチャそれは
VGG RestNet
から1000クラスで訓練されたので、

114
00:07:16.416 --> 00:07:19.565
これは、サイズ1000の出力を持っていま
す。

115
00:07:19.565 --> 00:07:21.995
我々は、テキスト内の4つのクラスを持って
いる

116
00:07:21.995 --> 00:07:25.490
だから我々は1000のサイズで最後の層を
削除することができます

117
00:07:25.490 --> 00:07:30.410
そして、その場所に4つのサイズで新しいも
のを置く。

118
00:07:30.410 --> 00:07:34.880
それから、私達はちょうど非常に小さい率の
私達のモデルを再教育する

119
00:07:34.880 --> 00:07:40.585
通常約1000回私たちの最初の低料金より
も低いです。

120
00:07:40.585 --> 00:07:43.901
それは微調整が行われている、

121
00:07:43.901 --> 00:07:47.495
しかし、我々はすでにこのビデオの前に議論
したように、

122
00:07:47.495 --> 00:07:52.240
我々は、同様のデータセットで事前に訓練さ
れたモデルを使用して恩恵を受けることがで
きます。

123
00:07:52.240 --> 00:07:56.720
イメージ自体は非常に異なったクラスから成
っている

124
00:07:56.720 --> 00:08:01.286
家具から食糧への車への動物は最も適した前
訓練されたモデルを定義できる。

125
00:08:01.286 --> 00:08:04.936
私達はちょうど訓練されたモデルを取ること
ができる

126
00:08:04.936 --> 00:08:09.683
建物や家屋の写真で設定された場所のデータ
では、

127
00:08:09.683 --> 00:08:14.025
このモデルを微調整し、その結果をさらに向
上させます。

128
00:08:14.025 --> 00:08:17.025
微調整の詳細に興味があれば、

129
00:08:17.025 --> 00:08:23.265
あなたはそれについての情報を見つけること
ができますほぼすべてのニューラルネットワ
ークライブラリすなわち Keras、

130
00:08:23.265 --> 00:08:27.030
PyTorch、カフェなど。

131
00:08:27.030 --> 00:08:33.410
場合によっては、また、より良いネットワー
クを訓練するためのトレーニング画像の数を
増やしたい。

132
00:08:33.410 --> 00:08:37.720
その場合、イメージの増強は助けであるかも
しれない。

133
00:08:37.720 --> 00:08:40.940
このイメージの増強の概念を説明しましょう
。

134
00:08:40.940 --> 00:08:42.260
前の例では、

135
00:08:42.260 --> 00:08:45.085
屋根画像の分類について議論した。

136
00:08:45.085 --> 00:08:51.710
わかりやすくするために、クラスごとに4つ
のイメージがあることを想像してみましょう
。

137
00:08:51.710 --> 00:08:54.430
トレーニングサンプルの数を増やすことがで
きます。

138
00:08:54.430 --> 00:08:59.325
180度で回転画像から始めましょう。

139
00:08:59.325 --> 00:09:02.035
なお、このような回転の後には、

140
00:09:02.035 --> 00:09:06.178
屋根があるのでクラス1のイメージはこのク
ラスに再度属する

141
00:09:06.178 --> 00:09:11.210
新しいイメージにも南北方向があります。

142
00:09:11.210 --> 00:09:15.215
同じことが他のクラスにも当てはまることを
簡単に確認できます。

143
00:09:15.215 --> 00:09:18.905
すごい。1回転だけやってから、

144
00:09:18.905 --> 00:09:23.480
我々はすでに2回の訓練を受けたデータの量
を増やします。

145
00:09:23.480 --> 00:09:28.655
さて、我々は90度でファーストクラスから
画像を回転させる場合、何が起こるのでしょ
うか?

146
00:09:28.655 --> 00:09:31.130
どのクラスに属していますか?

147
00:09:31.130 --> 00:09:35.045
はい、それは2番目のクラスに属し、最終的
には、

148
00:09:35.045 --> 00:09:40.114
画像を3番目と4番目のクラスから90度回
転させると、

149
00:09:40.114 --> 00:09:42.570
彼らは同じクラスに滞在します。

150
00:09:42.570 --> 00:09:48.710
見て、我々はちょうど私たちの訓練を受けた
セットのサイズを増やす4回

151
00:09:48.710 --> 00:09:51.380
そのような augmentations
の追加はそうではない

152
00:09:51.380 --> 00:09:55.320
訓練されたセットに真新しいイメージを加え
ることとして有効。

153
00:09:55.320 --> 00:10:00.410
これはまだ非常に有用であり、大幅にあなた
のスコアを高めることができます。

154
00:10:00.410 --> 00:10:04.085
一般的なケースでは、画像の増強は、グルー
プを含めることができます

155
00:10:04.085 --> 00:10:07.240
回転、ノイズなど。

156
00:10:07.240 --> 00:10:10.670
全体として、これはフィッティングと

157
00:10:10.670 --> 00:10:14.760
より良い結果でより堅牢なモデルを訓練する
ことができます。

158
00:10:14.760 --> 00:10:21.370
画像からベクトルを抽出し、このノートにつ
いての最後の音符は重要な1つです。

159
00:10:21.370 --> 00:10:26.155
convolutiontional ニュ
ーラルネットワークを微調整したり、ゼロか
らトレーニングしたい場合は、

160
00:10:26.155 --> 00:10:30.355
通常は、トレーニング済みのセットのイメー
ジからラベルを使用する必要があります。

161
00:10:30.355 --> 00:10:34.299
ので、ここで検証に注意してくださいとフィ
ットオーバーしないでください。

162
00:10:34.299 --> 00:10:39.550
さて、ここで説明した要点を思い出してみま
しょう。

163
00:10:39.550 --> 00:10:44.950
場合によっては、追加データとしてテキスト
や画像との競争があります。

164
00:10:44.950 --> 00:10:47.450
この場合、通常は抽出したい

165
00:10:47.450 --> 00:10:51.055
あなたのモデルを改善するためにそれらから
便利な機能。

166
00:10:51.055 --> 00:10:52.720
テキストを操作する場合は、

167
00:10:52.720 --> 00:10:55.490
前処理は有用であると証明することができま
す。

168
00:10:55.490 --> 00:10:58.940
これらの事前処理には、すべて小文字、ステ
ミング、分類、

169
00:10:58.940 --> 00:11:02.775
、ストップワードを削除します。

170
00:11:02.775 --> 00:11:05.705
その前処理が行われた後、

171
00:11:05.705 --> 00:11:10.505
あなたは言葉のいずれかのバッグや
Word2vec
アプローチで行くことができます。

172
00:11:10.505 --> 00:11:14.855
言葉の袋は、あなたが明確な解釈を保証しま
す。

173
00:11:14.855 --> 00:11:17.130
各機能は、を持つことによって調整される

174
00:11:17.130 --> 00:11:21.175
それぞれのユニークな単語のための機能の膨
大な量の1つ。

175
00:11:21.175 --> 00:11:24.095
他の側では、Word2vec が生成

176
00:11:24.095 --> 00:11:28.665
各特徴値の意味による比較的小さいベクトル
はかすんでいる場合もある。

177
00:11:28.665 --> 00:11:34.370
競争で重要である Word2vec
の他の利点はそれである

178
00:11:34.370 --> 00:11:41.060
同様の意味を持つ単語は、同様のベクトル表
現を持つことになります。

179
00:11:41.060 --> 00:11:46.400
また、Ngrams は、テキストのための
単語の相互作用を含むように適用することが
できます

180
00:11:46.400 --> 00:11:52.880
TFiDF は、単語の袋によって生成され
たポストプロセスのメトリックに適用するこ
とができます。

181
00:11:52.880 --> 00:11:55.830
今のイメージ。画像については、

182
00:11:55.830 --> 00:12:00.825
我々は、機能を抽出するために事前に訓練さ
れた畳み込みニューラルネットワークを使用
することができます。

183
00:12:00.825 --> 00:12:03.360
間の類似性に応じて

184
00:12:03.360 --> 00:12:07.980
競争データおよびデータニューラルネットワ
ークは訓練された、

185
00:12:07.980 --> 00:12:11.765
我々は、異なる層から記述子を計算する必要
があります。

186
00:12:11.765 --> 00:12:18.065
多くの場合、ニューラルネットワークの微調
整は、記述子の品質を向上させるのに役立ち
ます。

187
00:12:18.065 --> 00:12:21.120
効果的な微調整を目的として、

188
00:12:21.120 --> 00:12:25.095
我々はデータを増強したいかもしれない

189
00:12:25.095 --> 00:12:29.490
また、微調整やデータの増強は、多くの場合
、

190
00:12:29.490 --> 00:12:35.230
我々は画像を除く他の日付を持っている大会
。

191
00:12:35.230 --> 00:12:38.750
その上、前訓練されたモデルの数がある

192
00:12:38.750 --> 00:12:43.385
インターネット上での畳み込みニューラルネ
ットワークと Word2vec

193
00:12:43.385 --> 00:12:46.640
すごい。今、あなたが処理する方法を知って
いる

194
00:12:46.640 --> 00:12:51.245
テキストや画像のような追加のデータを持つ
コンテスト。

195
00:12:51.245 --> 00:12:54.800
我々が議論しているアイデアを適用し、適応
することにより、

196
00:12:54.800 --> 00:12:59.890
この種の設定では、エッジを得ることができ
ます。


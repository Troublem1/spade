1
00:00:03.250 --> 00:00:06.025
こんにちは。このビデオでは、

2
00:00:06.025 --> 00:00:09.608
我々は、カテゴリと序数の機能をカバーしま
す。

3
00:00:09.608 --> 00:00:12.395
私たちは彼らと一緒に動作する方法の概要を
説明します。

4
00:00:12.395 --> 00:00:17.354
特に、モデルタイプごとにどのような前処理
が使われるのでしょうか?

5
00:00:17.354 --> 00:00:19.035
何が違うのか

6
00:00:19.035 --> 00:00:25.845
カテゴリと序数の機能とどのように我々はそ
れらから新しい機能を生成することができま
すか?

7
00:00:25.845 --> 00:00:28.380
まず、からいくつかの行を見てみましょう

8
00:00:28.380 --> 00:00:32.545
タイタニックデータセットとカテゴリの機能
をここに検索します。

9
00:00:32.545 --> 00:00:35.980
彼らの名前は:
セックス、キャビンと乗り出した。

10
00:00:35.980 --> 00:00:42.955
これらは、通常のカテゴリ機能ですが、もう
一つの特別な、Pclass
機能があります。

11
00:00:42.955 --> 00:00:45.490
Pclass はチケットクラスの略で、

12
00:00:45.490 --> 00:00:50.150
3つのユニークな値:
1、2、および3があります。

13
00:00:50.150 --> 00:00:52.135
序数というか、

14
00:00:52.135 --> 00:00:55.455
言い換えれば、順序カテゴリ機能。

15
00:00:55.455 --> 00:01:00.105
これは基本的には、いくつかの有意義な方法
で注文されていることを意味します。

16
00:01:00.105 --> 00:01:04.045
たとえば、最初のクラスが2番目よりも高か
った場合、

17
00:01:04.045 --> 00:01:08.763
または、より多くの最初の3番目よりも高価
にする必要があります。

18
00:01:08.763 --> 00:01:11.085
我々はここで重要な注意をする必要がありま
す

19
00:01:11.085 --> 00:01:14.900
序数と数値の機能の違いについて。

20
00:01:14.900 --> 00:01:18.018
Pclass
が数値機能であったとしたら、

21
00:01:18.018 --> 00:01:20.160
我々は、最初の違いは、と言うことができる

22
00:01:20.160 --> 00:01:25.345
そして2級は二男と3級の差に等しく、

23
00:01:25.345 --> 00:01:27.575
しかし、Pclass は序数なので、

24
00:01:27.575 --> 00:01:29.880
どちらの差が大きいかはわかりません。

25
00:01:29.880 --> 00:01:31.635
これらの数値機能として、

26
00:01:31.635 --> 00:01:35.580
序数フィーチャを他の方法でソートして統合
することはできません。

27
00:01:35.580 --> 00:01:38.580
と同様のパフォーマンスを得ることを期待。

28
00:01:38.580 --> 00:01:41.987
序数機能のもう1つの例は、ドライバーのラ
イセンスの種類です。

29
00:01:41.987 --> 00:01:44.640
それは A、B、C のどちらかですが、

30
00:01:44.640 --> 00:01:47.660
または D。または別の例では、

31
00:01:47.660 --> 00:01:51.175
教育レベル、幼稚園、学校、

32
00:01:51.175 --> 00:01:54.830
学部卒、学士、修士、博士。

33
00:01:54.830 --> 00:01:59.105
これらのカテゴリは、ますます複雑な順序で
ソートされ、

34
00:01:59.105 --> 00:02:01.660
これは有用であると証明することができます
。

35
00:02:01.660 --> 00:02:04.095
最も簡単なエンコード方法

36
00:02:04.095 --> 00:02:08.995
カテゴリ機能とは、一意の値を異なる数値に
マップすることです。

37
00:02:08.995 --> 00:02:14.100
通常、人々はこのプロシージャをラベルのエ
ンコーディングと呼びます。

38
00:02:14.100 --> 00:02:19.310
このメソッドは、ツリーメソッドは、機能を
分割することができますので、2つの方法で
正常に動作

39
00:02:19.310 --> 00:02:24.370
、カテゴリ内の有用な値のほとんどを独自に
抽出します。

40
00:02:24.370 --> 00:02:27.114
非木ベースのモデルは、反対側に、

41
00:02:27.114 --> 00:02:30.035
通常、この機能を効果的に使用できません。

42
00:02:30.035 --> 00:02:34.940
そして、あなたは、ニューラルネットワーク
上の線形モデル kNN
を訓練したい場合は、

43
00:02:34.940 --> 00:02:38.780
カテゴリ機能を異なる方法で扱う必要があり
ます。

44
00:02:38.780 --> 00:02:44.320
これを説明するために、このトピックの冒頭
に示した例を思い出してみましょう。

45
00:02:44.320 --> 00:02:48.310
1つの Pclass
が1つのターゲットに通常導くかどうか、

46
00:02:48.310 --> 00:02:50.785
Pclass の2つのリードはゼロに、

47
00:02:50.785 --> 00:02:53.965
そして3つの Pclass
は1つに導く。

48
00:02:53.965 --> 00:02:55.845
この依存性は直線的ではなく、

49
00:02:55.845 --> 00:02:58.530
そして線形モデルは混同される。

50
00:02:58.530 --> 00:03:04.454
そして、実際には、ここでは、線形モデルの
予測を置くことができます

51
00:03:04.454 --> 00:03:09.385
そして、彼らはすべて0.5
の周りにある参照してください。

52
00:03:09.385 --> 00:03:14.015
これは、セットのようなものが3つの反対側
に見える

53
00:03:14.015 --> 00:03:19.545
我々は、2つの分割は、それぞれのユニーク
な値で選択し、独立してそれに到達するでし
ょう。

54
00:03:19.545 --> 00:03:25.751
したがって、このエントリは、ここでこれら
の機能を使用してはるかに良いスコアを達成
できる。

55
00:03:25.751 --> 00:03:30.069
では、カテゴリ機能をもう一度実行して、ラ
ベルのエンコードを適用してみましょう。

56
00:03:30.069 --> 00:03:33.155
この機能を着手してみましょう。

57
00:03:33.155 --> 00:03:35.284
ただし、エンコードする必要はありませんで
した

58
00:03:35.284 --> 00:03:39.000
前のフィーチャーは、モデルで使用する前に
Pclass ます。

59
00:03:39.000 --> 00:03:42.595
ここでは、我々は間違いなく着手でこれを行
う必要があります。

60
00:03:42.595 --> 00:03:45.470
それはいくつかの方法で達成することができ
ます。

61
00:03:45.470 --> 00:03:50.670
まず、アルファベット順または並べ替え順序
でエンコードを適用できます。

62
00:03:50.670 --> 00:03:54.795
この機能は、すなわち、S、C、Q
を解決するためのユニークな方法です。

63
00:03:54.795 --> 00:03:59.180
したがって、2つ、1つ、3としてエンコー
ドすることができます。

64
00:03:59.180 --> 00:04:03.340
これは、デフォルトでは sklearn
works
のラベルエンコーダと呼ばれます。

65
00:04:03.340 --> 00:04:07.940
2番目の方法も、コーディングがわずかに異
なるラベリングされます。

66
00:04:07.940 --> 00:04:12.255
ここでは、カテゴリフィーチャーを出現順に
エンコードします。

67
00:04:12.255 --> 00:04:17.005
たとえば、s はデータの最初のものである
ため、1に変更されます。

68
00:04:17.005 --> 00:04:20.730
次に c、我々は2に c を変更します。

69
00:04:20.730 --> 00:04:24.510
そして最後は3に変更される q です。

70
00:04:24.510 --> 00:04:29.115
すべてが意味のある方法でソートされている
場合、これは意味をなすことができます。

71
00:04:29.115 --> 00:04:33.165
これは、factorize
関数の既定の動作です。

72
00:04:33.165 --> 00:04:37.732
3番目の方法については、周波数エンコード
と呼ばれることを教えてくれます。

73
00:04:37.732 --> 00:04:43.130
この機能は、値をその周波数にマッピングす
ることでエンコードできます。

74
00:04:43.130 --> 00:04:52.440
私たちのためにも 30% が着手した c
と50に等しく、残りの20は q
に等しくなります。

75
00:04:52.440 --> 00:04:57.671
我々はそれに応じてこの値を変更することが
できます: c に0.3、s に0。

76
00:04:57.671 --> 00:05:01.690
5、および q を0.2 にします。

77
00:05:01.690 --> 00:05:05.910
これは、値の分布に関するいくつかの情報を
保持する

78
00:05:05.910 --> 00:05:09.590
線形および3つのモデルの両方を助けること
ができる。

79
00:05:09.590 --> 00:05:12.305
最初のものは、この機能を便利見つけること
ができます

80
00:05:12.305 --> 00:05:15.323
値の周波数がそれのターゲット値に相関して
いる場合。

81
00:05:15.323 --> 00:05:21.825
2番目のものは、同じ理由のために分割の少
ない数で助けることができる間。

82
00:05:21.825 --> 00:05:26.284
周波数エンコードに関するもう1つの重要な
瞬間があります。

83
00:05:26.284 --> 00:05:29.880
同じ頻度で複数のカテゴリがある場合は、

84
00:05:29.880 --> 00:05:33.985
彼らはこの新しい機能で区別されません。

85
00:05:33.985 --> 00:05:39.550
我々は、このような関係に対処するために、
ここで適用または実行の分類かもしれない。

86
00:05:39.550 --> 00:05:42.780
このようにすることは可能です。

87
00:05:42.780 --> 00:05:45.370
ラベルのエンコードを行う方法は他にもあり
ますが、

88
00:05:45.370 --> 00:05:49.810
そして、私は間違いなくそれらを構築する創
造的であることをお勧めします。

89
00:05:49.810 --> 00:05:52.607
大丈夫です。我々は、ラベルのエンコードを
議論

90
00:05:52.607 --> 00:05:57.640
周波数エンコーディング、そしてなぜこれは
ツリーベースのメソッドのために正常に動作
します。

91
00:05:57.640 --> 00:06:04.023
しかし、我々はまた、線形モデルは、ラベル
符号化機能と戦うことができる見てきました
。

92
00:06:04.023 --> 00:06:05.890
カテゴリの機能を識別する方法

93
00:06:05.890 --> 00:06:09.465
非ツリーベースのモデルも非常に簡単です。

94
00:06:09.465 --> 00:06:13.240
我々は、将来的には、それぞれのユニークな
価値のための新しいコードを作成する必要が
あります

95
00:06:13.240 --> 00:06:16.185
と適当なところに1つ入れます。

96
00:06:16.185 --> 00:06:18.420
他のすべてはゼロになります。

97
00:06:18.420 --> 00:06:21.837
このメソッドは、1ホットエンコーディング
と呼ばれます。

98
00:06:21.837 --> 00:06:26.375
この簡単な例でどのように動作するか見てみ
ましょう。

99
00:06:26.375 --> 00:06:29.555
だからここでは、Pclass
機能のそれぞれのユニークな値については、

100
00:06:29.555 --> 00:06:30.989
新しいコラムを作成したところです。

101
00:06:30.989 --> 00:06:34.416
私が言ったように、これは線形方法のために
よく働く、

102
00:06:34.416 --> 00:06:37.610
kNN、またはニューラルネットワーク。

103
00:06:37.610 --> 00:06:40.850
さらに、1つのホットエンコーディング機能
はすでに

104
00:06:40.850 --> 00:06:44.240
この機能の最小値は0であるため、スケーリ
ング

105
00:06:44.240 --> 00:06:45.950
そして、最大値は1です。

106
00:06:45.950 --> 00:06:50.085
重要な数値フィーチャの数が少なくて済むよ
うに注意する場合は、

107
00:06:50.085 --> 00:06:53.415
と何百ものバイナリ機能は、1つのホットエ
ンコーディングによって使用され、

108
00:06:53.415 --> 00:06:59.690
それは木方法のためにそれらが最初の物を効
率的に使用することは困難になることができ
る。

109
00:06:59.690 --> 00:07:03.200
より正確には、ツリーメソッドが遅くなりま
す、

110
00:07:03.200 --> 00:07:05.725
常にその結果を改善していない。

111
00:07:05.725 --> 00:07:11.315
また、カテゴリ機能に一意の値が多すぎる場
合は、

112
00:07:11.315 --> 00:07:16.378
ゼロ以外の値をいくつか追加すると、新しい
列が多すぎます。

113
00:07:16.378 --> 00:07:19.150
これらの新しいアレイを効率的に保存するに
は、

114
00:07:19.150 --> 00:07:21.885
疎行列について知る必要がある.

115
00:07:21.885 --> 00:07:27.280
一言で言えば、配列のすべての要素の
RAM
にスペースを割り当てるのではなく、

116
00:07:27.280 --> 00:07:30.260
ゼロ以外の要素しか保存できないため、

117
00:07:30.260 --> 00:07:31.830
多くのメモリを節約します。

118
00:07:31.830 --> 00:07:35.990
疎行列で行くことは、数が多ければ理にかな
っている

119
00:07:35.990 --> 00:07:41.125
0以外の値は、すべての値の半分よりもはる
かに少なくなります。

120
00:07:41.125 --> 00:07:48.480
疎行列は、カテゴリフィーチャやテキストデ
ータを操作する場合に便利です。

121
00:07:48.480 --> 00:07:54.045
一般的なライブラリのほとんどは、これらの
疎行列を直接、すなわち、作業することがで
きます

122
00:07:54.045 --> 00:07:58.270
XGBoost、LightGBM、skl
earn、その他。

123
00:07:58.270 --> 00:08:00.050
方法を考え出した後

124
00:08:00.050 --> 00:08:05.030
ツリーベースおよび非ツリーベースモデルの
ための事前処理されたカテゴリ機能

125
00:08:05.030 --> 00:08:08.345
我々は、機能の生成を簡単に見てみることが
できます。

126
00:08:08.345 --> 00:08:12.481
特徴生成の最も有用な例の1つ

127
00:08:12.481 --> 00:08:16.750
は、複数のカテゴリ機能間の機能の相互作用
です。

128
00:08:16.750 --> 00:08:22.750
これは、通常、非ツリーベースのモデルすな
わち、線形モデル、kNN に便利です。

129
00:08:22.750 --> 00:08:26.018
たとえば、ターゲットが依存していることを
仮定します。

130
00:08:26.018 --> 00:08:29.961
Pclass
機能とセックス機能の両方で。

131
00:08:29.961 --> 00:08:33.170
これが本当なら、線形モデルは調整すること
ができる

132
00:08:33.170 --> 00:08:37.040
これらの2つの機能のすべての可能な組み合
わせのための予測、

133
00:08:37.040 --> 00:08:39.195
そして、より良い結果を得る。

134
00:08:39.195 --> 00:08:40.883
どのように我々はこれを実現することができ
ます?

135
00:08:40.883 --> 00:08:44.180
このインタラクションを単純に連結して追加
してみましょう

136
00:08:44.180 --> 00:08:48.460
両方の列と1つのホットエンコーディングか
らの文字列を取得します。

137
00:08:48.460 --> 00:08:54.117
今線形モデルはあらゆる相互作用のための最
適係数を見つけ、改善することができる。

138
00:08:54.117 --> 00:08:57.005
シンプルで効果的です。

139
00:08:57.005 --> 00:09:01.517
機能の相互作用の詳細は、特に次の週に来る

140
00:09:01.517 --> 00:09:04.075
高度な機能のトピック。

141
00:09:04.075 --> 00:09:06.745
さて、この機能をまとめてみましょう。

142
00:09:06.745 --> 00:09:10.000
まず、序数は特殊なケースです。

143
00:09:10.000 --> 00:09:14.885
カテゴリ機能ですが、値が意味のある順序で
並べ替えられています。

144
00:09:14.885 --> 00:09:18.460
第二に、ラベルのエンコードは、基本的に置
き換える

145
00:09:18.460 --> 00:09:24.040
数値を含むカテゴリ機能のこの一意の値。

146
00:09:24.040 --> 00:09:27.320
第三に、この用語における周波数符号化は、

147
00:09:27.320 --> 00:09:30.540
固有の値をその周波数にマップします。

148
00:09:30.540 --> 00:09:38.740
第四に、ラベルの符号化と周波数符号化は、
しばしばツリーベースのメソッドに使用され
ます。

149
00:09:38.740 --> 00:09:43.210
第五に、1つのホットエンコーディングは、
多くの場合、非ツリーベースのメソッドに使
用されます。

150
00:09:43.210 --> 00:09:45.890
そして最後に、1つのホットエンコーディン
グの組み合わせを1つの心を適用する

151
00:09:45.890 --> 00:09:48.640
と和音のカテゴリ機能の組み合わせに

152
00:09:48.640 --> 00:09:52.030
非ツリーベースのモデルが

153
00:09:52.030 --> 00:09:56.030
機能間の相互作用を考慮し、改善する。

154
00:09:56.030 --> 00:10:01.545
いい。私達はちょうどそれを分類された特徴
のための前プロセス機能、整理した

155
00:10:01.545 --> 00:10:05.895
と機能の生成を簡単に見ていた。

156
00:10:05.895 --> 00:10:08.830
今、あなたはこれらの概念を適用することが
できます

157
00:10:08.830 --> 00:10:13.540
あなたの次の競争で、より良い結果を得る。

